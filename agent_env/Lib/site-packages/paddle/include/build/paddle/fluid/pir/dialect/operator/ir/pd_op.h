// This file is generated by "paddle/fluid/pir/dialect/op_generator/op_gen.py"
#pragma once
#include <vector>

#include "paddle/fluid/pir/dialect/operator/interface/decomp.h"
#include "paddle/fluid/pir/dialect/operator/interface/decomp_vjp.h"
#include "paddle/fluid/pir/dialect/operator/interface/infer_symbolic_shape/infer_symbolic_shape.h"
#include "paddle/fluid/pir/dialect/operator/interface/infer_symbolic_shape/cache_grad_op_symbolic_shape.h"
#include "paddle/fluid/pir/dialect/operator/interface/infermeta.h"
#include "paddle/fluid/pir/dialect/operator/interface/layout_transformation.h"
#include "paddle/fluid/pir/dialect/operator/interface/op_yaml_info.h"
#include "paddle/fluid/pir/dialect/operator/interface/parse_kernel_key.h"
#include "paddle/fluid/pir/dialect/operator/interface/vjp.h"
#include "paddle/fluid/pir/dialect/operator/trait/inplace.h"
#include "paddle/fluid/pir/dialect/operator/trait/forward_only.h"
#include "paddle/fluid/pir/dialect/operator/utils/op_yaml_info_util.h"
#include "paddle/fluid/pir/dialect/operator/utils/utils.h"
#include "paddle/pir/include/core/builder.h"
#include "paddle/pir/include/core/op_base.h"
#include "paddle/pir/include/core/op_trait.h"
#include "paddle/pir/include/core/operation_utils.h"
#ifdef PADDLE_WITH_DNNL
#include "paddle/fluid/pir/dialect/operator/trait/onednn.h"
#endif
#include "paddle/fluid/ir_adaptor/translator/pd_op_sig.h"
#include "paddle/fluid/pir/dialect/operator/ir/manual_op.h"
#include "paddle/fluid/pir/dialect/operator/trait/custom_vjp.h"
#include "paddle/phi/core/infermeta_utils.h"

#include "paddle/phi/common/data_type.h"
#include "paddle/fluid/pir/dialect/operator/interface/get_kernel_type_for_var.h"
            

namespace paddle {
namespace dialect {

extern std::unordered_map<std::string, std::vector<PdOpSig>> op_to_multi_kernels_map;
extern std::unordered_map<std::string, std::vector<PdOpSig>> sp_op_to_multi_kernels_map;

} // namespace dialect
} // namespace paddle

namespace paddle {
namespace dialect {

class TEST_API AbsOp : public pir::Op<AbsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Abs_Op : public pir::Op<Abs_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AccuracyOp : public pir::Op<AccuracyOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.accuracy"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value label() { return operand_source(2); }
  pir::Value accuracy() { return result(0); }
  pir::Value correct() { return result(1); }
  pir::Value total() { return result(2); }

};

class  AccuracyCheckOp : public pir::Op<AccuracyCheckOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.accuracy_check"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::string& fn_name, double rtol=1e-5, double atol=1e-8, bool equal_nan=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  AcosOp : public pir::Op<AcosOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Acos_Op : public pir::Op<Acos_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AcoshOp : public pir::Op<AcoshOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Acosh_Op : public pir::Op<Acosh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Adadelta_Op : public pir::Op<Adadelta_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adadelta_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value avg_squared_grad_, pir::Value avg_squared_update_, pir::Value learning_rate_, pir::Value master_param_, float rho=0.95f, float epsilon=1.0e-6f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value avg_squared_grad_, pir::Value avg_squared_update_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value avg_squared_grad() { return operand_source(2); }
  pir::Value avg_squared_update() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value master_param() { return operand_source(5); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value inf_norm_out() { return result(2); }
  pir::Value master_param_out() { return result(3); }

};

class  Adagrad_Op : public pir::Op<Adagrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adagrad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, float epsilon=1.0e-6f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  AdagradDenseParamSparseGrad_Op : public pir::Op<AdagradDenseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adagrad_dense_param_sparse_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, float epsilon=1.0e-6f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  Adam_Op : public pir::Op<Adam_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adam_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value moment2_max() { return operand_source(5); }
  pir::Value beta1_pow() { return operand_source(6); }
  pir::Value beta2_pow() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value skip_update() { return operand_source(9); }
  pir::Value beta1() { return operand_source(10); }
  pir::Value beta2() { return operand_source(11); }
  pir::Value epsilon() { return operand_source(12); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value moment2_max_out() { return result(3); }
  pir::Value beta1_pow_out() { return result(4); }
  pir::Value beta2_pow_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  AdamDenseParamSparseGrad_Op : public pir::Op<AdamDenseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adam_dense_param_sparse_grad_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value moment2_max() { return operand_source(5); }
  pir::Value beta1_pow() { return operand_source(6); }
  pir::Value beta2_pow() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value skip_update() { return operand_source(9); }
  pir::Value beta1() { return operand_source(10); }
  pir::Value beta2() { return operand_source(11); }
  pir::Value epsilon() { return operand_source(12); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value moment2_max_out() { return result(3); }
  pir::Value beta1_pow_out() { return result(4); }
  pir::Value beta2_pow_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  Adamax_Op : public pir::Op<Adamax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adamax_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment_, pir::Value inf_norm_, pir::Value beta1_pow_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment_, pir::Value inf_norm_, pir::Value beta1_pow_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value inf_norm() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value inf_norm_out() { return result(2); }
  pir::Value master_param_out() { return result(3); }

};

class  Adamw_Op : public pir::Op<Adamw_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.adamw_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, float lr_ratio=1.0f, float coeff=0.01f, bool with_decay=false, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, float lr_ratio=1.0f, float coeff=0.01f, bool with_decay=false, bool lazy_mode=false, int64_t min_row_size_to_use_multithread=1000, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value moment2_max() { return operand_source(5); }
  pir::Value beta1_pow() { return operand_source(6); }
  pir::Value beta2_pow() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value skip_update() { return operand_source(9); }
  pir::Value beta1() { return operand_source(10); }
  pir::Value beta2() { return operand_source(11); }
  pir::Value epsilon() { return operand_source(12); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value moment2_max_out() { return result(3); }
  pir::Value beta1_pow_out() { return result(4); }
  pir::Value beta2_pow_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  AddPositionEncodingOp : public pir::Op<AddPositionEncodingOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_position_encoding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f, float beta=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AddmmOp : public pir::Op<AddmmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Addmm_Op : public pir::Op<Addmm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AffineChannelOp : public pir::Op<AffineChannelOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_channel"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, const std::string& data_layout="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AffineChannel_Op : public pir::Op<AffineChannel_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_channel_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, const std::string& data_layout="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AffineGridOp : public pir::Op<AffineGridOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_grid"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& output_shape={}, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_shape_, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value output_shape() { return operand_source(1); }
  pir::Value output() { return result(0); }

};

class  AllOp : public pir::Op<AllOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AllGatherOp : public pir::Op<AllGatherOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all_gather"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AllReduceOp : public pir::Op<AllReduceOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all_reduce"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int reduce_type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AllReduce_Op : public pir::Op<AllReduce_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all_reduce_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int reduce_type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AllToAllOp : public pir::Op<AllToAllOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.all_to_all"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AllcloseOp : public pir::Op<AllcloseOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.allclose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, double rtol=1e-5, double atol=1e-8, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rtol_, pir::Value atol_, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rtol() { return operand_source(2); }
  pir::Value atol() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  AmaxOp : public pir::Op<AmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amax"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AminOp : public pir::Op<AminOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amin"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AngleOp : public pir::Op<AngleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.angle"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AnyOp : public pir::Op<AnyOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.any"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ApFacadeOp : public pir::Op<ApFacadeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ap_facade"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_, int64_t num_outputs, const std::string& custom_op_name, const std::string& infer_meta_func_name, const std::string& infer_symbolic_func_name, const std::string& serialized_attributes);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value xs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ApTrivialFusionBeginOp : public pir::Op<ApTrivialFusionBeginOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ap_trivial_fusion_begin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value xs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ApTrivialFusionEndOp : public pir::Op<ApTrivialFusionEndOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ap_trivial_fusion_end"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value xs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ApVariadicOp : public pir::Op<ApVariadicOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ap_variadic"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_, int num_outputs, const std::string& code_module_lambda, const std::string& infer_symbolic_lambda, const std::string& infer_meta_lambda, const std::string& rnel_dispatch_lambda, const std::string& kernel_dispatch_const_data_lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value xs_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value xs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ApplyPerChannelScaleOp : public pir::Op<ApplyPerChannelScaleOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.apply_per_channel_scale"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scales_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scales() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ArgmaxOp : public pir::Op<ArgmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argmax"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t axis, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ArgminOp : public pir::Op<ArgminOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argmin"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t axis, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdims=false, bool flatten=false, phi::DataType dtype=phi::DataType::INT64);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ArgsortOp : public pir::Op<ArgsortOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argsort"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool descending=false, bool stable=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  AsComplexOp : public pir::Op<AsComplexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_complex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsRealOp : public pir::Op<AsRealOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_real"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsStridedOp : public pir::Op<AsStridedOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_strided"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Asgd_Op : public pir::Op<Asgd_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asgd_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value d_, pir::Value y_, pir::Value n_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value d_, pir::Value y_, pir::Value n_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value d() { return operand_source(3); }
  pir::Value y() { return operand_source(4); }
  pir::Value n() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value d_out() { return result(1); }
  pir::Value y_out() { return result(2); }
  pir::Value master_param_out() { return result(3); }

};

class  AsinOp : public pir::Op<AsinOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Asin_Op : public pir::Op<Asin_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsinhOp : public pir::Op<AsinhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Asinh_Op : public pir::Op<Asinh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AssignPosOp : public pir::Op<AssignPosOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_pos"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cum_count_, pir::Value eff_num_len_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cum_count() { return operand_source(1); }
  pir::Value eff_num_len() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AssignValue_Op : public pir::Op<AssignValue_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_value_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, const std::vector<int>& shape, phi::DataType dtype, std::vector<phi::Scalar> values, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value output() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AtanOp : public pir::Op<AtanOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Atan_Op : public pir::Op<Atan_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Atan2Op : public pir::Op<Atan2Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan2"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  AtanhOp : public pir::Op<AtanhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Atanh_Op : public pir::Op<Atanh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AttentionLstmOp : public pir::Op<AttentionLstmOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.attention_lstm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value c0_, pir::Value h0_, pir::Value attention_weight_, pir::Value attention_bias_, pir::Value attention_scalar_, pir::Value attention_scalar_bias_, pir::Value lstm_weight_, pir::Value lstm_bias_, const std::string& gate_activation="sigmoid", const std::string& cell_activation="tanh", const std::string& candidate_activation="tanh");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value c0_, pir::Value h0_, pir::Value attention_weight_, pir::Value attention_bias_, pir::Value attention_scalar_, pir::Value attention_scalar_bias_, pir::Value lstm_weight_, pir::Value lstm_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value c0() { return operand_source(1); }
  pir::Value h0() { return operand_source(2); }
  pir::Value attention_weight() { return operand_source(3); }
  pir::Value attention_bias() { return operand_source(4); }
  pir::Value attention_scalar() { return operand_source(5); }
  pir::Value attention_scalar_bias() { return operand_source(6); }
  pir::Value lstm_weight() { return operand_source(7); }
  pir::Value lstm_bias() { return operand_source(8); }
  pir::Value hidden() { return result(0); }
  pir::Value cell() { return result(1); }
  pir::Value attentioned_x() { return result(2); }
  pir::Value attention_fc_out() { return result(3); }
  pir::Value lstm_x() { return result(4); }
  pir::Value lstm_out() { return result(5); }

};

class  AucOp : public pir::Op<AucOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.auc"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value stat_pos_, pir::Value stat_neg_, pir::Value ins_tag_weight_, const std::string& curve="ROC", int num_thresholds=(2 << 12) - 1, int slide_steps=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value stat_pos_, pir::Value stat_neg_, pir::Value ins_tag_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value stat_pos() { return operand_source(2); }
  pir::Value stat_neg() { return operand_source(3); }
  pir::Value ins_tag_weight() { return operand_source(4); }
  pir::Value auc() { return result(0); }
  pir::Value stat_pos_out() { return result(1); }
  pir::Value stat_neg_out() { return result(2); }

};

class  AverageAccumulates_Op : public pir::Op<AverageAccumulates_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.average_accumulates_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value in_sum_1_, pir::Value in_sum_2_, pir::Value in_sum_3_, pir::Value in_num_accumulates_, pir::Value in_old_num_accumulates_, pir::Value in_num_updates_, float average_window=0, int64_t max_average_window=INT64_MAX, int64_t min_average_window=10000L);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value in_sum_1_, pir::Value in_sum_2_, pir::Value in_sum_3_, pir::Value in_num_accumulates_, pir::Value in_old_num_accumulates_, pir::Value in_num_updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value in_sum_1() { return operand_source(1); }
  pir::Value in_sum_2() { return operand_source(2); }
  pir::Value in_sum_3() { return operand_source(3); }
  pir::Value in_num_accumulates() { return operand_source(4); }
  pir::Value in_old_num_accumulates() { return operand_source(5); }
  pir::Value in_num_updates() { return operand_source(6); }
  pir::Value out_sum_1() { return result(0); }
  pir::Value out_sum_2() { return result(1); }
  pir::Value out_sum_3() { return result(2); }
  pir::Value out_num_accumulates() { return result(3); }
  pir::Value out_old_num_accumulates() { return result(4); }
  pir::Value out_num_updates() { return result(5); }

};

class  BaddbmmOp : public pir::Op<BaddbmmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.baddbmm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Baddbmm_Op : public pir::Op<Baddbmm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.baddbmm_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  BarrierOp : public pir::Op<BarrierOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.barrier"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BatchFcOp : public pir::Op<BatchFcOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_fc"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  BceLossOp : public pir::Op<BceLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BceLoss_Op : public pir::Op<BceLoss_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BeamSearchOp : public pir::Op<BeamSearchOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.beam_search"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value pre_ids_, pir::Value pre_scores_, pir::Value ids_, pir::Value scores_, int level, int beam_size, int end_id, bool is_accumulated=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value pre_ids_, pir::Value pre_scores_, pir::Value ids_, pir::Value scores_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value pre_ids() { return operand_source(0); }
  pir::Value pre_scores() { return operand_source(1); }
  pir::Value ids() { return operand_source(2); }
  pir::Value scores() { return operand_source(3); }
  pir::Value selected_ids() { return result(0); }
  pir::Value selected_scores() { return result(1); }
  pir::Value parent_idx() { return result(2); }

};

class  BernoulliOp : public pir::Op<BernoulliOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bernoulli"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BicubicInterpOp : public pir::Op<BicubicInterpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bicubic_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_format="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output() { return result(0); }

};

class  BilinearOp : public pir::Op<BilinearOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value bias_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  BilinearInterpOp : public pir::Op<BilinearInterpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_format="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output() { return result(0); }

};

class  BincountOp : public pir::Op<BincountOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bincount"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, int minlength=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, pir::Value minlength_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weights_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weights() { return operand_source(1); }
  pir::Value minlength() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  BinomialOp : public pir::Op<BinomialOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.binomial"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value count_, pir::Value prob_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value count() { return operand_source(0); }
  pir::Value prob() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BipartiteMatchOp : public pir::Op<BipartiteMatchOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bipartite_match"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value dist_mat_, const std::string& match_type="bipartite", float dist_threshold=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value dist_mat_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value dist_mat() { return operand_source(0); }
  pir::Value col_to_row_match_indices() { return result(0); }
  pir::Value col_to_row_match_dist() { return result(1); }

};

class  BitwiseAndOp : public pir::Op<BitwiseAndOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_and"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseAnd_Op : public pir::Op<BitwiseAnd_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_and_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseLeftShiftOp : public pir::Op<BitwiseLeftShiftOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_left_shift"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool is_arithmetic=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseLeftShift_Op : public pir::Op<BitwiseLeftShift_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_left_shift_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool is_arithmetic=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseNotOp : public pir::Op<BitwiseNotOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_not"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BitwiseNot_Op : public pir::Op<BitwiseNot_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_not_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BitwiseOrOp : public pir::Op<BitwiseOrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_or"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseOr_Op : public pir::Op<BitwiseOr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_or_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseRightShiftOp : public pir::Op<BitwiseRightShiftOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_right_shift"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool is_arithmetic=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseRightShift_Op : public pir::Op<BitwiseRightShift_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_right_shift_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool is_arithmetic=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseXorOp : public pir::Op<BitwiseXorOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_xor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BitwiseXor_Op : public pir::Op<BitwiseXor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bitwise_xor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BmmOp : public pir::Op<BmmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bmm"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  BoxClipOp : public pir::Op<BoxClipOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.box_clip"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value im_info_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value im_info() { return operand_source(1); }
  pir::Value output() { return result(0); }

};

class  BoxCoderOp : public pir::Op<BoxCoderOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.box_coder"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prior_box_, pir::Value prior_box_var_, pir::Value target_box_, const std::string& code_type="encode_center_size", bool box_normalized=true, int axis=0, const std::vector<float>& variance={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prior_box_, pir::Value prior_box_var_, pir::Value target_box_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value prior_box() { return operand_source(0); }
  pir::Value prior_box_var() { return operand_source(1); }
  pir::Value target_box() { return operand_source(2); }
  pir::Value output_box() { return result(0); }

};

class  BroadcastOp : public pir::Op<BroadcastOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Broadcast_Op : public pir::Op<Broadcast_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BroadcastTensorsOp : public pir::Op<BroadcastTensorsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast_tensors"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BuildSrcRankAndLocalExpertIdOp : public pir::Op<BuildSrcRankAndLocalExpertIdOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.build_src_rank_and_local_expert_id"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_num_global_tensor_, const std::vector<int64_t>& expert_num_global, int64_t num_local_experts);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_num_global_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value expert_num_global_tensor() { return operand_source(0); }
  pir::Value vector() { return result(0); }
  pir::Value local_expert_id() { return result(1); }

};

class  CAllreduceSumOp : public pir::Op<CAllreduceSumOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_sum"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CAllreduceSum_Op : public pir::Op<CAllreduceSum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_allreduce_sum_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CConcatOp : public pir::Op<CConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_concat"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int rank, int nranks, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CIdentityOp : public pir::Op<CIdentityOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_identity"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CIdentity_Op : public pir::Op<CIdentity_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_identity_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id, bool use_calc_stream, bool use_model_parallel);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CScatterOp : public pir::Op<CScatterOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_scatter"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root=0, int nranks=0, bool use_calc_stream=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CSoftmaxWithCrossEntropyOp : public pir::Op<CSoftmaxWithCrossEntropyOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_cross_entropy"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, int64_t ignore_index=-100, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return result(0); }
  pir::Value loss() { return result(1); }

};

class  CSplitOp : public pir::Op<CSplitOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_split"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int rank=0, int nranks=1, int ring_id=0, bool use_model_parallel=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CalAuxLossOp : public pir::Op<CalAuxLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cal_aux_loss"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_prob_, pir::Value dispatch_mask_, pir::Value tokens_mask_, pir::Value dispatch_tokens_mask_, int64_t num_experts, bool use_group, int64_t moe_k, float clip_min);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_prob_, pir::Value dispatch_mask_, pir::Value tokens_mask_, pir::Value dispatch_tokens_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value gate_prob() { return operand_source(0); }
  pir::Value dispatch_mask() { return operand_source(1); }
  pir::Value tokens_mask() { return operand_source(2); }
  pir::Value dispatch_tokens_mask() { return operand_source(3); }
  pir::Value l_aux_loss() { return result(0); }
  pir::Value seqlen_float() { return result(1); }
  pir::Value ce() { return result(2); }

};

class  CalcReducedAttnScoresOp : public pir::Op<CalcReducedAttnScoresOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.calc_reduced_attn_scores"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value softmax_lse_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value softmax_lse() { return operand_source(2); }
  pir::Value reduced_scores() { return result(0); }

};

class TEST_API CastOp : public pir::Op<CastOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Cast_Op : public pir::Op<Cast_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CeilOp : public pir::Op<CeilOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Ceil_Op : public pir::Op<Ceil_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CeluOp : public pir::Op<CeluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ChannelShuffleOp : public pir::Op<ChannelShuffleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.channel_shuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int groups, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CheckFiniteAndUnscale_Op : public pir::Op<CheckFiniteAndUnscale_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.check_finite_and_unscale_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value found_infinite() { return result(1); }

};

class  CheckNumericsOp : public pir::Op<CheckNumericsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.check_numerics"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value tensor_, const std::string& op_type="", const std::string& var_name="", int check_nan_inf_level=0, int stack_height_limit=-1, const std::string& output_dir="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value tensor() { return operand_source(0); }
  pir::Value stats() { return result(0); }
  pir::Value values() { return result(1); }

};

class  CholeskyOp : public pir::Op<CholeskyOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool upper=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CholeskySolveOp : public pir::Op<CholeskySolveOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_solve"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool upper=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ClassCenterSampleOp : public pir::Op<ClassCenterSampleOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.class_center_sample"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, int num_classes, int num_samples, int ring_id=0, int rank=0, int nranks=1, bool fix_seed=false, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value label() { return operand_source(0); }
  pir::Value remapped_label() { return result(0); }
  pir::Value sampled_local_class_center() { return result(1); }

};

class  ClipOp : public pir::Op<ClipOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min, float max);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Clip_Op : public pir::Op<Clip_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min, float max);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  ClipByNormOp : public pir::Op<ClipByNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_by_norm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ClipByNormSrOp : public pir::Op<ClipByNormSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_by_norm_sr"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CoalesceTensorOp : public pir::Op<CoalesceTensorOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coalesce_tensor"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, phi::DataType dtype, bool copy_data=false, bool set_constant=false, bool persist_output=false, float constant=0.0, bool use_align=true, int align_size=-1, int size_of_dtype=-1, const std::vector<int64_t>& concated_shapes={}, const std::vector<int64_t>& concated_ranks={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value output() { return result(0); }
  pir::Value fused_output() { return result(1); }

};

class  CollectFpnProposalsOp : public pir::Op<CollectFpnProposalsOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.collect_fpn_proposals"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value multi_level_rois_, pir::Value multi_level_scores_, pir::Value multi_level_rois_num_, int post_nms_topn);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value multi_level_rois_, pir::Value multi_level_scores_, pir::Value multi_level_rois_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value multi_level_rois() { return operand_source(0); }
  pir::Value multi_level_scores() { return operand_source(1); }
  pir::Value multi_level_rois_num() { return operand_source(2); }
  pir::Value fpn_rois() { return result(0); }
  pir::Value rois_num() { return result(1); }

};

class  ComplexOp : public pir::Op<ComplexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.complex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value real_, pir::Value imag_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value real() { return operand_source(0); }
  pir::Value imag() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class TEST_API ConcatOp : public pir::Op<ConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ConjOp : public pir::Op<ConjOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conj"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API Conv2dOp : public pir::Op<Conv2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", const std::vector<int>& dilations={1, 1}, int groups=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Conv2dTransposeOp : public pir::Op<Conv2dTransposeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::vector<int64_t>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value output_size_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Conv2dTransposeBiasOp : public pir::Op<Conv2dTransposeBiasOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_bias"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::vector<int64_t>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, pir::Value output_size_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value output_size() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  Conv3dOp : public pir::Op<Conv3dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1, 1}, const std::string& data_format="NCDHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Conv3dTransposeOp : public pir::Op<Conv3dTransposeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_transpose"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, const std::vector<int>& output_padding={}, const std::vector<int>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1, 1}, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CopyToOp : public pir::Op<CopyToOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copy_to"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CopysignOp : public pir::Op<CopysignOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copysign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Copysign_Op : public pir::Op<Copysign_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copysign_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CorrelationOp : public pir::Op<CorrelationOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.correlation"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input1_, pir::Value input2_, int pad_size, int kernel_size, int max_displacement, int stride1, int stride2, int corr_type_multiply=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input1_, pir::Value input2_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input1() { return operand_source(0); }
  pir::Value input2() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CosOp : public pir::Op<CosOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Cos_Op : public pir::Op<Cos_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CoshOp : public pir::Op<CoshOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Cosh_Op : public pir::Op<Cosh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CrfDecodingOp : public pir::Op<CrfDecodingOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.crf_decoding"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value emission_, pir::Value transition_, pir::Value label_, pir::Value length_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value emission() { return operand_source(0); }
  pir::Value transition() { return operand_source(1); }
  pir::Value label() { return operand_source(2); }
  pir::Value length() { return operand_source(3); }
  pir::Value viterbi_path() { return result(0); }

};

class  CropOp : public pir::Op<CropOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.crop"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape={}, const std::vector<int64_t>& offsets={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_, pir::Value offsets_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value offsets() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  CrossOp : public pir::Op<CrossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=9);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CrossEntropyWithSoftmaxOp : public pir::Op<CrossEntropyWithSoftmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, bool soft_label=false, bool use_softmax=true, bool numeric_stable_mode=true, int ignore_index=-100, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return result(0); }
  pir::Value loss() { return result(1); }

};

class  CrossEntropyWithSoftmax_Op : public pir::Op<CrossEntropyWithSoftmax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, bool soft_label=false, bool use_softmax=true, bool numeric_stable_mode=true, int ignore_index=-100, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return result(0); }
  pir::Value loss() { return result(1); }

};

class  CtcAlignOp : public pir::Op<CtcAlignOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ctc_align"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_length_, int blank=0, bool merge_repeated=true, int padding_value=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_length_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value input_length() { return operand_source(1); }
  pir::Value output() { return result(0); }
  pir::Value output_length() { return result(1); }

};

class  CudnnLstmOp : public pir::Op<CudnnLstmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cudnn_lstm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value init_h_, pir::Value init_c_, pir::Value w_, pir::Value weight_list_, pir::Value sequence_length_, float dropout_prob=0.0, bool is_bidirec=false, int hidden_size=100, int num_layers=1, bool is_test=false, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value init_h_, pir::Value init_c_, pir::Value w_, pir::Value weight_list_, pir::Value sequence_length_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value init_h() { return operand_source(1); }
  pir::Value init_c() { return operand_source(2); }
  pir::Value w() { return operand_source(3); }
  pir::Value weight_list() { return operand_source(4); }
  pir::Value sequence_length() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value last_h() { return result(1); }
  pir::Value last_c() { return result(2); }
  pir::Value reserve() { return result(3); }
  pir::Value state_out() { return result(4); }

};

class TEST_API CummaxOp : public pir::Op<CummaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummax"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, phi::DataType dtype=phi::DataType::INT64);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  CumminOp : public pir::Op<CumminOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummin"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, phi::DataType dtype=phi::DataType::INT64);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  CumprodOp : public pir::Op<CumprodOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dim, bool exclusive=false, bool reverse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Cumprod_Op : public pir::Op<Cumprod_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dim, bool exclusive=false, bool reverse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CumsumOp : public pir::Op<CumsumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Cumsum_Op : public pir::Op<Cumsum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool flatten=false, bool exclusive=false, bool reverse=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CvmOp : public pir::Op<CvmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cvm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, bool use_cvm=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cvm() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DataOp : public pir::Op<DataOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.data"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::string& name, const std::vector<int64_t>& shape, phi::DataType dtype, const phi::Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  DecayedAdagradOp : public pir::Op<DecayedAdagradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.decayed_adagrad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, float decay=0.95f, float epsilon=1.0e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value moment() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }

};

class  DecodeJpegOp : public pir::Op<DecodeJpegOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.decode_jpeg"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& mode, const phi::Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DeformableConvOp : public pir::Op<DeformableConvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.deformable_conv"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations, int deformable_groups, int groups, int im2col_step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value offset() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value mask() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  DependOp : public pir::Op<DependOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depend"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dep_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value dep() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DepthwiseConv2dOp : public pir::Op<DepthwiseConv2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DepthwiseConv2dTransposeOp : public pir::Op<DepthwiseConv2dTransposeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_transpose"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::vector<int64_t>& output_size={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value output_size_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::vector<int>& output_padding={}, const std::string& padding_algorithm="EXPLICIT", int groups=1, const std::vector<int>& dilations={1, 1}, const std::string& data_format="NCHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  DequantizeAbsMaxOp : public pir::Op<DequantizeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_abs_max"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float max_range);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DequantizeLogOp : public pir::Op<DequantizeLogOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_log"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dict_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value dict() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DetOp : public pir::Op<DetOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.det"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};


class  DgcOp : public pir::Op<DgcOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dgc"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value u_, pir::Value v_, pir::Value grad_, pir::Value param_, pir::Value current_step_, pir::Value nranks_, float m=0.9, bool use_nesterov=true, const std::vector<float>& sparsity={}, float rampup_begin_step=0.0, float rampup_step=0.0, float regular_coeff=0.0, int regular_type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value u_, pir::Value v_, pir::Value grad_, pir::Value param_, pir::Value current_step_, pir::Value nranks_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value u() { return operand_source(0); }
  pir::Value v() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value param() { return operand_source(3); }
  pir::Value current_step() { return operand_source(4); }
  pir::Value nranks() { return operand_source(5); }
  pir::Value u_out() { return result(0); }
  pir::Value v_out() { return result(1); }
  pir::Value encode_grad() { return result(2); }
  pir::Value grad_out() { return result(3); }
  pir::Value k() { return result(4); }
  pir::Value gather_buff() { return result(5); }

};

class  DgcClipByNormOp : public pir::Op<DgcClipByNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dgc_clip_by_norm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value current_step_, float max_norm, float rampup_begin_step=-1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value current_step_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value current_step() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DgcClipByNormSrOp : public pir::Op<DgcClipByNormSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dgc_clip_by_norm_sr"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value current_step_, float max_norm, float rampup_begin_step=-1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value current_step_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value current_step() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DgcMomentumOp : public pir::Op<DgcMomentumOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dgc_momentum"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::Value current_step_tensor_, pir::Value nranks_tensor_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f, float rampup_begin_step=-1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::Value current_step_tensor_, pir::Value nranks_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value current_step_tensor() { return operand_source(5); }
  pir::Value nranks_tensor() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }
  pir::Value grad_out() { return result(3); }

};

class  DiagOp : public pir::Op<DiagOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, float padding_value=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DiagEmbedOp : public pir::Op<DiagEmbedOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag_embed"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int offset=0, int dim1=-2, int dim2=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DiagonalOp : public pir::Op<DiagonalOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diagonal"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DigammaOp : public pir::Op<DigammaOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Digamma_Op : public pir::Op<Digamma_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DirichletOp : public pir::Op<DirichletOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dirichlet"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value alpha_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value alpha() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DisableCheckModelNanInfOp : public pir::Op<DisableCheckModelNanInfOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.disable_check_model_nan_inf"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int flag=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DistOp : public pir::Op<DistOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dist"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float p=2.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DotOp : public pir::Op<DotOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DpsgdOp : public pir::Op<DpsgdOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dpsgd"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, float clip=10.0f, float batch_size=16.0f, float sigma=1.0f, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value param_out() { return result(0); }

};

class  DropoutOp : public pir::Op<DropoutOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::SideEffectTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dropout"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_tensor_, float p=0.5f, bool is_test=false, const std::string& mode="downgrade_in_infer", int seed=0, bool fix_seed=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_tensor_, pir::Value p_, bool is_test=false, const std::string& mode="downgrade_in_infer", int seed=0, bool fix_seed=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value seed_tensor() { return operand_source(1); }
  pir::Value p() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value mask() { return result(1); }

};

class  EditDistanceOp : public pir::Op<EditDistanceOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.edit_distance"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hyps_, pir::Value refs_, pir::Value hypslength_, pir::Value refslength_, bool normalized=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hyps_, pir::Value refs_, pir::Value hypslength_, pir::Value refslength_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value hyps() { return operand_source(0); }
  pir::Value refs() { return operand_source(1); }
  pir::Value hypslength() { return operand_source(2); }
  pir::Value refslength() { return operand_source(3); }
  pir::Value sequencenum() { return result(0); }
  pir::Value out() { return result(1); }

};

class  EigOp : public pir::Op<EigOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eig"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_w() { return result(0); }
  pir::Value out_v() { return result(1); }

};

class  EighOp : public pir::Op<EighOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigh"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& UPLO="L");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_w() { return result(0); }
  pir::Value out_v() { return result(1); }

};

class  EigvalsOp : public pir::Op<EigvalsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvals"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EigvalshOp : public pir::Op<EigvalshOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvalsh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& uplo="L", bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value eigenvalues() { return result(0); }
  pir::Value eigenvectors() { return result(1); }

};

class  EluOp : public pir::Op<EluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Elu_Op : public pir::Op<Elu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EmbeddingWithScaledGradientOp : public pir::Op<EmbeddingWithScaledGradientOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_with_scaled_gradient"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  EmptyOp : public pir::Op<EmptyOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.empty"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value shape() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EmptyLikeOp : public pir::Op<EmptyLikeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.empty_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EnableCheckModelNanInfOp : public pir::Op<EnableCheckModelNanInfOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.enable_check_model_nan_inf"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int flag=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EqualAllOp : public pir::Op<EqualAllOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal_all"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ErfOp : public pir::Op<ErfOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Erf_Op : public pir::Op<Erf_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ErfinvOp : public pir::Op<ErfinvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Erfinv_Op : public pir::Op<Erfinv_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ExpOp : public pir::Op<ExpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Exp_Op : public pir::Op<Exp_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ExpandAsOp : public pir::Op<ExpandAsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_as"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<int64_t>& target_shape={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ExpandModalityExpertIdOp : public pir::Op<ExpandModalityExpertIdOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_modality_expert_id"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_id_, int64_t num_expert_per_modality, int64_t group_size, int64_t modality_offset, bool is_group_expert);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_id_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value expert_id() { return operand_source(0); }
  pir::Value expert_id_out() { return result(0); }

};

class  Expm1Op : public pir::Op<Expm1Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Expm1_Op : public pir::Op<Expm1_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Exponential_Op : public pir::Op<Exponential_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exponential_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lam);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  EyeOp : public pir::Op<EyeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eye"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, float num_rows, float num_columns, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value num_rows_, pir::Value num_columns_, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value num_rows() { return operand_source(0); }
  pir::Value num_columns() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FakeChannelWiseDequantizeMaxAbsOp : public pir::Op<FakeChannelWiseDequantizeMaxAbsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_channel_wise_dequantize_max_abs"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scales_, const std::vector<int>& quant_bits={8}, int quant_axis=0, int x_num_col_dims=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scales_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scales() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FakeChannelWiseQuantizeAbsMaxOp : public pir::Op<FakeChannelWiseQuantizeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_channel_wise_quantize_abs_max"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int bit_length=8, int round_type=1, int quant_axis=0, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }

};

class  FakeChannelWiseQuantizeDequantizeAbsMaxOp : public pir::Op<FakeChannelWiseQuantizeDequantizeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_channel_wise_quantize_dequantize_abs_max"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int bit_length=8, int round_type=1, int quant_axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }

};

class  FakeDequantizeMaxAbsOp : public pir::Op<FakeDequantizeMaxAbsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_dequantize_max_abs"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float max_range);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FakeQuantizeAbsMaxOp : public pir::Op<FakeQuantizeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_abs_max"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int bit_length=8, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }

};

class  FakeQuantizeDequantizeAbsMaxOp : public pir::Op<FakeQuantizeDequantizeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_dequantize_abs_max"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int bit_length=8, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }

};

class  FakeQuantizeDequantizeMovingAverageAbsMaxOp : public pir::Op<FakeQuantizeDequantizeMovingAverageAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_dequantize_moving_average_abs_max"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value in_accum() { return operand_source(2); }
  pir::Value in_state() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  FakeQuantizeDequantizeMovingAverageAbsMax_Op : public pir::Op<FakeQuantizeDequantizeMovingAverageAbsMax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_dequantize_moving_average_abs_max_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value in_accum() { return operand_source(2); }
  pir::Value in_state() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  FakeQuantizeMovingAverageAbsMaxOp : public pir::Op<FakeQuantizeMovingAverageAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_moving_average_abs_max"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value in_accum() { return operand_source(2); }
  pir::Value in_state() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  FakeQuantizeMovingAverageAbsMax_Op : public pir::Op<FakeQuantizeMovingAverageAbsMax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_moving_average_abs_max_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value in_accum() { return operand_source(2); }
  pir::Value in_state() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  FakeQuantizeRangeAbsMaxOp : public pir::Op<FakeQuantizeRangeAbsMaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_range_abs_max"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value iter_, int window_size=10000, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value iter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value iter() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_scales() { return result(2); }

};

class  FakeQuantizeRangeAbsMax_Op : public pir::Op<FakeQuantizeRangeAbsMax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_range_abs_max_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value iter_, int window_size=10000, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_scale_, pir::Value iter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_scale() { return operand_source(1); }
  pir::Value iter() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_scales() { return result(2); }

};

class  FftC2cOp : public pir::Op<FftC2cOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2c"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FftC2rOp : public pir::Op<FftC2rOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2r"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, int64_t last_dim_size=0L);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FftR2cOp : public pir::Op<FftR2cOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_r2c"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FillOp : public pir::Op<FillOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Fill_Op : public pir::Op<Fill_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FillDiagonalOp : public pir::Op<FillDiagonalOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0, int offset=0, bool wrap=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FillDiagonal_Op : public pir::Op<FillDiagonal_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value=0, int offset=0, bool wrap=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FillDiagonalTensorOp : public pir::Op<FillDiagonalTensorOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int64_t offset=0, int dim1=0, int dim2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FillDiagonalTensor_Op : public pir::Op<FillDiagonalTensor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int64_t offset=0, int dim1=0, int dim2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FlashAttnOp : public pir::Op<FlashAttnOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value fixed_seed_offset() { return operand_source(3); }
  pir::Value attn_mask() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }
  pir::Value softmax_lse() { return result(2); }
  pir::Value seed_offset() { return result(3); }

};

class  FlashAttnQkvpackedOp : public pir::Op<FlashAttnQkvpackedOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_qkvpacked"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value fixed_seed_offset() { return operand_source(1); }
  pir::Value attn_mask() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }
  pir::Value softmax_lse() { return result(2); }
  pir::Value seed_offset() { return result(3); }

};

class  FlashAttnUnpaddedOp : public pir::Op<FlashAttnUnpaddedOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_unpadded"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, float scale, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value cu_seqlens_q() { return operand_source(3); }
  pir::Value cu_seqlens_k() { return operand_source(4); }
  pir::Value fixed_seed_offset() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::Value max_seqlen_q() { return operand_source(7); }
  pir::Value max_seqlen_k() { return operand_source(8); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }
  pir::Value softmax_lse() { return result(2); }
  pir::Value seed_offset() { return result(3); }

};

class  FlashAttnV3Op : public pir::Op<FlashAttnV3Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_v3"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_v__, pir::Value q_descale__, pir::Value k_descale__, pir::Value v_descale__, float softmax_scale, bool is_causal, int window_size_left, int window_size_right, float softcap, int num_splits, bool manual_set_pack_gqa, bool pack_gqa_, int sm_margin);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_v__, pir::Value q_descale__, pir::Value k_descale__, pir::Value v_descale__, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value q_v_() { return operand_source(3); }
  pir::Value q_descale_() { return operand_source(4); }
  pir::Value k_descale_() { return operand_source(5); }
  pir::Value v_descale_() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value softmax_lse() { return result(1); }

};

class  FlashAttnV3VarlenOp : public pir::Op<FlashAttnV3VarlenOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_v3_varlen"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value q_v__, pir::Value q_descale__, pir::Value k_descale__, pir::Value v_descale__, float softmax_scale, bool is_causal, int window_size_left, int window_size_right, float softcap, int num_splits, bool manual_set_pack_gqa, bool pack_gqa_, int sm_margin, int max_seqlen_q, int max_seqlen_k);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value q_v__, pir::Value q_descale__, pir::Value k_descale__, pir::Value v_descale__, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value cu_seqlens_q() { return operand_source(3); }
  pir::Value cu_seqlens_k() { return operand_source(4); }
  pir::Value q_v_() { return operand_source(5); }
  pir::Value q_descale_() { return operand_source(6); }
  pir::Value k_descale_() { return operand_source(7); }
  pir::Value v_descale_() { return operand_source(8); }
  pir::Value out() { return result(0); }
  pir::Value softmax_lse() { return result(1); }

};

class  FlashAttnVarlenQkvpackedOp : public pir::Op<FlashAttnVarlenQkvpackedOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_varlen_qkvpacked"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="", bool varlen_padded=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, float scale, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="", bool varlen_padded=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value fixed_seed_offset_, pir::Value attn_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value cu_seqlens_q() { return operand_source(1); }
  pir::Value cu_seqlens_k() { return operand_source(2); }
  pir::Value fixed_seed_offset() { return operand_source(3); }
  pir::Value attn_mask() { return operand_source(4); }
  pir::Value max_seqlen_q() { return operand_source(5); }
  pir::Value max_seqlen_k() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }
  pir::Value softmax_lse() { return result(2); }
  pir::Value seed_offset() { return result(3); }

};

class  FlashmaskAttentionOp : public pir::Op<FlashmaskAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flashmask_attention"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value startend_row_indices_, pir::Value fixed_seed_offset_, float dropout=0.0, bool causal=false, bool return_softmax=false, bool is_test=false, const std::string& rng_name="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value startend_row_indices_, pir::Value fixed_seed_offset_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value startend_row_indices() { return operand_source(3); }
  pir::Value fixed_seed_offset() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }
  pir::Value softmax_lse() { return result(2); }
  pir::Value seed_offset() { return result(3); }

};

class  FlattenOp : public pir::Op<FlattenOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_axis=1, int stop_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Flatten_Op : public pir::Op<Flatten_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_axis=1, int stop_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FlipOp : public pir::Op<FlipOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flip"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FloorOp : public pir::Op<FloorOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Floor_Op : public pir::Op<Floor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FmaxOp : public pir::Op<FmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmax"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FminOp : public pir::Op<FminOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FoldOp : public pir::Op<FoldOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fold"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& output_sizes, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FractionalMaxPool2dOp : public pir::Op<FractionalMaxPool2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fractional_max_pool2d"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& output_size, const std::vector<int>& kernel_size={0, 0}, float random_u=0.0, bool return_mask=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value mask() { return result(1); }

};

class  FractionalMaxPool3dOp : public pir::Op<FractionalMaxPool3dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fractional_max_pool3d"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& output_size, const std::vector<int>& kernel_size={0, 0, 0}, float random_u=0.0, bool return_mask=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value mask() { return result(1); }

};

class  FrameOp : public pir::Op<FrameOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frame"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int frame_length, int hop_length, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FrobeniusNormOp : public pir::Op<FrobeniusNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frobenius_norm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FtrlOp : public pir::Op<FtrlOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ftrl"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, float l1=0.0f, float l2=0.0f, float lr_power=-0.5f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value squared_accumulator() { return operand_source(1); }
  pir::Value linear_accumulator() { return operand_source(2); }
  pir::Value grad() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value squared_accum_out() { return result(1); }
  pir::Value linear_accum_out() { return result(2); }

};

class  FtrlSrOp : public pir::Op<FtrlSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ftrl_sr"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, float l1=0.0f, float l2=0.0f, float lr_power=-0.5f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value squared_accumulator_, pir::Value linear_accumulator_, pir::Value grad_, pir::Value learning_rate_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value squared_accumulator() { return operand_source(1); }
  pir::Value linear_accumulator() { return operand_source(2); }
  pir::Value grad() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value squared_accum_out() { return result(1); }
  pir::Value linear_accum_out() { return result(2); }

};

class TEST_API FullOp : public pir::Op<FullOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, double value, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  Full_Op : public pir::Op<Full_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, const std::vector<int64_t>& shape, double value, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value output_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value output() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FullBatchSizeLikeOp : public pir::Op<FullBatchSizeLikeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_batch_size_like"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int>& shape, phi::DataType dtype, double value, int input_dim_idx, int output_dim_idx, const phi::Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API FullIntArrayOp : public pir::Op<FullIntArrayOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_int_array"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& value, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  FullLikeOp : public pir::Op<FullLikeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value, phi::DataType dtype=phi::DataType::UNDEFINED, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value value_, phi::DataType dtype=phi::DataType::UNDEFINED, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FullWithTensorOp : public pir::Op<FullWithTensorOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_with_tensor"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value value_, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value value_, pir::Value shape_, phi::DataType dtype=phi::DataType::FLOAT32);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value value() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedBatchNormActOp : public pir::Op<FusedBatchNormActOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  FusedBatchNormAct_Op : public pir::Op<FusedBatchNormAct_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  FusedBnAddActivationOp : public pir::Op<FusedBnAddActivationOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value z() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  FusedBnAddActivation_Op : public pir::Op<FusedBnAddActivation_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value z_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value z() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  FusedSoftmaxMaskOp : public pir::Op<FusedSoftmaxMaskOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedSoftmaxMaskUpperTriangleOp : public pir::Op<FusedSoftmaxMaskUpperTriangleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask_upper_triangle"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value X_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value X() { return operand_source(0); }
  pir::Value Out() { return result(0); }

};

class  GammainccOp : public pir::Op<GammainccOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaincc"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Gammaincc_Op : public pir::Op<Gammaincc_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaincc_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GammalnOp : public pir::Op<GammalnOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Gammaln_Op : public pir::Op<Gammaln_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GatherOp : public pir::Op<GatherOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  GatherNdOp : public pir::Op<GatherNdOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_nd"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GatherTreeOp : public pir::Op<GatherTreeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_tree"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value parents_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value ids() { return operand_source(0); }
  pir::Value parents() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GaussianOp : public pir::Op<GaussianOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, float mean, float std, int seed, phi::DataType dtype, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, float mean, float std, int seed, phi::DataType dtype, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value shape() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GaussianInplaceOp : public pir::Op<GaussianInplaceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GaussianInplace_Op : public pir::Op<GaussianInplace_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API GeluOp : public pir::Op<GeluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gelu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool approximate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GenerateProposalsOp : public pir::Op<GenerateProposalsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.generate_proposals"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value scores_, pir::Value bbox_deltas_, pir::Value im_shape_, pir::Value anchors_, pir::Value variances_, int pre_nms_top_n, int post_nms_top_n, float nms_thresh, float min_size, float eta, bool pixel_offset=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value scores_, pir::Value bbox_deltas_, pir::Value im_shape_, pir::Value anchors_, pir::Value variances_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value scores() { return operand_source(0); }
  pir::Value bbox_deltas() { return operand_source(1); }
  pir::Value im_shape() { return operand_source(2); }
  pir::Value anchors() { return operand_source(3); }
  pir::Value variances() { return operand_source(4); }
  pir::Value rpn_rois() { return result(0); }
  pir::Value rpn_roi_probs() { return result(1); }
  pir::Value rpn_rois_num() { return result(2); }

};

class  GlobalGatherOp : public pir::Op<GlobalGatherOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.global_gather"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value local_count_, pir::Value global_count_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value local_count_, pir::Value global_count_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value local_count() { return operand_source(1); }
  pir::Value global_count() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  GlobalScatterOp : public pir::Op<GlobalScatterOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.global_scatter"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value local_count_, pir::Value global_count_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value local_count_, pir::Value global_count_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value local_count() { return operand_source(1); }
  pir::Value global_count() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  GraphKhopSamplerOp : public pir::Op<GraphKhopSamplerOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.graph_khop_sampler"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value x_, pir::Value eids_, const std::vector<int>& sample_sizes, bool return_eids);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value x_, pir::Value eids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value row() { return operand_source(0); }
  pir::Value colptr() { return operand_source(1); }
  pir::Value x() { return operand_source(2); }
  pir::Value eids() { return operand_source(3); }
  pir::Value out_src() { return result(0); }
  pir::Value out_dst() { return result(1); }
  pir::Value sample_index() { return result(2); }
  pir::Value reindex_x() { return result(3); }
  pir::Value out_eids() { return result(4); }

};

class  GraphSampleNeighborsOp : public pir::Op<GraphSampleNeighborsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.graph_sample_neighbors"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value x_, pir::Value eids_, pir::Value perm_buffer_, int sample_size, bool return_eids, bool flag_perm_buffer);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value x_, pir::Value eids_, pir::Value perm_buffer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value row() { return operand_source(0); }
  pir::Value colptr() { return operand_source(1); }
  pir::Value x() { return operand_source(2); }
  pir::Value eids() { return operand_source(3); }
  pir::Value perm_buffer() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value out_count() { return result(1); }
  pir::Value out_eids() { return result(2); }

};

class  GridSampleOp : public pir::Op<GridSampleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.grid_sample"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, const std::string& mode="bilinear", const std::string& padding_mode="zeros", bool align_corners=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grid() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GroupNormOp : public pir::Op<GroupNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5, int groups=-1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return result(0); }
  pir::Value mean() { return result(1); }
  pir::Value variance() { return result(2); }

};

class  GruOp : public pir::Op<GruOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gru"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value weight_, pir::Value bias_, const std::string& activation="tanh", const std::string& gate_activation="sigmoid", bool is_reverse=false, bool origin_mode=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value weight_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value batch_gate() { return result(0); }
  pir::Value batch_reset_hidden_prev() { return result(1); }
  pir::Value batch_hidden() { return result(2); }
  pir::Value hidden() { return result(3); }

};

class  GruUnitOp : public pir::Op<GruUnitOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gru_unit"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value hidden_prev_, pir::Value weight_, pir::Value bias_, int activation=2, int gate_activation=1, bool origin_mode=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value hidden_prev_, pir::Value weight_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value hidden_prev() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value gate() { return result(0); }
  pir::Value reset_hidden_prev() { return result(1); }
  pir::Value hidden() { return result(2); }

};

class  GumbelSoftmaxOp : public pir::Op<GumbelSoftmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gumbel_softmax"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float temperature=1.0, bool hard=false, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  HardshrinkOp : public pir::Op<HardshrinkOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  HardsigmoidOp : public pir::Op<HardsigmoidOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float slope=0.2, float offset=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  HardtanhOp : public pir::Op<HardtanhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float t_min=0, float t_max=24);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Hardtanh_Op : public pir::Op<Hardtanh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float t_min=0, float t_max=24);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  HeavisideOp : public pir::Op<HeavisideOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.heaviside"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  HingeLossOp : public pir::Op<HingeLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hinge_loss"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value labels_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value labels() { return operand_source(1); }
  pir::Value loss() { return result(0); }

};

class  HistogramOp : public pir::Op<HistogramOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.histogram"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value weight_, int64_t bins=100, float min=0.0, float max=0.0, bool density=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  HsigmoidLossOp : public pir::Op<HsigmoidLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hsigmoid_loss"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value w_, pir::Value bias_, pir::Value path_, pir::Value code_, int num_classes, bool is_sparse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value w_, pir::Value bias_, pir::Value path_, pir::Value code_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value path() { return operand_source(4); }
  pir::Value code() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value pre_out() { return result(1); }
  pir::Value w_out() { return result(2); }

};

class  HuberLossOp : public pir::Op<HuberLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.huber_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, float delta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value residual() { return result(1); }

};

class  I0Op : public pir::Op<I0Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  I0_Op : public pir::Op<I0_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  I0eOp : public pir::Op<I0eOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0e"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  I1Op : public pir::Op<I1Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  I1eOp : public pir::Op<I1eOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1e"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IdentityLossOp : public pir::Op<IdentityLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int reduction=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IdentityLoss_Op : public pir::Op<IdentityLoss_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int reduction=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Im2sequenceOp : public pir::Op<Im2sequenceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.im2sequence"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<int>& kernels, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0, 0, 0}, const std::vector<int>& out_stride={1, 1});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ImagOp : public pir::Op<ImagOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.imag"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IndexAddOp : public pir::Op<IndexAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value add_value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexAdd_Op : public pir::Op<IndexAdd_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value add_value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value add_value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexElementwiseGetOp : public pir::Op<IndexElementwiseGetOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_elementwise_get"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, const std::vector<int64_t>& input_dims, const std::vector<int64_t>& input_strides, const std::vector<int64_t>& index_dims, const std::vector<int64_t>& index_stride);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  IndexElementwisePutOp : public pir::Op<IndexElementwisePutOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_elementwise_put"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, const std::vector<int64_t>& input_dims, const std::vector<int64_t>& input_strides, const std::vector<int64_t>& index_dims, const std::vector<int64_t>& index_strides, int64_t slice_offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexElementwisePut_Op : public pir::Op<IndexElementwisePut_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_elementwise_put_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, const std::vector<int64_t>& input_dims, const std::vector<int64_t>& input_strides, const std::vector<int64_t>& index_dims, const std::vector<int64_t>& index_strides, int64_t slice_offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexPutOp : public pir::Op<IndexPutOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexPut_Op : public pir::Op<IndexPut_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  IndexSampleOp : public pir::Op<IndexSampleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_sample"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  IndexSelectOp : public pir::Op<IndexSelectOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  IndexSelectStridedOp : public pir::Op<IndexSelectStridedOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_strided"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t index, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  InstanceNormOp : public pir::Op<InstanceNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return result(0); }
  pir::Value saved_mean() { return result(1); }
  pir::Value saved_variance() { return result(2); }

};

class  InverseOp : public pir::Op<InverseOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.inverse"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsEmptyOp : public pir::Op<IsEmptyOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.is_empty"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IscloseOp : public pir::Op<IscloseOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isclose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, double rtol=1e-5, double atol=1e-8, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rtol_, pir::Value atol_, bool equal_nan=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rtol() { return operand_source(2); }
  pir::Value atol() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  IsfiniteOp : public pir::Op<IsfiniteOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isfinite"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsfiniteSrOp : public pir::Op<IsfiniteSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isfinite_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsinfOp : public pir::Op<IsinfOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isinf"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsinfSrOp : public pir::Op<IsinfSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isinf_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsnanOp : public pir::Op<IsnanOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsnanSrOp : public pir::Op<IsnanSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  KldivLossOp : public pir::Op<KldivLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kldiv_loss"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, const std::string& reduction="mean", bool log_target=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out() { return result(0); }

};


class  KronOp : public pir::Op<KronOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kron"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  KthvalueOp : public pir::Op<KthvalueOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kthvalue"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int k=1, int axis=-1, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  L1NormOp : public pir::Op<L1NormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.l1_norm"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  L1Norm_Op : public pir::Op<L1Norm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.l1_norm_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LabelSmoothOp : public pir::Op<LabelSmoothOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.label_smooth"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value prior_dist_, float epsilon=0.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value prior_dist_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value label() { return operand_source(0); }
  pir::Value prior_dist() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Lamb_Op : public pir::Op<Lamb_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lamb_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float weight_decay, float beta1=0.9, float beta2=0.999, float epsilon=1.0e-6f, bool always_adapt=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value beta1_pow_out() { return result(3); }
  pir::Value beta2_pow_out() { return result(4); }
  pir::Value master_param_outs() { return result(5); }

};

class  LambSr_Op : public pir::Op<LambSr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lamb_sr_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, float weight_decay, float beta1=0.9, float beta2=0.999, float epsilon=1.0e-6f, bool always_adapt=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value beta1_pow() { return operand_source(5); }
  pir::Value beta2_pow() { return operand_source(6); }
  pir::Value master_param() { return operand_source(7); }
  pir::Value skip_update() { return operand_source(8); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value beta1_pow_out() { return result(3); }
  pir::Value beta2_pow_out() { return result(4); }
  pir::Value master_param_outs() { return result(5); }

};

class TEST_API LayerNormOp : public pir::Op<LayerNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value mean() { return result(1); }
  pir::Value variance() { return result(2); }

};

class  LeakyReluOp : public pir::Op<LeakyReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float negative_slope=0.02f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LeakyRelu_Op : public pir::Op<LeakyRelu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float negative_slope=0.02f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LerpOp : public pir::Op<LerpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Lerp_Op : public pir::Op<Lerp_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  LgammaOp : public pir::Op<LgammaOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Lgamma_Op : public pir::Op<Lgamma_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LimitByCapacityOp : public pir::Op<LimitByCapacityOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.limit_by_capacity"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_count_, pir::Value capacity_, int n_worker);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value expert_count_, pir::Value capacity_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value expert_count() { return operand_source(0); }
  pir::Value capacity() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LinearInterpOp : public pir::Op<LinearInterpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_format="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output() { return result(0); }

};

class  LinspaceOp : public pir::Op<LinspaceOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linspace"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value number_, phi::DataType dtype, const phi::Place& place);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value number_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value start() { return operand_source(0); }
  pir::Value stop() { return operand_source(1); }
  pir::Value number() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  LlmInt8LinearOp : public pir::Op<LlmInt8LinearOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.llm_int8_linear"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, float threshold=6.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  LogOp : public pir::Op<LogOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log_Op : public pir::Op<Log_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log10Op : public pir::Op<Log10Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log10_Op : public pir::Op<Log10_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log1pOp : public pir::Op<Log1pOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log1p_Op : public pir::Op<Log1p_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log2Op : public pir::Op<Log2Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log2_Op : public pir::Op<Log2_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogLossOp : public pir::Op<LogLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_loss"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogSoftmaxOp : public pir::Op<LogSoftmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_softmax"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogcumsumexpOp : public pir::Op<LogcumsumexpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logcumsumexp"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool flatten=false, bool exclusive=false, bool reverse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogicalAndOp : public pir::Op<LogicalAndOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_and"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogicalAnd_Op : public pir::Op<LogicalAnd_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_and_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogicalNotOp : public pir::Op<LogicalNotOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_not"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogicalNot_Op : public pir::Op<LogicalNot_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_not_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogicalOrOp : public pir::Op<LogicalOrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_or"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogicalOr_Op : public pir::Op<LogicalOr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_or_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogicalXorOp : public pir::Op<LogicalXorOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_xor"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogicalXor_Op : public pir::Op<LogicalXor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logical_xor_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LogitOp : public pir::Op<LogitOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float eps=1e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Logit_Op : public pir::Op<Logit_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float eps=1e-6f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogsigmoidOp : public pir::Op<LogsigmoidOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LogspaceOp : public pir::Op<LogspaceOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logspace"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value num_, pir::Value base_, phi::DataType dtype, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value stop_, pir::Value num_, pir::Value base_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value start() { return operand_source(0); }
  pir::Value stop() { return operand_source(1); }
  pir::Value num() { return operand_source(2); }
  pir::Value base() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  LogsumexpOp : public pir::Op<LogsumexpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsumexp"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& axis={0}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LookupTableDequantOp : public pir::Op<LookupTableDequantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_dequant"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LpPool2dOp : public pir::Op<LpPool2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lp_pool2d"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides={1,1}, const std::vector<int64_t>& paddings={0,0}, bool ceil_mode=false, bool exclusive=true, const std::string& data_format="NCHW", const std::string& pooling_type="", bool global_pooling=false, bool adaptive=false, const std::string& padding_algorithm="EXPLICIT", float norm_type=0.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LstmOp : public pir::Op<LstmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lstm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value c0_, pir::Value weight_, pir::Value bias_, bool use_peepholes=true, bool is_reverse=false, bool is_test=false, const std::string& gate_activation="sigmoid", const std::string& cell_activation="tanh", const std::string& candidate_activation="tanh");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value c0_, pir::Value weight_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value c0() { return operand_source(2); }
  pir::Value weight() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value hidden() { return result(0); }
  pir::Value cell() { return result(1); }
  pir::Value batch_gate() { return result(2); }
  pir::Value batch_cell_pre_act() { return result(3); }

};

class  LstsqOp : public pir::Op<LstsqOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lstsq"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float rcond=0.0f, const std::string& driver="gels");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value rcond_, const std::string& driver="gels");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value rcond() { return operand_source(2); }
  pir::Value solution() { return result(0); }
  pir::Value residuals() { return result(1); }
  pir::Value rank() { return result(2); }
  pir::Value singular_values() { return result(3); }

};

class  LuOp : public pir::Op<LuOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool pivot=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value pivots() { return result(1); }
  pir::Value infos() { return result(2); }

};

class  Lu_Op : public pir::Op<Lu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool pivot=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value pivots() { return result(1); }
  pir::Value infos() { return result(2); }

};

class  LuSolveOp : public pir::Op<LuSolveOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_solve"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value b_, pir::Value lu_, pir::Value pivots_, const std::string& trans);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value b_, pir::Value lu_, pir::Value pivots_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value b() { return operand_source(0); }
  pir::Value lu() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  LuUnpackOp : public pir::Op<LuUnpackOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_unpack"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool unpack_ludata=true, bool unpack_pivots=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value pmat() { return result(0); }
  pir::Value l() { return result(1); }
  pir::Value u() { return result(2); }

};

class  MarginCrossEntropyOp : public pir::Op<MarginCrossEntropyOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, bool return_softmax=false, int ring_id=0, int rank=0, int nranks=1, float margin1=1.0f, float margin2=0.5f, float margin3=0.0f, float scale=64.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return result(0); }
  pir::Value loss() { return result(1); }

};

class  MaskedFillOp : public pir::Op<MaskedFillOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_fill"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value value_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  MaskedFill_Op : public pir::Op<MaskedFill_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_fill_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value value_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  MaskedMultiheadAttention_Op : public pir::Op<MaskedMultiheadAttention_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_multihead_attention_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cache_kv_, pir::Value bias_, pir::Value src_mask_, pir::Value cum_offsets_, pir::Value sequence_lengths_, pir::Value rotary_tensor_, pir::Value beam_cache_offset_, pir::Value qkv_out_scale_, pir::Value out_shift_, pir::Value out_smooth_, int seq_len, int rotary_emb_dims, bool use_neox_rotary_style=false, const std::string& compute_dtype="default", float out_scale=-1, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cache_kv_, pir::Value bias_, pir::Value src_mask_, pir::Value cum_offsets_, pir::Value sequence_lengths_, pir::Value rotary_tensor_, pir::Value beam_cache_offset_, pir::Value qkv_out_scale_, pir::Value out_shift_, pir::Value out_smooth_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cache_kv() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value src_mask() { return operand_source(3); }
  pir::Value cum_offsets() { return operand_source(4); }
  pir::Value sequence_lengths() { return operand_source(5); }
  pir::Value rotary_tensor() { return operand_source(6); }
  pir::Value beam_cache_offset() { return operand_source(7); }
  pir::Value qkv_out_scale() { return operand_source(8); }
  pir::Value out_shift() { return operand_source(9); }
  pir::Value out_smooth() { return operand_source(10); }
  pir::Value out() { return result(0); }
  pir::Value cache_kv_out() { return result(1); }
  pir::Value beam_cache_offset_out() { return result(2); }

};

class  MaskedSelectOp : public pir::Op<MaskedSelectOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_select"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MatchMatrixTensorOp : public pir::Op<MatchMatrixTensorOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.match_matrix_tensor"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, int dim_t=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value tmp() { return result(1); }

};

class  MatrixNmsOp : public pir::Op<MatrixNmsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_nms"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, float score_threshold, int nms_top_k, int keep_top_k, float post_threshold=0., bool use_gaussian=false, float gaussian_sigma=2., int background_label=0, bool normalized=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value bboxes() { return operand_source(0); }
  pir::Value scores() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value index() { return result(1); }
  pir::Value roisnum() { return result(2); }

};

class  MatrixPowerOp : public pir::Op<MatrixPowerOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_power"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MatrixRankOp : public pir::Op<MatrixRankOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_rank"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float tol, bool use_default_tol=true, bool hermitian=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MatrixRankAtolRtolOp : public pir::Op<MatrixRankAtolRtolOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_rank_atol_rtol"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_, pir::Value rtol_, bool hermitian=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_, pir::Value rtol_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value atol() { return operand_source(1); }
  pir::Value rtol() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  MatrixRankTolOp : public pir::Op<MatrixRankTolOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_rank_tol"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_tensor_, bool use_default_tol=true, bool hermitian=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value atol_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value atol_tensor() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaxOp : public pir::Op<MaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaxPool2dWithIndexOp : public pir::Op<MaxPool2dWithIndexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_with_index"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, bool global_pooling=false, bool adaptive=false, bool ceil_mode=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value mask() { return result(1); }

};

class  MaxPool3dWithIndexOp : public pir::Op<MaxPool3dWithIndexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool3d_with_index"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1, 1}, const std::vector<int>& paddings={0, 0, 0}, bool global_pooling=false, bool adaptive=false, bool ceil_mode=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value mask() { return result(1); }

};

class  MaxoutOp : public pir::Op<MaxoutOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxout"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int groups, int axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MeanOp : public pir::Op<MeanOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MeanAllOp : public pir::Op<MeanAllOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_all"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MemcpyD2hOp : public pir::Op<MemcpyD2hOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy_d2h"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MemcpyH2dOp : public pir::Op<MemcpyH2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy_h2d"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MemoryEfficientAttentionOp : public pir::Op<MemoryEfficientAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memory_efficient_attention"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value causal_diagonal_, pir::Value seqlen_k_, int64_t max_seqlen_q, int64_t max_seqlen_k, bool causal, double dropout_p, float scale, bool is_test);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value causal_diagonal_, pir::Value seqlen_k_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, bool causal, double dropout_p, float scale, bool is_test);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value causal_diagonal_, pir::Value seqlen_k_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlens_q() { return operand_source(4); }
  pir::Value cu_seqlens_k() { return operand_source(5); }
  pir::Value causal_diagonal() { return operand_source(6); }
  pir::Value seqlen_k() { return operand_source(7); }
  pir::Value max_seqlen_q() { return operand_source(8); }
  pir::Value max_seqlen_k() { return operand_source(9); }
  pir::Value output() { return result(0); }
  pir::Value logsumexp() { return result(1); }
  pir::Value seed_and_offset() { return result(2); }

};

class  MergeSelectedRowsOp : public pir::Op<MergeSelectedRowsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merge_selected_rows"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MergedAdam_Op : public pir::Op<MergedAdam_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merged_adam_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::Value beta1_, pir::Value beta2_, pir::Value epsilon_, bool multi_precision=false, bool use_global_beta_pow=false, bool amsgrad=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value moment1_, pir::Value moment2_, pir::Value moment2_max_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moment1() { return operand_source(3); }
  pir::Value moment2() { return operand_source(4); }
  pir::Value moment2_max() { return operand_source(5); }
  pir::Value beta1_pow() { return operand_source(6); }
  pir::Value beta2_pow() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value beta1() { return operand_source(9); }
  pir::Value beta2() { return operand_source(10); }
  pir::Value epsilon() { return operand_source(11); }
  pir::Value param_out() { return result(0); }
  pir::Value moment1_out() { return result(1); }
  pir::Value moment2_out() { return result(2); }
  pir::Value moment2_max_out() { return result(3); }
  pir::Value beta1_pow_out() { return result(4); }
  pir::Value beta2_pow_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  MergedMomentum_Op : public pir::Op<MergedMomentum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.merged_momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::vector<std::string>& regularization_method={}, const std::vector<float>& regularization_coeff={}, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  MeshgridOp : public pir::Op<MeshgridOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.meshgrid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MishOp : public pir::Op<MishOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ModeOp : public pir::Op<ModeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mode"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  MoeCombineOp : public pir::Op<MoeCombineOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_combine"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weights_, pir::Value scatter_index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value combine_weights() { return operand_source(1); }
  pir::Value scatter_index() { return operand_source(2); }
  pir::Value y() { return result(0); }

};

class  MoeCombineNoWeightOp : public pir::Op<MoeCombineNoWeightOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_combine_no_weight"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weight_, pir::Value scatter_index_, float epsilon=1.0e-15);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weight_, pir::Value scatter_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value combine_weight() { return operand_source(1); }
  pir::Value scatter_index() { return operand_source(2); }
  pir::Value y() { return result(0); }

};

class  MoeGateDispatchOp : public pir::Op<MoeGateDispatchOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gate_logits_, pir::Value corr_bias_, int64_t k, int64_t capacity, bool use_pad);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gate_logits_, pir::Value corr_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value gate_logits() { return operand_source(1); }
  pir::Value corr_bias() { return operand_source(2); }
  pir::Value y() { return result(0); }
  pir::Value combine_weights() { return result(1); }
  pir::Value scatter_index() { return result(2); }
  pir::Value expert_offset() { return result(3); }
  pir::Value expert_id() { return result(4); }

};

class  MoeGateDispatchPartialNosoftmaxtopkOp : public pir::Op<MoeGateDispatchPartialNosoftmaxtopkOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch_partial_nosoftmaxtopk"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weights_, pir::Value expert_id_, int64_t k, int64_t capacity, int64_t num_experts, bool use_pad, int64_t expert_start_index, int64_t expert_end_index, bool reverse_token_drop);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weights_, pir::Value expert_id_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value combine_weights() { return operand_source(1); }
  pir::Value expert_id() { return operand_source(2); }
  pir::Value y() { return result(0); }
  pir::Value combine_weights_out() { return result(1); }
  pir::Value scatter_index() { return result(2); }
  pir::Value scatter_index_rev() { return result(3); }
  pir::Value expert_offset() { return result(4); }
  pir::Value expert_nums_local() { return result(5); }

};

class  MoeGateDispatchPermuteOp : public pir::Op<MoeGateDispatchPermuteOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch_permute"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gate_logits_, pir::Value corr_bias_, int64_t k, int64_t capacity, int64_t world_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gate_logits_, pir::Value corr_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value gate_logits() { return operand_source(1); }
  pir::Value corr_bias() { return operand_source(2); }
  pir::Value y() { return result(0); }
  pir::Value combine_weights() { return result(1); }
  pir::Value scatter_index() { return result(2); }
  pir::Value expert_offset() { return result(3); }
  pir::Value expert_id() { return result(4); }

};

class  MoePermuteOp : public pir::Op<MoePermuteOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_permute"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hidden_states_, pir::Value scale_, pir::Value expert_routemap_topk_, pir::Value expert_prob_topk_, int num_experts, const std::vector<int>& tokens_per_expert, int padding_alignment);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hidden_states_, pir::Value scale_, pir::Value expert_routemap_topk_, pir::Value expert_prob_topk_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value hidden_states() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value expert_routemap_topk() { return operand_source(2); }
  pir::Value expert_prob_topk() { return operand_source(3); }
  pir::Value hidden_states_unzipped() { return result(0); }
  pir::Value zipped_expertwise_rowmap() { return result(1); }
  pir::Value token_prob_unzipped() { return result(2); }
  pir::Value scale_unzipped() { return result(3); }

};

class  MoeUnpermuteOp : public pir::Op<MoeUnpermuteOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_unpermute"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hidden_states_unzipped_, pir::Value zipped_expertwise_rowmap_, pir::Value expert_routemap_topk_, pir::Value token_prob_unzipped_, int total_zipped_tokens_num, int num_experts, bool use_mix_precision);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value hidden_states_unzipped_, pir::Value zipped_expertwise_rowmap_, pir::Value expert_routemap_topk_, pir::Value token_prob_unzipped_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value hidden_states_unzipped() { return operand_source(0); }
  pir::Value zipped_expertwise_rowmap() { return operand_source(1); }
  pir::Value expert_routemap_topk() { return operand_source(2); }
  pir::Value token_prob_unzipped() { return operand_source(3); }
  pir::Value hidden_states() { return result(0); }
  pir::Value expert_prob_topk() { return result(1); }

};

class  Momentum_Op : public pir::Op<Momentum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  MomentumDenseParamSparseGrad_Op : public pir::Op<MomentumDenseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.momentum_dense_param_sparse_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  MpAllreduceSumOp : public pir::Op<MpAllreduceSumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mp_allreduce_sum"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MpAllreduceSum_Op : public pir::Op<MpAllreduceSum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mp_allreduce_sum_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MultiDotOp : public pir::Op<MultiDotOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_dot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MulticlassNms3Op : public pir::Op<MulticlassNms3Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiclass_nms3"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::Value rois_num_, float score_threshold, int nms_top_k, int keep_top_k, float nms_threshold=0.3, bool normalized=true, float nms_eta=1.0, int background_label=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value bboxes_, pir::Value scores_, pir::Value rois_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value bboxes() { return operand_source(0); }
  pir::Value scores() { return operand_source(1); }
  pir::Value rois_num() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value index() { return result(1); }
  pir::Value nms_rois_num() { return result(2); }

};

class  MultinomialOp : public pir::Op<MultinomialOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multinomial"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num_samples=1, bool replacement=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value num_samples_, bool replacement=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value num_samples() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MultiplexOp : public pir::Op<MultiplexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiplex"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MvOp : public pir::Op<MvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Nadam_Op : public pir::Op<Nadam_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nadam_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value momentum_decay_pow_, pir::Value beta2_pow_, pir::Value mu_product_, pir::Value moment1_, pir::Value moment2_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, float momentum_decay=0.004f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value momentum_decay_pow_, pir::Value beta2_pow_, pir::Value mu_product_, pir::Value moment1_, pir::Value moment2_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value momentum_decay_pow() { return operand_source(3); }
  pir::Value beta2_pow() { return operand_source(4); }
  pir::Value mu_product() { return operand_source(5); }
  pir::Value moment1() { return operand_source(6); }
  pir::Value moment2() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value param_out() { return result(0); }
  pir::Value momentum_decay_pow_out() { return result(1); }
  pir::Value beta2_pow_out() { return result(2); }
  pir::Value mu_product_out() { return result(3); }
  pir::Value moment1_out() { return result(4); }
  pir::Value moment2_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  NanmedianOp : public pir::Op<NanmedianOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nanmedian"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=true, const std::string& mode="avg");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value medians() { return result(1); }

};

class  NearestInterpOp : public pir::Op<NearestInterpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nearest_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_format="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output() { return result(0); }

};

class  NextafterOp : public pir::Op<NextafterOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nextafter"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  NllLossOp : public pir::Op<NllLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nll_loss"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, int64_t ignore_index=-100, const std::string& reduction="mean");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value total_weight() { return result(1); }

};

class  NmsOp : public pir::Op<NmsOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nms"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  NonzeroOp : public pir::Op<NonzeroOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nonzero"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  NormOp : public pir::Op<NormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis, float epsilon, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value norm() { return result(1); }

};

class  NpuIdentityOp : public pir::Op<NpuIdentityOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.npu_identity"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int format=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  NumelOp : public pir::Op<NumelOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.numel"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value size() { return result(0); }

};

class  OneHotOp : public pir::Op<OneHotOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.one_hot"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num_classes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value num_classes_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value num_classes() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  OnesOp : public pir::Op<OnesOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ones"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out() { return result(0); }

};

class  OnesLikeOp : public pir::Op<OnesLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ones_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const phi::Place& place={});
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  OverlapAddOp : public pir::Op<OverlapAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.overlap_add"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int hop_length, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PNormOp : public pir::Op<PNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.p_norm"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float porder=2, int axis=-1, float epsilon=1.0e-12f, bool keepdim=false, bool asvector=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PadOp : public pir::Op<PadOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value pad_value() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Pad3dOp : public pir::Op<Pad3dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& paddings, const std::string& mode="constant", float pad_value=0.0, const std::string& data_format="NCDHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value paddings_, const std::string& mode="constant", float pad_value=0.0, const std::string& data_format="NCDHW");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value paddings() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  PartialAllgatherOp : public pir::Op<PartialAllgatherOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_allgather"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int nranks, int rank, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PartialAllgather_Op : public pir::Op<PartialAllgather_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_allgather_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int nranks, int rank, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PartialConcatOp : public pir::Op<PartialConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_concat"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_index=0, int length=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PartialSumOp : public pir::Op<PartialSumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_sum"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int start_index=0, int length=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PixelShuffleOp : public pir::Op<PixelShuffleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_shuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int upscale_factor=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PixelUnshuffleOp : public pir::Op<PixelUnshuffleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_unshuffle"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int downscale_factor=1, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PoissonOp : public pir::Op<PoissonOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.poisson"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PolygammaOp : public pir::Op<PolygammaOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Polygamma_Op : public pir::Op<Polygamma_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Pool2dOp : public pir::Op<Pool2dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_size_, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value kernel_size() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Pool3dOp : public pir::Op<Pool3dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool3d"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PowOp : public pir::Op<PowOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float y=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Pow_Op : public pir::Op<Pow_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float y=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PreluOp : public pir::Op<PreluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prelu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, const std::string& data_format="NCHW", const std::string& mode="all");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value alpha() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  PriorBoxOp : public pir::Op<PriorBoxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prior_box"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value image_, const std::vector<float>& min_sizes, const std::vector<float>& max_sizes={}, const std::vector<float>& aspect_ratios={}, const std::vector<float>& variances={}, bool flip=true, bool clip=true, float step_w=0.0, float step_h=0.0, float offset=0.5, bool min_max_aspect_ratios_order=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value image_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value image() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value var() { return result(1); }

};

class  ProdOp : public pir::Op<ProdOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prod"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  PruneGateByCapacityOp : public pir::Op<PruneGateByCapacityOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prune_gate_by_capacity"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_idx_, pir::Value expert_count_, int64_t n_expert=0, int64_t n_worker=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_idx_, pir::Value expert_count_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value gate_idx() { return operand_source(0); }
  pir::Value expert_count() { return operand_source(1); }
  pir::Value out_gate_idx() { return result(0); }

};

class  PsroiPoolOp : public pir::Op<PsroiPoolOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.psroi_pool"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, int output_channels=1, float spatial_scale=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  PutAlongAxisOp : public pir::Op<PutAlongAxisOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, int axis, const std::string& reduce="assign", bool include_self=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  PutAlongAxis_Op : public pir::Op<PutAlongAxis_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, int axis, const std::string& reduce="assign", bool include_self=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  PyramidHashOp : public pir::Op<PyramidHashOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pyramid_hash"; }
  static const char *attributes_name[12];
  static constexpr uint32_t attributes_num = 12;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value white_list_, pir::Value black_list_, int num_emb=0, int space_len=0, int pyramid_layer=2, int rand_len=0, float drop_out_percent=0, int is_training=0, bool use_filter=true, int white_list_len=0, int black_list_len=0, int seed=0, float lr=0.0, const std::string& distribute_update_vars="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value white_list_, pir::Value black_list_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value white_list() { return operand_source(2); }
  pir::Value black_list() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value drop_pos() { return result(1); }
  pir::Value x_temp_out() { return result(2); }

};

class  QrOp : public pir::Op<QrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qr"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& mode="reduced");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value q() { return result(0); }
  pir::Value r() { return result(1); }

};

class  Radam_Op : public pir::Op<Radam_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.radam_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value rho_, pir::Value moment1_, pir::Value moment2_, pir::Value master_param_, float beta1=0.9f, float beta2=0.999f, float epsilon=1.0e-8f, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value learning_rate_, pir::Value beta1_pow_, pir::Value beta2_pow_, pir::Value rho_, pir::Value moment1_, pir::Value moment2_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value beta1_pow() { return operand_source(3); }
  pir::Value beta2_pow() { return operand_source(4); }
  pir::Value rho() { return operand_source(5); }
  pir::Value moment1() { return operand_source(6); }
  pir::Value moment2() { return operand_source(7); }
  pir::Value master_param() { return operand_source(8); }
  pir::Value param_out() { return result(0); }
  pir::Value beta1_pow_out() { return result(1); }
  pir::Value beta2_pow_out() { return result(2); }
  pir::Value rho_out() { return result(3); }
  pir::Value moment1_out() { return result(4); }
  pir::Value moment2_out() { return result(5); }
  pir::Value master_param_out() { return result(6); }

};

class  RandintOp : public pir::Op<RandintOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.randint"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int low, int high, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::INT64, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, int low, int high, phi::DataType dtype=phi::DataType::INT64, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value shape() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  RandomRoutingOp : public pir::Op<RandomRoutingOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.random_routing"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prob_, pir::Value topk_value_, pir::Value topk_idx_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value prob() { return operand_source(0); }
  pir::Value topk_value() { return operand_source(1); }
  pir::Value topk_idx() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  RandomRouting_Op : public pir::Op<RandomRouting_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.random_routing_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value prob_, pir::Value topk_value_, pir::Value topk_idx_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value prob() { return operand_source(0); }
  pir::Value topk_value() { return operand_source(1); }
  pir::Value topk_idx() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  RandpermOp : public pir::Op<RandpermOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.randperm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int n, phi::DataType dtype, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  RankAttentionOp : public pir::Op<RankAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rank_attention"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rank_offset_, pir::Value rank_param_, int max_rank=3, int max_size=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rank_offset_, pir::Value rank_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value rank_offset() { return operand_source(1); }
  pir::Value rank_param() { return operand_source(2); }
  pir::Value input_help() { return result(0); }
  pir::Value out() { return result(1); }
  pir::Value ins_rank() { return result(2); }

};

class  ReadFileOp : public pir::Op<ReadFileOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.read_file"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::string& filename="", phi::DataType dtype=phi::DataType::UINT8, const phi::Place& place=phi::CPUPlace());
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  RealOp : public pir::Op<RealOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.real"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReciprocalOp : public pir::Op<ReciprocalOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Reciprocal_Op : public pir::Op<Reciprocal_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReduceOp : public pir::Op<ReduceOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reduce"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root_id=0, int reduce_type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Reduce_Op : public pir::Op<Reduce_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reduce_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int root_id=0, int reduce_type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReduceAsOp : public pir::Op<ReduceAsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reduce_as"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value target_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value target() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ReduceScatterOp : public pir::Op<ReduceScatterOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reduce_scatter"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int nranks=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReindexGraphOp : public pir::Op<ReindexGraphOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reindex_graph"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value neighbors_, pir::Value count_, pir::Value hashtable_value_, pir::Value hashtable_index_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value neighbors() { return operand_source(1); }
  pir::Value count() { return operand_source(2); }
  pir::Value hashtable_value() { return operand_source(3); }
  pir::Value hashtable_index() { return operand_source(4); }
  pir::Value reindex_src() { return result(0); }
  pir::Value reindex_dst() { return result(1); }
  pir::Value out_nodes() { return result(2); }

};

class TEST_API ReluOp : public pir::Op<ReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Relu_Op : public pir::Op<Relu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Relu6Op : public pir::Op<Relu6Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  RenormOp : public pir::Op<RenormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Renorm_Op : public pir::Op<Renorm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  RepeatInterleaveOp : public pir::Op<RepeatInterleaveOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int repeats, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};


class  RepeatInterleaveWithTensorIndexOp : public pir::Op<RepeatInterleaveWithTensorIndexOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_with_tensor_index"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value repeats() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class TEST_API ReshapeOp : public pir::Op<ReshapeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Reshape_Op : public pir::Op<Reshape_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  RestrictNonzeroOp : public pir::Op<RestrictNonzeroOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.restrict_nonzero"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, int64_t total_true_num);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReverseOp : public pir::Op<ReverseOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reverse"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  RmsNormOp : public pir::Op<RmsNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rms_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, float epsilon, int begin_norm_axis, float quant_scale, int quant_round_type, float quant_max_bound, float quant_min_bound);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value norm_weight() { return operand_source(3); }
  pir::Value norm_bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value residual_out() { return result(1); }
  pir::Value inv_var() { return result(2); }

};

class  Rmsprop_Op : public pir::Op<Rmsprop_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rmsprop_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, float epsilon=1.0e-10f, float decay=0.9f, float momentum=0.0f, bool centered=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value mean_square() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value mean_grad() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value mean_square_out() { return result(2); }
  pir::Value mean_grad_out() { return result(3); }
  pir::Value master_param_outs() { return result(4); }

};

class  RmspropDenseParamSparseGrad_Op : public pir::Op<RmspropDenseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rmsprop_dense_param_sparse_grad_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, float epsilon=1.0e-10f, float decay=0.9f, float momentum=0.0f, bool centered=false, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value mean_square_, pir::Value grad_, pir::Value moment_, pir::Value learning_rate_, pir::Value mean_grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value mean_square() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value moment() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value mean_grad() { return operand_source(5); }
  pir::Value master_param() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value moment_out() { return result(1); }
  pir::Value mean_square_out() { return result(2); }
  pir::Value mean_grad_out() { return result(3); }
  pir::Value master_param_outs() { return result(4); }

};

class  RnnOp : public pir::Op<RnnOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, float dropout_prob=0.0, bool is_bidirec=false, int input_size=10, int hidden_size=100, int num_layers=1, const std::string& mode="RNN_TANH", int seed=0, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value dropout_state_in() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value dropout_state_out() { return result(1); }
  pir::Value state() { return result(2); }
  pir::Value reserve() { return result(3); }

};

class  Rnn_Op : public pir::Op<Rnn_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, float dropout_prob=0.0, bool is_bidirec=false, int input_size=10, int hidden_size=100, int num_layers=1, const std::string& mode="RNN_TANH", int seed=0, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value dropout_state_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value dropout_state_in() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value dropout_state_out() { return result(1); }
  pir::Value state() { return result(2); }
  pir::Value reserve() { return result(3); }

};

class  RoiAlignOp : public pir::Op<RoiAlignOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_align"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, float spatial_scale=1.0, int sampling_ratio=-1, bool aligned=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  RoiPoolOp : public pir::Op<RoiPoolOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_pool"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, int pooled_height=1, int pooled_width=1, float spatial_scale=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value arg_max() { return result(1); }

};

class  RollOp : public pir::Op<RollOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roll"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shifts={}, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shifts_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shifts() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  RoundOp : public pir::Op<RoundOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int decimals=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Round_Op : public pir::Op<Round_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int decimals=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Rprop_Op : public pir::Op<Rprop_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rprop_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value prev_, pir::Value learning_rate_, pir::Value master_param_, pir::Value learning_rate_range_, pir::Value etas_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value prev_, pir::Value learning_rate_, pir::Value master_param_, pir::Value learning_rate_range_, pir::Value etas_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value prev() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value learning_rate_range() { return operand_source(5); }
  pir::Value etas() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value prev_out() { return result(1); }
  pir::Value learning_rate_out() { return result(2); }
  pir::Value master_param_out() { return result(3); }

};

class  RreluOp : public pir::Op<RreluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rrelu"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float lower=1.0f/8, float upper=1.0f/3, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value noise() { return result(1); }

};

class  RsqrtOp : public pir::Op<RsqrtOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Rsqrt_Op : public pir::Op<Rsqrt_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API ScaleOp : public pir::Op<ScaleOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ScaleSrOp : public pir::Op<ScaleSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_sr"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Scale_Op : public pir::Op<Scale_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ScaleSr_Op : public pir::Op<ScaleSr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_sr_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float bias=0.0, bool bias_after_scale=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ScatterOp : public pir::Op<ScatterOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, bool overwrite=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Scatter_Op : public pir::Op<Scatter_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, bool overwrite=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  ScatterNdAddOp : public pir::Op<ScatterNdAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_nd_add"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value updates_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value updates() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SearchsortedOp : public pir::Op<SearchsortedOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.searchsorted"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sorted_sequence_, pir::Value values_, bool out_int32=false, bool right=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sorted_sequence_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value sorted_sequence() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SegmentPoolOp : public pir::Op<SegmentPoolOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.segment_pool"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, const std::string& pooltype="SUM");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value segment_ids() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value summed_ids() { return result(1); }

};

class  SeluOp : public pir::Op<SeluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.selu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale=1.0507009873554804934193349852946, float alpha=1.6732632423543772848170429916717);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SendURecvOp : public pir::Op<SendURecvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_u_recv"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, const std::string& reduce_op="SUM", const std::vector<int64_t>& out_size={0});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_size_, const std::string& reduce_op="SUM");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value src_index() { return operand_source(1); }
  pir::Value dst_index() { return operand_source(2); }
  pir::Value out_size() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value dst_count() { return result(1); }

};

class  SendUeRecvOp : public pir::Op<SendUeRecvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_ue_recv"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, const std::string& message_op="ADD", const std::string& reduce_op="SUM", const std::vector<int64_t>& out_size={0});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_size_, const std::string& message_op="ADD", const std::string& reduce_op="SUM");
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out_size() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value dst_count() { return result(1); }

};

class  SendUvOp : public pir::Op<SendUvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_uv"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, const std::string& message_op="ADD");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  SequenceConvOp : public pir::Op<SequenceConvOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_conv"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value padding_data_, pir::Value filter_, int context_length, bool padding_trainable=false, int context_start=0, int context_stride=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value padding_data_, pir::Value filter_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value padding_data() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SequenceMaskOp : public pir::Op<SequenceMaskOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_mask"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int max_len, phi::DataType out_dtype);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value max_len_, phi::DataType out_dtype);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value max_len() { return operand_source(1); }
  pir::Value y() { return result(0); }

};

class  SequencePoolOp : public pir::Op<SequencePoolOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_pool"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool is_test=false, const std::string& pooltype="AVERAGE", float pad_value=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value max_index() { return result(1); }

};

class  SetOp : public pir::Op<SetOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value source_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value source_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value source() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Set_Op : public pir::Op<Set_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value source_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value source_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value source() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SetValueWithTensorOp : public pir::Op<SetValueWithTensorOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::Value out() { return result(0); }

};

class  SetValueWithTensor_Op : public pir::Op<SetValueWithTensor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value values_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value values() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::Value out() { return result(0); }

};

class  Sgd_Op : public pir::Op<Sgd_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::Value param_out() { return result(0); }
  pir::Value master_param_out() { return result(1); }

};

class  SgdDenseParamSparseGrad_Op : public pir::Op<SgdDenseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_dense_param_sparse_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::Value param_out() { return result(0); }
  pir::Value master_param_out() { return result(1); }

};

class  SgdSparseParamSparseGrad_Op : public pir::Op<SgdSparseParamSparseGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sgd_sparse_param_sparse_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, bool multi_precision=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value learning_rate_, pir::Value grad_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value learning_rate() { return operand_source(1); }
  pir::Value grad() { return operand_source(2); }
  pir::Value master_param() { return operand_source(3); }
  pir::Value param_out() { return result(0); }
  pir::Value master_param_out() { return result(1); }

};

class  ShapeOp : public pir::Op<ShapeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShapeSrOp : public pir::Op<ShapeSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Shape64Op : public pir::Op<Shape64Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape64"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Shape64SrOp : public pir::Op<Shape64SrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shape64_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShardIndexOp : public pir::Op<ShardIndexOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shard_index"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int index_num, int nshards, int shard_id, int ignore_value=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShareDataOp : public pir::Op<ShareDataOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.share_data"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShareDataSrOp : public pir::Op<ShareDataSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.share_data_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShuffleBatchOp : public pir::Op<ShuffleBatchOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_batch"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_, int startup_seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value seed_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value seed() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value shuffle_idx() { return result(1); }
  pir::Value seed_out() { return result(2); }

};

class  ShuffleChannelOp : public pir::Op<ShuffleChannelOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_channel"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int group=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SigmoidOp : public pir::Op<SigmoidOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Sigmoid_Op : public pir::Op<Sigmoid_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SigmoidCrossEntropyWithLogitsOp : public pir::Op<SigmoidCrossEntropyWithLogitsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, bool normalize=false, int ignore_index=-100);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SigmoidCrossEntropyWithLogits_Op : public pir::Op<SigmoidCrossEntropyWithLogits_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, bool normalize=false, int ignore_index=-100);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SignOp : public pir::Op<SignOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SiluOp : public pir::Op<SiluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinOp : public pir::Op<SinOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Sin_Op : public pir::Op<Sin_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinhOp : public pir::Op<SinhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Sinh_Op : public pir::Op<Sinh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SliceOp : public pir::Op<SliceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SlogdetOp : public pir::Op<SlogdetOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slogdet"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftplusOp : public pir::Op<SoftplusOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float beta=1.0, float threshold=20.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftshrinkOp : public pir::Op<SoftshrinkOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftsignOp : public pir::Op<SoftsignOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SolveOp : public pir::Op<SolveOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.solve"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SparseAttentionOp : public pir::Op<SparseAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_attention"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value offset_, pir::Value columns_, pir::Value key_padding_mask_, pir::Value attn_mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value offset() { return operand_source(3); }
  pir::Value columns() { return operand_source(4); }
  pir::Value key_padding_mask() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value sparse_dot_sdd() { return result(1); }
  pir::Value softmax() { return result(2); }

};

class  SpectralNormOp : public pir::Op<SpectralNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.spectral_norm"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, int dim=0, int power_iters=1, float eps=1e-12f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value weight() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SplitOp : public pir::Op<SplitOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& sections, int axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value sections_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value sections() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SplitWithNumOp : public pir::Op<SplitWithNumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split_with_num"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num, int axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, int num);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SqrtOp : public pir::Op<SqrtOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SqrtSrOp : public pir::Op<SqrtSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Sqrt_Op : public pir::Op<Sqrt_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SqrtSr_Op : public pir::Op<SqrtSr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_sr_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquareOp : public pir::Op<SquareOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquareSrOp : public pir::Op<SquareSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Square_Op : public pir::Op<Square_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquareSr_Op : public pir::Op<SquareSr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_sr_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquaredL2NormOp : public pir::Op<SquaredL2NormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squared_l2_norm"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SqueezeOp : public pir::Op<SqueezeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Squeeze_Op : public pir::Op<Squeeze_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  StackOp : public pir::Op<StackOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stack"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  StandardGammaOp : public pir::Op<StandardGammaOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.standard_gamma"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  StanhOp : public pir::Op<StanhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stanh"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale_a=0.67f, float scale_b=1.7159f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  StftOp : public pir::Op<StftOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stft"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value window_, int n_fft, int hop_length, bool normalized, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value window_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value window() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  StridedSliceOp : public pir::Op<StridedSliceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.strided_slice"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& strides);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value strides_, const std::vector<int>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value strides() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  SumOp : public pir::Op<SumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SvdOp : public pir::Op<SvdOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svd"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool full_matrices=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value u() { return result(0); }
  pir::Value s() { return result(1); }
  pir::Value vh() { return result(2); }

};

class  SvdvalsOp : public pir::Op<SvdvalsOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svdvals"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value s() { return result(0); }

};

class  SwigluOp : public pir::Op<SwigluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swiglu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SwishOp : public pir::Op<SwishOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,pir::UnaryElementWiseTrait,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SyncBatchNorm_Op : public pir::Op<SyncBatchNorm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_format, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  SyncCalcStreamOp : public pir::Op<SyncCalcStreamOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_calc_stream"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SyncCalcStream_Op : public pir::Op<SyncCalcStream_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_calc_stream_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TakeAlongAxisOp : public pir::Op<TakeAlongAxisOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.take_along_axis"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  TanOp : public pir::Op<TanOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Tan_Op : public pir::Op<Tan_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TanhOp : public pir::Op<TanhOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Tanh_Op : public pir::Op<Tanh_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TanhShrinkOp : public pir::Op<TanhShrinkOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TdmChildOp : public pir::Op<TdmChildOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tdm_child"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value tree_info_, int child_nums, phi::DataType dtype=phi::DataType::INT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value tree_info_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value tree_info() { return operand_source(1); }
  pir::Value child() { return result(0); }
  pir::Value leaf_mask() { return result(1); }

};

class  TdmSamplerOp : public pir::Op<TdmSamplerOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tdm_sampler"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value travel_, pir::Value layer_, bool output_positive=true, const std::vector<int>& neg_samples_num_list={}, const std::vector<int>& layer_offset={}, int seed=0, int dtype=2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value travel_, pir::Value layer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value travel() { return operand_source(1); }
  pir::Value layer() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value labels() { return result(1); }
  pir::Value mask() { return result(2); }

};

class  TemporalShiftOp : public pir::Op<TemporalShiftOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.temporal_shift"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int seg_num, float shift_ratio=0.25f, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ThresholdedReluOp : public pir::Op<ThresholdedReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0, float value=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ThresholdedRelu_Op : public pir::Op<ThresholdedRelu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::UnaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=1.0, float value=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TopPSamplingOp : public pir::Op<TopPSamplingOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.top_p_sampling"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ps_, pir::Value threshold_, pir::Value topp_seed_, int seed=-1, int k=0, const std::string& mode="truncate");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ps_, pir::Value threshold_, pir::Value topp_seed_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ps() { return operand_source(1); }
  pir::Value threshold() { return operand_source(2); }
  pir::Value topp_seed() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value ids() { return result(1); }
  pir::Value topk_scores() { return result(2); }
  pir::Value topk_ids() { return result(3); }

};

class  TopkOp : public pir::Op<TopkOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.topk"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int k=1, int axis=-1, bool largest=true, bool sorted=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value k_, int axis=-1, bool largest=true, bool sorted=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }

};

class  TraceOp : public pir::Op<TraceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trace"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TransLayoutOp : public pir::Op<TransLayoutOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trans_layout"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API TransposeOp : public pir::Op<TransposeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Transpose_Op : public pir::Op<Transpose_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TriangularSolveOp : public pir::Op<TriangularSolveOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triangular_solve"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool upper=true, bool transpose=false, bool unitriangular=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  TrilOp : public pir::Op<TrilOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Tril_Op : public pir::Op<Tril_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TrilIndicesOp : public pir::Op<TrilIndicesOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_indices"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int rows, int cols, int offset, phi::DataType dtype, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  TrilinearInterpOp : public pir::Op<TrilinearInterpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trilinear_interp"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, const std::string& data_format="NCHW", int out_d=0, int out_h=0, int out_w=0, const std::vector<float>& scale={}, const std::string& interp_method="bilinear", bool align_corners=true, int align_mode=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output() { return result(0); }

};

class  TriuOp : public pir::Op<TriuOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Triu_Op : public pir::Op<Triu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TriuIndicesOp : public pir::Op<TriuIndicesOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_indices"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int row, int col, int offset, phi::DataType dtype, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  TruncOp : public pir::Op<TruncOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Trunc_Op : public pir::Op<Trunc_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TruncatedGaussianRandomOp : public pir::Op<TruncatedGaussianRandomOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.truncated_gaussian_random"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& shape, float mean, float std, int seed, float a, float b, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  UnbindOp : public pir::Op<UnbindOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unbind"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UnfoldOp : public pir::Op<UnfoldOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unfold"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API UniformOp : public pir::Op<UniformOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype, float min, float max, int seed, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shape_, pir::Value min_, pir::Value max_, phi::DataType dtype, int seed, const phi::Place& place={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value shape() { return operand_source(0); }
  pir::Value min() { return operand_source(1); }
  pir::Value max() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  UniformInplaceOp : public pir::Op<UniformInplaceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UniformInplace_Op : public pir::Op<UniformInplace_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UniformRandomBatchSizeLikeOp : public pir::Op<UniformRandomBatchSizeLikeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_random_batch_size_like"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int>& shape, int input_dim_idx=0, int output_dim_idx=0, float min=-1.0f, float max=1.0f, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0f, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UniformRandomBatchSizeLikeSrOp : public pir::Op<UniformRandomBatchSizeLikeSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_random_batch_size_like_sr"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<int>& shape, int input_dim_idx=0, int output_dim_idx=0, float min=-1.0f, float max=1.0f, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0f, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UniqueConsecutiveOp : public pir::Op<UniqueConsecutiveOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unique_consecutive"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool return_inverse=false, bool return_counts=false, const std::vector<int>& axis={}, phi::DataType dtype=phi::DataType::FLOAT32);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value index() { return result(1); }
  pir::Value counts() { return result(2); }

};

class  UnpoolOp : public pir::Op<UnpoolOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::vector<int64_t>& output_size, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value output_size_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value output_size() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Unpool3dOp : public pir::Op<Unpool3dOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool3d"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, const std::vector<int>& ksize, const std::vector<int>& strides={1,1,1}, const std::vector<int>& paddings={0,0,0}, const std::vector<int>& output_size={0,0,0}, const std::string& data_format="NCDHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  UnsqueezeOp : public pir::Op<UnsqueezeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Unsqueeze_Op : public pir::Op<Unsqueeze_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  UnstackOp : public pir::Op<UnstackOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unstack"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=0, int num=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  UpdateLossScaling_Op : public pir::Op<UpdateLossScaling_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.update_loss_scaling_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, int incr_every_n_steps, int decr_every_n_nan_or_inf, float incr_ratio, float decr_ratio, bool stop_update=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, pir::Value stop_update_, int incr_every_n_steps, int decr_every_n_nan_or_inf, float incr_ratio, float decr_ratio);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value found_infinite_, pir::Value prev_loss_scaling_, pir::Value in_good_steps_, pir::Value in_bad_steps_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value found_infinite() { return operand_source(1); }
  pir::Value prev_loss_scaling() { return operand_source(2); }
  pir::Value in_good_steps() { return operand_source(3); }
  pir::Value in_bad_steps() { return operand_source(4); }
  pir::Value stop_update() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value loss_scaling() { return result(1); }
  pir::Value out_good_steps() { return result(2); }
  pir::Value out_bad_steps() { return result(3); }

};

class  VarianceOp : public pir::Op<VarianceOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.variance"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ViewDtypeOp : public pir::Op<ViewDtypeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_dtype"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ViewSliceOp : public pir::Op<ViewSliceOp,paddle::dialect::InferMetaInterface,paddle::dialect::InplaceTrait,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_slice"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, int64_t begin_idx, int64_t end_idx);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ViterbiDecodeOp : public pir::Op<ViterbiDecodeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.viterbi_decode"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value potentials_, pir::Value transition_params_, pir::Value lengths_, bool include_bos_eos_tag=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value potentials_, pir::Value transition_params_, pir::Value lengths_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value potentials() { return operand_source(0); }
  pir::Value transition_params() { return operand_source(1); }
  pir::Value lengths() { return operand_source(2); }
  pir::Value scores() { return result(0); }
  pir::Value path() { return result(1); }

};

class  WarpctcOp : public pir::Op<WarpctcOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warpctc"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value logits_length_, pir::Value labels_length_, int blank=0, bool norm_by_times=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value logits_length_, pir::Value labels_length_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value logits_length() { return operand_source(2); }
  pir::Value labels_length() { return operand_source(3); }
  pir::Value loss() { return result(0); }
  pir::Value warpctcgrad() { return result(1); }

};

class  WarprnntOp : public pir::Op<WarprnntOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warprnnt"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value input_lengths_, pir::Value label_lengths_, int blank=0, float fastemit_lambda=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value input_lengths_, pir::Value label_lengths_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value input_lengths() { return operand_source(2); }
  pir::Value label_lengths() { return operand_source(3); }
  pir::Value loss() { return result(0); }
  pir::Value warprnntgrad() { return result(1); }

};

class  WeightDequantizeOp : public pir::Op<WeightDequantizeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_dequantize"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, const std::string& algo="weight_only_int8", int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  WeightOnlyLinearOp : public pir::Op<WeightOnlyLinearOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_only_linear"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, const std::string& weight_dtype, int arch=80, int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  WeightQuantizeOp : public pir::Op<WeightQuantizeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_quantize"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& algo="weight_only_int8", int arch=80, int group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scale() { return result(1); }

};

class  WeightedSampleNeighborsOp : public pir::Op<WeightedSampleNeighborsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weighted_sample_neighbors"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value edge_weight_, pir::Value input_nodes_, pir::Value eids_, int sample_size, bool return_eids);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value row_, pir::Value colptr_, pir::Value edge_weight_, pir::Value input_nodes_, pir::Value eids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value row() { return operand_source(0); }
  pir::Value colptr() { return operand_source(1); }
  pir::Value edge_weight() { return operand_source(2); }
  pir::Value input_nodes() { return operand_source(3); }
  pir::Value eids() { return operand_source(4); }
  pir::Value out_neighbors() { return result(0); }
  pir::Value out_count() { return result(1); }
  pir::Value out_eids() { return result(2); }

};

class  WhereOp : public pir::Op<WhereOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  Where_Op : public pir::Op<Where_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  YoloBoxOp : public pir::Op<YoloBoxOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value img_size_, const std::vector<int>& anchors={}, int class_num=1, float conf_thresh=0.01, int downsample_ratio=32, bool clip_bbox=true, float scale_x_y=1.0, bool iou_aware=false, float iou_aware_factor=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value img_size_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value img_size() { return operand_source(1); }
  pir::Value boxes() { return result(0); }
  pir::Value scores() { return result(1); }

};

class  YoloBoxHeadOp : public pir::Op<YoloBoxHeadOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box_head"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& anchors, int class_num);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  YoloBoxPostOp : public pir::Op<YoloBoxPostOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box_post"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value boxes0_, pir::Value boxes1_, pir::Value boxes2_, pir::Value image_shape_, pir::Value image_scale_, const std::vector<int>& anchors0, const std::vector<int>& anchors1, const std::vector<int>& anchors2, int class_num, float conf_thresh, int downsample_ratio0, int downsample_ratio1, int downsample_ratio2, bool clip_bbox, float scale_x_y, float nms_threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value boxes0_, pir::Value boxes1_, pir::Value boxes2_, pir::Value image_shape_, pir::Value image_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value boxes0() { return operand_source(0); }
  pir::Value boxes1() { return operand_source(1); }
  pir::Value boxes2() { return operand_source(2); }
  pir::Value image_shape() { return operand_source(3); }
  pir::Value image_scale() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value nms_rois_num() { return result(1); }

};

class  YoloLossOp : public pir::Op<YoloLossOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_loss"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, const std::vector<int>& anchors={}, const std::vector<int>& anchor_mask={}, int class_num=1, float ignore_thresh=0.7, int downsample_ratio=32, bool use_label_smooth=true, float scale_x_y=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value gt_box() { return operand_source(1); }
  pir::Value gt_label() { return operand_source(2); }
  pir::Value gt_score() { return operand_source(3); }
  pir::Value loss() { return result(0); }
  pir::Value objectness_mask() { return result(1); }
  pir::Value gt_match_mask() { return result(2); }

};

class  ZerosOp : public pir::Op<ZerosOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.zeros"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int64_t>& shape, phi::DataType dtype=phi::DataType::FLOAT32, const phi::Place& place=phi::CPUPlace());
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out() { return result(0); }

};

class  ZerosLikeOp : public pir::Op<ZerosLikeOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.zeros_like"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype=phi::DataType::UNDEFINED, const phi::Place& place={});
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ChunkEvalOp : public pir::Op<ChunkEvalOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.chunk_eval"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inference_, pir::Value label_, pir::Value seq_length_, int num_chunk_types, const std::string& chunk_scheme="IOB", const std::vector<int>& excluded_chunk_types={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inference_, pir::Value label_, pir::Value seq_length_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inference() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value seq_length() { return operand_source(2); }
  pir::Value precision() { return result(0); }
  pir::Value recall() { return result(1); }
  pir::Value f1_score() { return result(2); }
  pir::Value num_infer_chunks() { return result(3); }
  pir::Value num_label_chunks() { return result(4); }
  pir::Value num_correct_chunks() { return result(5); }

};

class  Fp8GemmBlockwise_Op : public pir::Op<Fp8GemmBlockwise_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fp8_gemm_blockwise_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value A_, pir::Value A_scale_, pir::Value B_, pir::Value B_scale_, pir::Value input_result_, pir::Value bias_, pir::Value pre_gelu_, pir::Value workspace_, bool transa, bool transb, bool grad, bool accumulate, bool use_split_accumulator, int math_sm_count, bool is_A_1d_scaled, bool is_B_1d_scaled);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value A_, pir::Value A_scale_, pir::Value B_, pir::Value B_scale_, pir::Value input_result_, pir::Value bias_, pir::Value pre_gelu_, pir::Value workspace_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value A() { return operand_source(0); }
  pir::Value A_scale() { return operand_source(1); }
  pir::Value B() { return operand_source(2); }
  pir::Value B_scale() { return operand_source(3); }
  pir::Value input_result() { return operand_source(4); }
  pir::Value bias() { return operand_source(5); }
  pir::Value pre_gelu() { return operand_source(6); }
  pir::Value workspace() { return operand_source(7); }
  pir::Value output() { return result(0); }
  pir::Value pre_gelu_out() { return result(1); }
  pir::Value workspace_out() { return result(2); }

};

class  Fp8QuantBlockwiseOp : public pir::Op<Fp8QuantBlockwiseOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fp8_quant_blockwise"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float epsilon, bool using_1x128_vec_quant, bool input_transpose, bool output_scale_transpose, bool using_e5m2, bool using_pow2_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scale() { return result(1); }
  pir::Value out_transposed() { return result(2); }
  pir::Value scale_transposed() { return result(3); }

};

class  FusedRmsNormExtOp : public pir::Op<FusedRmsNormExtOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rms_norm_ext"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value y() { return result(0); }
  pir::Value invvar() { return result(1); }

};

class  IntBincountOp : public pir::Op<IntBincountOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.int_bincount"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t low, int64_t high, int64_t dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  NumberCountOp : public pir::Op<NumberCountOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.number_count"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value numbers_, int upper_range);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value numbers_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value numbers() { return operand_source(0); }
  pir::Value out() { return result(0); }

};


class  AbsDoubleGradOp : public pir::Op<AbsDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  AbsGradOp : public pir::Op<AbsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AbsTripleGradOp : public pir::Op<AbsTripleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_grad_grad() { return operand_source(1); }
  pir::Value grad_x_grad_grad() { return result(0); }

};

class  AcosDoubleGradOp : public pir::Op<AcosDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  AcosDoubleGrad_Op : public pir::Op<AcosDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  AcosGradOp : public pir::Op<AcosGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcosGrad_Op : public pir::Op<AcosGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcoshGradOp : public pir::Op<AcoshGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcoshGrad_Op : public pir::Op<AcoshGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AddPositionEncodingGradOp : public pir::Op<AddPositionEncodingGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_position_encoding_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha=1.0f, float beta=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AddmmGradOp : public pir::Op<AddmmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha, float beta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  AffineChannelGradOp : public pir::Op<AffineChannelGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_channel_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_grad_, const std::string& data_layout="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  AffineChannelGrad_Op : public pir::Op<AffineChannelGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_channel_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_grad_, const std::string& data_layout="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  AffineGridGradOp : public pir::Op<AffineGridGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.affine_grid_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, const std::vector<int64_t>& output_shape, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, pir::Value output_shape_, bool align_corners=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value output_grad() { return operand_source(1); }
  pir::Value output_shape() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  AmaxGradOp : public pir::Op<AmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amax_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  AminGradOp : public pir::Op<AminGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.amin_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  AngleGradOp : public pir::Op<AngleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.angle_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ArgsortGradOp : public pir::Op<ArgsortGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.argsort_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value indices_, pir::Value x_, pir::Value out_grad_, int axis, bool descending, bool stable);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value indices_, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value indices() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  AsComplexGradOp : public pir::Op<AsComplexGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_complex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  AsRealGradOp : public pir::Op<AsRealGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_real_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  AsStridedGradOp : public pir::Op<AsStridedGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.as_strided_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, const std::vector<int64_t>& dims={}, const std::vector<int64_t>& stride={}, int64_t offset=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value input_grad() { return result(0); }

};

class  AsinGradOp : public pir::Op<AsinGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinGrad_Op : public pir::Op<AsinGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinhGradOp : public pir::Op<AsinhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinhGrad_Op : public pir::Op<AsinhGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Atan2GradOp : public pir::Op<Atan2GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan2_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AtanGradOp : public pir::Op<AtanGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanGrad_Op : public pir::Op<AtanGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanhGradOp : public pir::Op<AtanhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanhGrad_Op : public pir::Op<AtanhGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  BaddbmmGradOp : public pir::Op<BaddbmmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.baddbmm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha, float beta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  BatchFcGradOp : public pir::Op<BatchFcGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_fc_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value w_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  BceLossGradOp : public pir::Op<BceLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  BceLossGrad_Op : public pir::Op<BceLossGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bce_loss_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  BicubicInterpGradOp : public pir::Op<BicubicInterpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bicubic_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_format, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  BilinearGradOp : public pir::Op<BilinearGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value weight_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  BilinearInterpGradOp : public pir::Op<BilinearInterpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bilinear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_format, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  BmmGradOp : public pir::Op<BmmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bmm_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  BroadcastTensorsGradOp : public pir::Op<BroadcastTensorsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.broadcast_tensors_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value input_grad() { return result(0); }

};

class  CConcatGradOp : public pir::Op<CConcatGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_concat_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int rank=0, int nranks=1, int ring_id=0, bool use_model_parallel=true);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  CSoftmaxWithCrossEntropyGradOp : public pir::Op<CSoftmaxWithCrossEntropyGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_cross_entropy_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, int64_t ignore_index=-100, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value softmax() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::Value logits_grad() { return result(0); }

};

class  CSoftmaxWithCrossEntropyGrad_Op : public pir::Op<CSoftmaxWithCrossEntropyGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_cross_entropy_grad_"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, int64_t ignore_index=-100, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value softmax() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::Value logits_grad() { return result(0); }

};

class  CalAuxLossGradOp : public pir::Op<CalAuxLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cal_aux_loss_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_prob_, pir::Value seqlen_float_, pir::Value ce_, pir::Value l_aux_loss_grad_, int64_t num_experts, bool use_group, int64_t moe_k);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value gate_prob_, pir::Value seqlen_float_, pir::Value ce_, pir::Value l_aux_loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value gate_prob() { return operand_source(0); }
  pir::Value seqlen_float() { return operand_source(1); }
  pir::Value ce() { return operand_source(2); }
  pir::Value l_aux_loss_grad() { return operand_source(3); }
  pir::Value gate_prob_grad() { return result(0); }

};

class  CastGradOp : public pir::Op<CastGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CeilGradOp : public pir::Op<CeilGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  CeilGrad_Op : public pir::Op<CeilGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.ceil_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  CeluDoubleGradOp : public pir::Op<CeluDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  CeluDoubleGrad_Op : public pir::Op<CeluDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  CeluGradOp : public pir::Op<CeluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CeluGrad_Op : public pir::Op<CeluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.celu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ChannelShuffleGradOp : public pir::Op<ChannelShuffleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.channel_shuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int groups, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  CholeskyGradOp : public pir::Op<CholeskyGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, bool upper);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CholeskySolveGradOp : public pir::Op<CholeskySolveGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cholesky_solve_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, bool upper);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  ClipDoubleGradOp : public pir::Op<ClipDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ClipGradOp : public pir::Op<ClipGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  ClipGrad_Op : public pir::Op<ClipGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.clip_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float min=0., float max=0.);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value min_, pir::Value max_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value min() { return operand_source(2); }
  pir::Value max() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  ComplexGradOp : public pir::Op<ComplexGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.complex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value real_, pir::Value imag_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value real() { return operand_source(0); }
  pir::Value imag() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value real_grad() { return result(0); }
  pir::Value imag_grad() { return result(1); }

};

class  ConcatDoubleGradOp : public pir::Op<ConcatDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, int axis=0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ConcatGradOp : public pir::Op<ConcatGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.concat_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  ConjGradOp : public pir::Op<ConjGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conj_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  Conv2dGradOp : public pir::Op<Conv2dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, const std::vector<int>& dilations, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  Conv2dGradGradOp : public pir::Op<Conv2dGradGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_grad_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, const std::vector<int>& dilations, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  Conv2dTransposeDoubleGradOp : public pir::Op<Conv2dTransposeDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_double_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::Value output_size() { return operand_source(5); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  Conv2dTransposeGradOp : public pir::Op<Conv2dTransposeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value output_size() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  Conv3dDoubleGradOp : public pir::Op<Conv3dDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  Conv3dGradOp : public pir::Op<Conv3dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  Conv3dTransposeGradOp : public pir::Op<Conv3dTransposeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_transpose_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  CopysignGradOp : public pir::Op<CopysignGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copysign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  CopysignGrad_Op : public pir::Op<CopysignGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.copysign_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  CorrelationGradOp : public pir::Op<CorrelationGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.correlation_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input1_, pir::Value input2_, pir::Value out_grad_, int pad_size, int kernel_size, int max_displacement, int stride1, int stride2, int corr_type_multiply=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input1_, pir::Value input2_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input1() { return operand_source(0); }
  pir::Value input2() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input1_grad() { return result(0); }
  pir::Value input2_grad() { return result(1); }

};

class  CosDoubleGradOp : public pir::Op<CosDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  CosDoubleGrad_Op : public pir::Op<CosDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  CosGradOp : public pir::Op<CosGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CosGrad_Op : public pir::Op<CosGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CosTripleGradOp : public pir::Op<CosTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  CosTripleGrad_Op : public pir::Op<CosTripleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cos_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  CoshGradOp : public pir::Op<CoshGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CoshGrad_Op : public pir::Op<CoshGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cosh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CropGradOp : public pir::Op<CropGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.crop_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& offsets);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value offsets_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value offsets() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  CrossEntropyWithSoftmaxGradOp : public pir::Op<CrossEntropyWithSoftmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value label() { return operand_source(0); }
  pir::Value softmax() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  CrossEntropyWithSoftmaxGrad_Op : public pir::Op<CrossEntropyWithSoftmaxGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_entropy_with_softmax_grad_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool soft_label, bool use_softmax, bool numeric_stable_mode, int ignore_index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value label() { return operand_source(0); }
  pir::Value softmax() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  CrossGradOp : public pir::Op<CrossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  CudnnLstmGradOp : public pir::Op<CudnnLstmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cudnn_lstm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value init_h_, pir::Value init_c_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value reserve_, pir::Value state_out_, pir::Value out_grad_, pir::Value last_h_grad_, pir::Value last_c_grad_, float dropout_prob=0.0, bool is_bidirec=false, int hidden_size=100, int num_layers=1, bool is_test=false, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value init_h_, pir::Value init_c_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value reserve_, pir::Value state_out_, pir::Value out_grad_, pir::Value last_h_grad_, pir::Value last_c_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value init_h() { return operand_source(1); }
  pir::Value init_c() { return operand_source(2); }
  pir::Value weight_list() { return operand_source(3); }
  pir::Value sequence_length() { return operand_source(4); }
  pir::Value out() { return operand_source(5); }
  pir::Value reserve() { return operand_source(6); }
  pir::Value state_out() { return operand_source(7); }
  pir::Value out_grad() { return operand_source(8); }
  pir::Value last_h_grad() { return operand_source(9); }
  pir::Value last_c_grad() { return operand_source(10); }
  pir::Value x_grad() { return result(0); }
  pir::Value init_h_grad() { return result(1); }
  pir::Value init_c_grad() { return result(2); }
  pir::Value weight_list_grad() { return result(3); }

};

class  CummaxGradOp : public pir::Op<CummaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummax_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  CumminGradOp : public pir::Op<CumminGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cummin_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  CumprodGradOp : public pir::Op<CumprodGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumprod_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int dim, bool exclusive, bool reverse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  CumsumGradOp : public pir::Op<CumsumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cumsum_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis, bool flatten, bool exclusive, bool reverse);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool flatten, bool exclusive, bool reverse);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  CvmGradOp : public pir::Op<CvmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cvm_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::Value out_grad_, bool use_cvm=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cvm() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  DeformableConvGradOp : public pir::Op<DeformableConvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.deformable_conv_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations, int deformable_groups, int groups, int im2col_step);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value offset_, pir::Value filter_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value offset() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value mask() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value offset_grad() { return result(1); }
  pir::Value filter_grad() { return result(2); }
  pir::Value mask_grad() { return result(3); }

};

class  DepthwiseConv2dDoubleGradOp : public pir::Op<DepthwiseConv2dDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value grad_out_, pir::Value grad_input_grad_, pir::Value grad_filter_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_input_grad() { return operand_source(3); }
  pir::Value grad_filter_grad() { return operand_source(4); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  DepthwiseConv2dGradOp : public pir::Op<DepthwiseConv2dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  DepthwiseConv2dTransposeGradOp : public pir::Op<DepthwiseConv2dTransposeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.depthwise_conv2d_transpose_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value output_size() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  DetGradOp : public pir::Op<DetGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.det_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  DiagGradOp : public pir::Op<DiagGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diag_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  DiagonalGradOp : public pir::Op<DiagonalGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.diagonal_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset=0, int axis1=0, int axis2=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  DigammaGradOp : public pir::Op<DigammaGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.digamma_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  DistGradOp : public pir::Op<DistGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dist_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, float p);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  DotGradOp : public pir::Op<DotGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dot_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  DropoutGradOp : public pir::Op<DropoutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dropout_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_, pir::Value out_grad_, float p, bool is_test, const std::string& mode);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_, pir::Value out_grad_, pir::Value p_, bool is_test, const std::string& mode);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value mask() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value p() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  EigGradOp : public pir::Op<EigGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eig_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_w_, pir::Value out_v_, pir::Value out_w_grad_, pir::Value out_v_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_w() { return operand_source(0); }
  pir::Value out_v() { return operand_source(1); }
  pir::Value out_w_grad() { return operand_source(2); }
  pir::Value out_v_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  EighGradOp : public pir::Op<EighGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_w_, pir::Value out_v_, pir::Value out_w_grad_, pir::Value out_v_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_w() { return operand_source(0); }
  pir::Value out_v() { return operand_source(1); }
  pir::Value out_w_grad() { return operand_source(2); }
  pir::Value out_v_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  EigvalshGradOp : public pir::Op<EigvalshGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.eigvalsh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value eigenvectors_, pir::Value eigenvalues_grad_, const std::string& uplo, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value eigenvectors_, pir::Value eigenvalues_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value eigenvectors() { return operand_source(0); }
  pir::Value eigenvalues_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  EluDoubleGradOp : public pir::Op<EluDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  EluDoubleGrad_Op : public pir::Op<EluDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  EluGradOp : public pir::Op<EluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  EluGrad_Op : public pir::Op<EluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  EmbeddingWithScaledGradientGradOp : public pir::Op<EmbeddingWithScaledGradientGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_with_scaled_gradient_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  ErfGradOp : public pir::Op<ErfGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erf_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ErfinvGradOp : public pir::Op<ErfinvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.erfinv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ExpDoubleGradOp : public pir::Op<ExpDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  ExpGradOp : public pir::Op<ExpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ExpGrad_Op : public pir::Op<ExpGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exp_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ExpandAsGradOp : public pir::Op<ExpandAsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_as_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& target_shape);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ExpandDoubleGradOp : public pir::Op<ExpandDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& shape);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ExpandGradOp : public pir::Op<ExpandGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expand_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value shape() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  Expm1GradOp : public pir::Op<Expm1GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Expm1Grad_Op : public pir::Op<Expm1Grad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FakeChannelWiseQuantizeDequantizeAbsMaxGradOp : public pir::Op<FakeChannelWiseQuantizeDequantizeAbsMaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_channel_wise_quantize_dequantize_abs_max_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int bit_length=8, int round_type=1, int quant_axis=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FakeQuantizeDequantizeAbsMaxGradOp : public pir::Op<FakeQuantizeDequantizeAbsMaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_dequantize_abs_max_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int bit_length=8, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FakeQuantizeDequantizeMovingAverageAbsMaxGradOp : public pir::Op<FakeQuantizeDequantizeMovingAverageAbsMaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fake_quantize_dequantize_moving_average_abs_max_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float moving_rate=0.9, int bit_length=8, bool is_test=false, int round_type=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FftC2cGradOp : public pir::Op<FftC2cGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2c_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FftC2rGradOp : public pir::Op<FftC2rGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_c2r_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, int64_t last_dim_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FftR2cGradOp : public pir::Op<FftR2cGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fft_r2c_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::string& normalization, bool forward, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FillDiagonalGradOp : public pir::Op<FillDiagonalGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value, int offset, bool wrap);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FillDiagonalTensorGradOp : public pir::Op<FillDiagonalTensorGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int64_t offset, int dim1, int dim2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FillDiagonalTensorGrad_Op : public pir::Op<FillDiagonalTensorGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_diagonal_tensor_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int64_t offset, int dim1, int dim2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FillGradOp : public pir::Op<FillGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FillGrad_Op : public pir::Op<FillGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fill_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value value_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value value() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FlashAttnGradOp : public pir::Op<FlashAttnGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, float dropout=0.0, bool causal=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value softmax_lse() { return operand_source(4); }
  pir::Value seed_offset() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  FlashAttnQkvpackedGradOp : public pir::Op<FlashAttnQkvpackedGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_qkvpacked_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, float dropout=0.0, bool causal=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value softmax_lse() { return operand_source(2); }
  pir::Value seed_offset() { return operand_source(3); }
  pir::Value attn_mask() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value qkv_grad() { return result(0); }

};

class  FlashAttnUnpaddedGradOp : public pir::Op<FlashAttnUnpaddedGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_unpadded_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, float scale, float dropout=0.0, bool causal=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value cu_seqlens_q() { return operand_source(3); }
  pir::Value cu_seqlens_k() { return operand_source(4); }
  pir::Value out() { return operand_source(5); }
  pir::Value softmax_lse() { return operand_source(6); }
  pir::Value seed_offset() { return operand_source(7); }
  pir::Value attn_mask() { return operand_source(8); }
  pir::Value out_grad() { return operand_source(9); }
  pir::Value max_seqlen_q() { return operand_source(10); }
  pir::Value max_seqlen_k() { return operand_source(11); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  FlashAttnV3GradOp : public pir::Op<FlashAttnV3GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_v3_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value out_grad_, float softmax_scale, bool is_causal, int window_size_left, int window_size_right, float softcap, int sm_margin);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value out_, pir::Value softmax_lse_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value softmax_lse() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  FlashAttnVarlenQkvpackedGradOp : public pir::Op<FlashAttnVarlenQkvpackedGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flash_attn_varlen_qkvpacked_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, int64_t max_seqlen_q, int64_t max_seqlen_k, float scale, float dropout=0.0, bool causal=false, bool varlen_padded=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, float scale, float dropout=0.0, bool causal=false, bool varlen_padded=true);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value attn_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value cu_seqlens_q() { return operand_source(1); }
  pir::Value cu_seqlens_k() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value softmax_lse() { return operand_source(4); }
  pir::Value seed_offset() { return operand_source(5); }
  pir::Value attn_mask() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value max_seqlen_q() { return operand_source(8); }
  pir::Value max_seqlen_k() { return operand_source(9); }
  pir::Value qkv_grad() { return result(0); }

};

class  FlashmaskAttentionGradOp : public pir::Op<FlashmaskAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flashmask_attention_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value startend_row_indices_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value out_grad_, float dropout=0.0, bool causal=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value startend_row_indices_, pir::Value out_, pir::Value softmax_lse_, pir::Value seed_offset_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value startend_row_indices() { return operand_source(3); }
  pir::Value out() { return operand_source(4); }
  pir::Value softmax_lse() { return operand_source(5); }
  pir::Value seed_offset() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  FlattenGradOp : public pir::Op<FlattenGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FlattenGrad_Op : public pir::Op<FlattenGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flatten_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FlipGradOp : public pir::Op<FlipGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.flip_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int>& axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FloorGradOp : public pir::Op<FloorGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FloorGrad_Op : public pir::Op<FloorGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FmaxGradOp : public pir::Op<FmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmax_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  FminGradOp : public pir::Op<FminGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fmin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  FoldGradOp : public pir::Op<FoldGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fold_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& output_sizes, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FractionalMaxPool2dGradOp : public pir::Op<FractionalMaxPool2dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fractional_max_pool2d_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& output_size, const std::vector<int>& kernel_size, float random_u, bool return_mask);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  FractionalMaxPool3dGradOp : public pir::Op<FractionalMaxPool3dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fractional_max_pool3d_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& output_size, const std::vector<int>& kernel_size, float random_u, bool return_mask);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  FrameGradOp : public pir::Op<FrameGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frame_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int frame_length, int hop_length, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FrobeniusNormGradOp : public pir::Op<FrobeniusNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.frobenius_norm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keep_dim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  FusedBatchNormActGradOp : public pir::Op<FusedBatchNormActGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_batch_norm_act_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value reserve_space() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  FusedBnAddActivationGradOp : public pir::Op<FusedBnAddActivationGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bn_add_activation_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value reserve_space() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value z_grad() { return result(1); }
  pir::Value scale_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  FusedSoftmaxMaskGradOp : public pir::Op<FusedSoftmaxMaskGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FusedSoftmaxMaskUpperTriangleGradOp : public pir::Op<FusedSoftmaxMaskUpperTriangleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_softmax_mask_upper_triangle_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value Out_, pir::Value Out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value Out() { return operand_source(0); }
  pir::Value Out_grad() { return operand_source(1); }
  pir::Value X_grad() { return result(0); }

};

class  GammainccGradOp : public pir::Op<GammainccGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaincc_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value y_grad() { return result(0); }

};

class  GammalnGradOp : public pir::Op<GammalnGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gammaln_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  GatherGradOp : public pir::Op<GatherGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, int axis=0);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  GatherNdDoubleGradOp : public pir::Op<GatherNdDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_nd_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_out() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_out_grad() { return result(0); }

};

class  GatherNdGradOp : public pir::Op<GatherNdGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gather_nd_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  GaussianInplaceGradOp : public pir::Op<GaussianInplaceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  GaussianInplaceGrad_Op : public pir::Op<GaussianInplaceGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gaussian_inplace_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float mean=0, float std=1.0, int seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class TEST_API GeluGradOp : public pir::Op<GeluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gelu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, bool approximate);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  GlobalGatherGradOp : public pir::Op<GlobalGatherGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.global_gather_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value local_count_, pir::Value global_count_, pir::Value out_grad_, int ring_id=0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value local_count() { return operand_source(0); }
  pir::Value global_count() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  GlobalScatterGradOp : public pir::Op<GlobalScatterGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.global_scatter_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value local_count_, pir::Value global_count_, pir::Value out_grad_, int ring_id=0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value local_count() { return operand_source(0); }
  pir::Value global_count() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  GridSampleGradOp : public pir::Op<GridSampleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.grid_sample_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::Value out_grad_, const std::string& mode, const std::string& padding_mode, bool align_corners);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grid_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grid() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grid_grad() { return result(1); }

};

class  GroupNormGradOp : public pir::Op<GroupNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, float epsilon, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value y_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  GroupNormGrad_Op : public pir::Op<GroupNormGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm_grad_"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, float epsilon, int groups, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value y_, pir::Value mean_, pir::Value variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value y() { return operand_source(3); }
  pir::Value mean() { return operand_source(4); }
  pir::Value variance() { return operand_source(5); }
  pir::Value y_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  GruGradOp : public pir::Op<GruGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gru_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value weight_, pir::Value bias_, pir::Value batch_gate_, pir::Value batch_reset_hidden_prev_, pir::Value batch_hidden_, pir::Value hidden_, pir::Value hidden_grad_, const std::string& activation="tanh", const std::string& gate_activation="sigmoid", bool is_reverse=false, bool origin_mode=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value weight_, pir::Value bias_, pir::Value batch_gate_, pir::Value batch_reset_hidden_prev_, pir::Value batch_hidden_, pir::Value hidden_, pir::Value hidden_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value batch_gate() { return operand_source(4); }
  pir::Value batch_reset_hidden_prev() { return operand_source(5); }
  pir::Value batch_hidden() { return operand_source(6); }
  pir::Value hidden() { return operand_source(7); }
  pir::Value hidden_grad() { return operand_source(8); }
  pir::Value input_grad() { return result(0); }
  pir::Value h0_grad() { return result(1); }
  pir::Value weight_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  GruUnitGradOp : public pir::Op<GruUnitGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gru_unit_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value hidden_prev_, pir::Value weight_, pir::Value bias_, pir::Value gate_, pir::Value reset_hidden_prev_, pir::Value hidden_grad_, int activation, int gate_activation, bool origin_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value hidden_prev_, pir::Value weight_, pir::Value bias_, pir::Value gate_, pir::Value reset_hidden_prev_, pir::Value hidden_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value hidden_prev() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value gate() { return operand_source(4); }
  pir::Value reset_hidden_prev() { return operand_source(5); }
  pir::Value hidden_grad() { return operand_source(6); }
  pir::Value input_grad() { return result(0); }
  pir::Value hidden_prev_grad() { return result(1); }
  pir::Value weight_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  GumbelSoftmaxGradOp : public pir::Op<GumbelSoftmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gumbel_softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardshrinkGradOp : public pir::Op<HardshrinkGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardshrinkGrad_Op : public pir::Op<HardshrinkGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardshrink_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardsigmoidGradOp : public pir::Op<HardsigmoidGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float slope, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardsigmoidGrad_Op : public pir::Op<HardsigmoidGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardsigmoid_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float slope, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardtanhGradOp : public pir::Op<HardtanhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float t_min, float t_max);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardtanhGrad_Op : public pir::Op<HardtanhGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardtanh_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float t_min, float t_max);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HeavisideGradOp : public pir::Op<HeavisideGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.heaviside_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  HingeLossGradOp : public pir::Op<HingeLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hinge_loss_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value labels_, pir::Value loss_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value labels() { return operand_source(1); }
  pir::Value loss_grad() { return operand_source(2); }
  pir::Value logits_grad() { return result(0); }

};

class  HsigmoidLossGradOp : public pir::Op<HsigmoidLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hsigmoid_loss_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value label_, pir::Value path_, pir::Value code_, pir::Value bias_, pir::Value pre_out_, pir::Value out_grad_, int num_classes, bool is_sparse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value label_, pir::Value path_, pir::Value code_, pir::Value bias_, pir::Value pre_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value label() { return operand_source(2); }
  pir::Value path() { return operand_source(3); }
  pir::Value code() { return operand_source(4); }
  pir::Value bias() { return operand_source(5); }
  pir::Value pre_out() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value w_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  HuberLossGradOp : public pir::Op<HuberLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.huber_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value residual_, pir::Value out_grad_, float delta);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value residual_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value residual() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value input_grad() { return result(0); }
  pir::Value label_grad() { return result(1); }

};

class  I0GradOp : public pir::Op<I0GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  I0eGradOp : public pir::Op<I0eGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i0e_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  I1GradOp : public pir::Op<I1GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  I1eGradOp : public pir::Op<I1eGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.i1e_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  IdentityLossGradOp : public pir::Op<IdentityLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  IdentityLossGrad_Op : public pir::Op<IdentityLossGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.identity_loss_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ImagGradOp : public pir::Op<ImagGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.imag_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  IndexAddDoubleGradOp : public pir::Op<IndexAddDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value index() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_add_value_grad() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class  IndexAddGradOp : public pir::Op<IndexAddGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value index() { return operand_source(0); }
  pir::Value add_value() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value add_value_grad() { return result(1); }

};

class  IndexAddGrad_Op : public pir::Op<IndexAddGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_add_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value add_value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value index() { return operand_source(0); }
  pir::Value add_value() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value add_value_grad() { return result(1); }

};

class  IndexElementwiseGetGradOp : public pir::Op<IndexElementwiseGetGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_elementwise_get_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, const std::vector<int64_t>& input_dims, const std::vector<int64_t>& input_strides, const std::vector<int64_t>& index_dims, const std::vector<int64_t>& index_stride);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  IndexElementwisePutGradOp : public pir::Op<IndexElementwisePutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_elementwise_put_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, pir::Value out_grad_, const std::vector<int64_t>& input_dims, const std::vector<int64_t>& input_strides, const std::vector<int64_t>& index_dims, const std::vector<int64_t>& index_strides, int64_t slice_offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value value_grad() { return result(1); }

};

class  IndexPutDoubleGradOp : public pir::Op<IndexPutDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_value_grad() { return operand_source(4); }
  pir::Value grad_out_grad() { return result(0); }

};

class  IndexPutGradOp : public pir::Op<IndexPutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_put_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::Value out_grad_, bool accumulate=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value value_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value value_grad() { return result(1); }

};

class  IndexSampleGradOp : public pir::Op<IndexSampleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_sample_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  IndexSelectDoubleGradOp : public pir::Op<IndexSelectDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value grad_x_grad_, int axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value index() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  IndexSelectGradOp : public pir::Op<IndexSelectGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  IndexSelectStridedGradOp : public pir::Op<IndexSelectStridedGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.index_select_strided_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int64_t index, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  InstanceNormDoubleGradOp : public pir::Op<InstanceNormDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_y_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_y_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value saved_mean() { return operand_source(2); }
  pir::Value saved_variance() { return operand_source(3); }
  pir::Value grad_y() { return operand_source(4); }
  pir::Value grad_x_grad() { return operand_source(5); }
  pir::Value grad_scale_grad() { return operand_source(6); }
  pir::Value grad_bias_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value grad_y_grad() { return result(2); }

};

class  InstanceNormGradOp : public pir::Op<InstanceNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.instance_norm_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value y_grad_, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value saved_mean() { return operand_source(2); }
  pir::Value saved_variance() { return operand_source(3); }
  pir::Value y_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  InverseGradOp : public pir::Op<InverseGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.inverse_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  KldivLossGradOp : public pir::Op<KldivLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kldiv_loss_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value out_grad_, const std::string& reduction, bool log_target);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  KronGradOp : public pir::Op<KronGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kron_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  KthvalueGradOp : public pir::Op<KthvalueGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.kthvalue_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int k, int axis, bool keepdim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  L1NormGradOp : public pir::Op<L1NormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.l1_norm_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LabelSmoothGradOp : public pir::Op<LabelSmoothGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.label_smooth_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value label_grad() { return result(0); }

};

class  LayerNormGradOp : public pir::Op<LayerNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::Value out_grad_, float epsilon=1e-5, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_, pir::Value variance_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean() { return operand_source(3); }
  pir::Value variance() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  LeakyReluDoubleGradOp : public pir::Op<LeakyReluDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  LeakyReluDoubleGrad_Op : public pir::Op<LeakyReluDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  LeakyReluGradOp : public pir::Op<LeakyReluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LeakyReluGrad_Op : public pir::Op<LeakyReluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float negative_slope);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LerpGradOp : public pir::Op<LerpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lerp_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value weight_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  LgammaGradOp : public pir::Op<LgammaGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lgamma_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LinearInterpGradOp : public pir::Op<LinearInterpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.linear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_format, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  Log10GradOp : public pir::Op<Log10GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log10Grad_Op : public pir::Op<Log10Grad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log10_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log1pGradOp : public pir::Op<Log1pGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log1pGrad_Op : public pir::Op<Log1pGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log2GradOp : public pir::Op<Log2GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log2Grad_Op : public pir::Op<Log2Grad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log2_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogDoubleGradOp : public pir::Op<LogDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  LogDoubleGrad_Op : public pir::Op<LogDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  LogGradOp : public pir::Op<LogGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogGrad_Op : public pir::Op<LogGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogLossGradOp : public pir::Op<LogLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_loss_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value input_grad() { return result(0); }

};

class  LogSoftmaxGradOp : public pir::Op<LogSoftmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log_softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogcumsumexpGradOp : public pir::Op<LogcumsumexpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logcumsumexp_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int axis, bool flatten, bool exclusive, bool reverse);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};


class  LogitGradOp : public pir::Op<LogitGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logit_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float eps);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogsigmoidGradOp : public pir::Op<LogsigmoidGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogsigmoidGrad_Op : public pir::Op<LogsigmoidGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsigmoid_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LogsumexpGradOp : public pir::Op<LogsumexpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.logsumexp_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& axis, bool keepdim, bool reduce_all);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  LpPool2dGradOp : public pir::Op<LpPool2dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lp_pool2d_grad"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm, float norm_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  LstmGradOp : public pir::Op<LstmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lstm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value c0_, pir::Value weight_, pir::Value bias_, pir::Value hidden_, pir::Value cell_, pir::Value batch_gate_, pir::Value batch_cell_pre_act_, pir::Value hidden_grad_, bool use_peepholes, bool is_reverse, bool is_test, const std::string& gate_activation, const std::string& cell_activation, const std::string& candidate_activation);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value h0_, pir::Value c0_, pir::Value weight_, pir::Value bias_, pir::Value hidden_, pir::Value cell_, pir::Value batch_gate_, pir::Value batch_cell_pre_act_, pir::Value hidden_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value c0() { return operand_source(2); }
  pir::Value weight() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value hidden() { return operand_source(5); }
  pir::Value cell() { return operand_source(6); }
  pir::Value batch_gate() { return operand_source(7); }
  pir::Value batch_cell_pre_act() { return operand_source(8); }
  pir::Value hidden_grad() { return operand_source(9); }
  pir::Value input_grad() { return result(0); }
  pir::Value h0_grad() { return result(1); }
  pir::Value c0_grad() { return result(2); }
  pir::Value weight_grad() { return result(3); }
  pir::Value bias_grad() { return result(4); }

};

class  LuGradOp : public pir::Op<LuGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, bool pivot);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  LuGrad_Op : public pir::Op<LuGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, bool pivot);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value pivots_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  LuSolveGradOp : public pir::Op<LuSolveGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_solve_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value b_, pir::Value lu_, pir::Value pivots_, pir::Value out_, pir::Value out_grad_, const std::string& trans);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value b_, pir::Value lu_, pir::Value pivots_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value b() { return operand_source(0); }
  pir::Value lu() { return operand_source(1); }
  pir::Value pivots() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value b_grad() { return result(0); }
  pir::Value lu_grad() { return result(1); }

};

class  LuUnpackGradOp : public pir::Op<LuUnpackGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lu_unpack_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value l_, pir::Value u_, pir::Value pmat_, pir::Value l_grad_, pir::Value u_grad_, bool unpack_ludata, bool unpack_pivots);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value l_, pir::Value u_, pir::Value pmat_, pir::Value l_grad_, pir::Value u_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value l() { return operand_source(2); }
  pir::Value u() { return operand_source(3); }
  pir::Value pmat() { return operand_source(4); }
  pir::Value l_grad() { return operand_source(5); }
  pir::Value u_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }

};

class  MarginCrossEntropyGradOp : public pir::Op<MarginCrossEntropyGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool return_softmax, int ring_id, int rank, int nranks, float margin1, float margin2, float margin3, float scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::Value logits_grad() { return result(0); }

};

class  MarginCrossEntropyGrad_Op : public pir::Op<MarginCrossEntropyGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.margin_cross_entropy_grad_"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, bool return_softmax, int ring_id, int rank, int nranks, float margin1, float margin2, float margin3, float scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value softmax_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value softmax() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::Value logits_grad() { return result(0); }

};

class  MaskedFillDoubleGradOp : public pir::Op<MaskedFillDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_fill_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value mask() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_value_grad() { return operand_source(2); }
  pir::Value grad_out_grad() { return result(0); }

};

class  MaskedFillGradOp : public pir::Op<MaskedFillGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_fill_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value value_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value value_grad() { return result(1); }

};

class  MaskedFillGrad_Op : public pir::Op<MaskedFillGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_fill_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value value_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value value_grad() { return result(1); }

};

class  MaskedSelectGradOp : public pir::Op<MaskedSelectGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_select_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MatchMatrixTensorGradOp : public pir::Op<MatchMatrixTensorGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.match_matrix_tensor_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::Value tmp_, pir::Value out_grad_, int dim_t=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_, pir::Value tmp_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value tmp() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value w_grad() { return result(2); }

};

class  MatrixPowerGradOp : public pir::Op<MatrixPowerGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matrix_power_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MaxGradOp : public pir::Op<MaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  MaxPool2dWithIndexGradOp : public pir::Op<MaxPool2dWithIndexGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_with_index_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool global_pooling, bool adaptive, bool ceil_mode=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MaxPool3dWithIndexGradOp : public pir::Op<MaxPool3dWithIndexGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool3d_with_index_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, bool global_pooling, bool adaptive, bool ceil_mode=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MaxoutGradOp : public pir::Op<MaxoutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxout_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, int groups, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MeanAllGradOp : public pir::Op<MeanAllGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_all_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  MeanDoubleGradOp : public pir::Op<MeanDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  MeanGradOp : public pir::Op<MeanGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mean_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MemoryEfficientAttentionGradOp : public pir::Op<MemoryEfficientAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memory_efficient_attention_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value output_, pir::Value logsumexp_, pir::Value seed_and_offset_, pir::Value output_grad_, int64_t max_seqlen_q, int64_t max_seqlen_k, bool causal, double dropout_p, float scale);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value output_, pir::Value logsumexp_, pir::Value seed_and_offset_, pir::Value output_grad_, pir::Value max_seqlen_q_, pir::Value max_seqlen_k_, bool causal, double dropout_p, float scale);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value bias_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value output_, pir::Value logsumexp_, pir::Value seed_and_offset_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlens_q() { return operand_source(4); }
  pir::Value cu_seqlens_k() { return operand_source(5); }
  pir::Value output() { return operand_source(6); }
  pir::Value logsumexp() { return operand_source(7); }
  pir::Value seed_and_offset() { return operand_source(8); }
  pir::Value output_grad() { return operand_source(9); }
  pir::Value max_seqlen_q() { return operand_source(10); }
  pir::Value max_seqlen_k() { return operand_source(11); }
  pir::Value query_grad() { return result(0); }
  pir::Value key_grad() { return result(1); }
  pir::Value value_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  MeshgridGradOp : public pir::Op<MeshgridGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.meshgrid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value inputs_grad() { return result(0); }

};

class  MishGradOp : public pir::Op<MishGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  MishGrad_Op : public pir::Op<MishGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mish_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float lambda);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ModeGradOp : public pir::Op<ModeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mode_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int axis, bool keepdim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MoeCombineGradOp : public pir::Op<MoeCombineGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_combine_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weights_, pir::Value scatter_index_, pir::Value y_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value combine_weights() { return operand_source(1); }
  pir::Value scatter_index() { return operand_source(2); }
  pir::Value y_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value combine_weights_grad() { return result(1); }

};

class  MoeCombineNoWeightGradOp : public pir::Op<MoeCombineNoWeightGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_combine_no_weight_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weight_, pir::Value scatter_index_, pir::Value y_grad_, float epsilon=1.0e-15);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value combine_weight_, pir::Value scatter_index_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value combine_weight() { return operand_source(1); }
  pir::Value scatter_index() { return operand_source(2); }
  pir::Value y_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  MoeGateDispatchGradOp : public pir::Op<MoeGateDispatchGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_, pir::Value scatter_index_, pir::Value expert_id_, pir::Value y_grad_, pir::Value combine_weights_grad_, int64_t k, int64_t capacity, bool use_pad);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_, pir::Value scatter_index_, pir::Value expert_id_, pir::Value y_grad_, pir::Value combine_weights_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value combine_weights() { return operand_source(0); }
  pir::Value scatter_index() { return operand_source(1); }
  pir::Value expert_id() { return operand_source(2); }
  pir::Value y_grad() { return operand_source(3); }
  pir::Value combine_weights_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value gate_logits_grad() { return result(1); }

};

class  MoeGateDispatchPartialNosoftmaxtopkGradOp : public pir::Op<MoeGateDispatchPartialNosoftmaxtopkGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch_partial_nosoftmaxtopk_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_out_, pir::Value scatter_index_, pir::Value scatter_index_rev_, pir::Value expert_offset_, pir::Value expert_nums_local_, pir::Value y_grad_, pir::Value combine_weights_out_grad_, int64_t k, int64_t capacity, bool use_pad, int64_t expert_start_index, int64_t expert_end_index);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_out_, pir::Value scatter_index_, pir::Value scatter_index_rev_, pir::Value expert_offset_, pir::Value expert_nums_local_, pir::Value y_grad_, pir::Value combine_weights_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value combine_weights_out() { return operand_source(0); }
  pir::Value scatter_index() { return operand_source(1); }
  pir::Value scatter_index_rev() { return operand_source(2); }
  pir::Value expert_offset() { return operand_source(3); }
  pir::Value expert_nums_local() { return operand_source(4); }
  pir::Value y_grad() { return operand_source(5); }
  pir::Value combine_weights_out_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value combine_weights_grad() { return result(1); }

};

class  MoeGateDispatchPermuteGradOp : public pir::Op<MoeGateDispatchPermuteGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moe_gate_dispatch_permute_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_, pir::Value scatter_index_, pir::Value expert_id_, pir::Value y_grad_, pir::Value combine_weights_grad_, int64_t k, int64_t capacity, int64_t world_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value combine_weights_, pir::Value scatter_index_, pir::Value expert_id_, pir::Value y_grad_, pir::Value combine_weights_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value combine_weights() { return operand_source(0); }
  pir::Value scatter_index() { return operand_source(1); }
  pir::Value expert_id() { return operand_source(2); }
  pir::Value y_grad() { return operand_source(3); }
  pir::Value combine_weights_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value gate_logits_grad() { return result(1); }

};

class  MpAllreduceSumGradOp : public pir::Op<MpAllreduceSumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mp_allreduce_sum_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int ring_id=0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  MultiDotGradOp : public pir::Op<MultiDotGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_dot_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  MultiplexGradOp : public pir::Op<MultiplexGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiplex_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::Value index_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value inputs_grad() { return result(0); }

};

class  MvGradOp : public pir::Op<MvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value vec_grad() { return result(1); }

};

class  NanmedianGradOp : public pir::Op<NanmedianGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nanmedian_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value medians_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value medians_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value medians() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  NearestInterpGradOp : public pir::Op<NearestInterpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nearest_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_format, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  NllLossGradOp : public pir::Op<NllLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nll_loss_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value total_weight_, pir::Value out_grad_, int64_t ignore_index, const std::string& reduction);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value total_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value total_weight() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value input_grad() { return result(0); }

};

class  NormGradOp : public pir::Op<NormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value norm_, pir::Value out_grad_, int axis, float epsilon, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value norm_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value norm() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  OverlapAddGradOp : public pir::Op<OverlapAddGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.overlap_add_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int hop_length, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PNormGradOp : public pir::Op<PNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.p_norm_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float porder, int axis, float epsilon, bool keepdim, bool asvector);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  Pad3dDoubleGradOp : public pir::Op<Pad3dDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d_double_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& paddings, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::Value paddings_, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value paddings() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  Pad3dGradOp : public pir::Op<Pad3dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad3d_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& paddings, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value paddings_, const std::string& mode, float pad_value, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value paddings() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  PadDoubleGradOp : public pir::Op<PadDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value pad_value() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  PadGradOp : public pir::Op<PadGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& paddings, float pad_value);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value pad_value_, const std::vector<int>& paddings);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value pad_value() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  PartialConcatGradOp : public pir::Op<PartialConcatGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_concat_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int start_index, int length);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PartialSumGradOp : public pir::Op<PartialSumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_sum_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int start_index, int length);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PixelShuffleGradOp : public pir::Op<PixelShuffleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_shuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int upscale_factor, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  PixelUnshuffleGradOp : public pir::Op<PixelUnshuffleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pixel_unshuffle_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int downscale_factor, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  PoissonGradOp : public pir::Op<PoissonGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.poisson_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  PolygammaGradOp : public pir::Op<PolygammaGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.polygamma_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int n);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Pool2dDoubleGradOp : public pir::Op<Pool2dDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d_double_grad"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::Value kernel_size_, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value kernel_size() { return operand_source(2); }
  pir::Value grad_out_grad() { return result(0); }

};

class  Pool2dGradOp : public pir::Op<Pool2dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool2d_grad"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value kernel_size_, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value kernel_size() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  Pool3dGradOp : public pir::Op<Pool3dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pool3d_grad"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& kernel_size, const std::vector<int64_t>& strides, const std::vector<int64_t>& paddings, bool ceil_mode, bool exclusive, const std::string& data_format, const std::string& pooling_type, bool global_pooling, bool adaptive, const std::string& padding_algorithm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  PowDoubleGradOp : public pir::Op<PowDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  PowDoubleGrad_Op : public pir::Op<PowDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  PowGradOp : public pir::Op<PowGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float y=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PowGrad_Op : public pir::Op<PowGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float y=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PowTripleGradOp : public pir::Op<PowTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_x_grad_, pir::Value grad_grad_out_grad_, float y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_x_grad_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }
  pir::Value grad_grad_x_grad() { return result(2); }

};

class  PreluGradOp : public pir::Op<PreluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prelu_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::Value out_grad_, const std::string& data_format, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value alpha_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value alpha() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value alpha_grad() { return result(1); }

};

class  ProdGradOp : public pir::Op<ProdGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.prod_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keepdim, bool reduce_all);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  PsroiPoolGradOp : public pir::Op<PsroiPoolGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.psroi_pool_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, int pooled_height, int pooled_width, int output_channels, float spatial_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  PutAlongAxisDoubleGradOp : public pir::Op<PutAlongAxisDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis_double_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::Value grad_values_grad() { return operand_source(3); }
  pir::Value grad_arr_grad() { return operand_source(4); }
  pir::Value grad_out_grad() { return result(0); }

};

class  PutAlongAxisGradOp : public pir::Op<PutAlongAxisGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.put_along_axis_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::Value out_, pir::Value out_grad_, int axis, const std::string& reduce, bool include_self);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value values_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value values() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value arr_grad() { return result(0); }
  pir::Value values_grad() { return result(1); }

};

class  QrGradOp : public pir::Op<QrGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qr_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value q_, pir::Value r_, pir::Value q_grad_, pir::Value r_grad_, const std::string& mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value q_, pir::Value r_, pir::Value q_grad_, pir::Value r_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value q() { return operand_source(1); }
  pir::Value r() { return operand_source(2); }
  pir::Value q_grad() { return operand_source(3); }
  pir::Value r_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  RankAttentionGradOp : public pir::Op<RankAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rank_attention_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rank_offset_, pir::Value rank_param_, pir::Value input_help_, pir::Value ins_rank_, pir::Value out_grad_, int max_rank=3, int max_size=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rank_offset_, pir::Value rank_param_, pir::Value input_help_, pir::Value ins_rank_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value rank_offset() { return operand_source(1); }
  pir::Value rank_param() { return operand_source(2); }
  pir::Value input_help() { return operand_source(3); }
  pir::Value ins_rank() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value rank_param_grad() { return result(0); }

};

class  RealGradOp : public pir::Op<RealGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.real_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  ReciprocalGradOp : public pir::Op<ReciprocalGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReciprocalGrad_Op : public pir::Op<ReciprocalGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reciprocal_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReduceAsGradOp : public pir::Op<ReduceAsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reduce_as_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value target_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value target() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  Relu6GradOp : public pir::Op<Relu6GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Relu6Grad_Op : public pir::Op<Relu6Grad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReluDoubleGradOp : public pir::Op<ReluDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ReluDoubleGrad_Op : public pir::Op<ReluDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class TEST_API ReluGradOp : public pir::Op<ReluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReluGrad_Op : public pir::Op<ReluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  RenormGradOp : public pir::Op<RenormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.renorm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float p, int axis, float max_norm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  RepeatInterleaveDoubleGradOp : public pir::Op<RepeatInterleaveDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, int repeats, int axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value grad_out_grad() { return result(0); }

};

class  RepeatInterleaveGradOp : public pir::Op<RepeatInterleaveGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int repeats, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  RepeatInterleaveWithTensorIndexDoubleGradOp : public pir::Op<RepeatInterleaveWithTensorIndexDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_with_tensor_index_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value repeats_, pir::Value grad_x_grad_, int axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value repeats() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  RepeatInterleaveWithTensorIndexGradOp : public pir::Op<RepeatInterleaveWithTensorIndexGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.repeat_interleave_with_tensor_index_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeats_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value repeats() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  ReshapeDoubleGradOp : public pir::Op<ReshapeDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ReshapeDoubleGrad_Op : public pir::Op<ReshapeDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_out() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  ReshapeGradOp : public pir::Op<ReshapeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReshapeGrad_Op : public pir::Op<ReshapeGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReverseGradOp : public pir::Op<ReverseGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reverse_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int64_t>& axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  RmsNormGradOp : public pir::Op<RmsNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rms_norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::Value inv_var_, pir::Value out_grad_, float epsilon, int begin_norm_axis, float quant_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::Value inv_var_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value norm_weight() { return operand_source(3); }
  pir::Value norm_bias() { return operand_source(4); }
  pir::Value inv_var() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value norm_weight_grad() { return result(1); }
  pir::Value norm_bias_grad() { return result(2); }

};

class  RnnGradOp : public pir::Op<RnnGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rnn_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value dropout_state_out_, pir::Value reserve_, pir::Value out_grad_, pir::Value state_grad_, float dropout_prob, bool is_bidirec, int input_size, int hidden_size, int num_layers, const std::string& mode, int seed, bool is_test);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value pre_state_, pir::Value weight_list_, pir::Value sequence_length_, pir::Value out_, pir::Value dropout_state_out_, pir::Value reserve_, pir::Value out_grad_, pir::Value state_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value pre_state() { return operand_source(1); }
  pir::Value weight_list() { return operand_source(2); }
  pir::Value sequence_length() { return operand_source(3); }
  pir::Value out() { return operand_source(4); }
  pir::Value dropout_state_out() { return operand_source(5); }
  pir::Value reserve() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value state_grad() { return operand_source(8); }
  pir::Value x_grad() { return result(0); }
  pir::Value pre_state_grad() { return result(1); }
  pir::Value weight_list_grad() { return result(2); }

};

class  RoiAlignGradOp : public pir::Op<RoiAlignGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_align_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, int pooled_height, int pooled_width, float spatial_scale, int sampling_ratio, bool aligned);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  RoiPoolGradOp : public pir::Op<RoiPoolGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roi_pool_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value arg_max_, pir::Value out_grad_, int pooled_height, int pooled_width, float spatial_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value boxes_, pir::Value boxes_num_, pir::Value arg_max_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value boxes() { return operand_source(1); }
  pir::Value boxes_num() { return operand_source(2); }
  pir::Value arg_max() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  RollGradOp : public pir::Op<RollGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roll_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& shifts, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value shifts_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value shifts() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  RoundGradOp : public pir::Op<RoundGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  RoundGrad_Op : public pir::Op<RoundGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.round_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  RreluGradOp : public pir::Op<RreluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rrelu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value noise_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value noise() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  RsqrtDoubleGradOp : public pir::Op<RsqrtDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  RsqrtDoubleGrad_Op : public pir::Op<RsqrtDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  RsqrtGradOp : public pir::Op<RsqrtGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  RsqrtGrad_Op : public pir::Op<RsqrtGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.rsqrt_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ScaleGradOp : public pir::Op<ScaleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float scale=1.0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ScatterGradOp : public pir::Op<ScatterGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_, bool overwrite);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value index() { return operand_source(0); }
  pir::Value updates() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value updates_grad() { return result(1); }

};

class  ScatterNdAddGradOp : public pir::Op<ScatterNdAddGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scatter_nd_add_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value index_, pir::Value updates_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value index() { return operand_source(0); }
  pir::Value updates() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value updates_grad() { return result(1); }

};

class  SegmentPoolGradOp : public pir::Op<SegmentPoolGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.segment_pool_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::Value out_, pir::Value summed_ids_, pir::Value out_grad_, const std::string& pooltype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value segment_ids_, pir::Value out_, pir::Value summed_ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value segment_ids() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value summed_ids() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  SeluGradOp : public pir::Op<SeluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.selu_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, float scale, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SendURecvGradOp : public pir::Op<SendURecvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_u_recv_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, const std::string& reduce_op="SUM");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value src_index() { return operand_source(1); }
  pir::Value dst_index() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value dst_count() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value x_grad() { return result(0); }

};

class  SendUeRecvGradOp : public pir::Op<SendUeRecvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_ue_recv_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, const std::string& message_op, const std::string& reduce_op);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_, pir::Value dst_count_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out() { return operand_source(4); }
  pir::Value dst_count() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SendUvGradOp : public pir::Op<SendUvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_uv_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_grad_, const std::string& message_op="ADD");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value src_index_, pir::Value dst_index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value src_index() { return operand_source(2); }
  pir::Value dst_index() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SequenceConvGradOp : public pir::Op<SequenceConvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_conv_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value padding_data_, pir::Value filter_, pir::Value out_grad_, int context_length, bool padding_trainable=false, int context_start=0, int context_stride=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value padding_data_, pir::Value filter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value padding_data() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value padding_data_grad() { return result(1); }
  pir::Value filter_grad() { return result(2); }

};

class  SequencePoolGradOp : public pir::Op<SequencePoolGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_pool_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value max_index_, pir::Value out_grad_, bool is_test, const std::string& pooltype, float pad_value);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value max_index_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value max_index() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SetValueWithTensorGradOp : public pir::Op<SetValueWithTensorGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_with_tensor_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value values() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value steps() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value values_grad() { return result(1); }

};

class  ShuffleChannelGradOp : public pir::Op<ShuffleChannelGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_channel_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int group=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  SigmoidCrossEntropyWithLogitsGradOp : public pir::Op<SigmoidCrossEntropyWithLogitsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, bool normalize, int ignore_index);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  SigmoidCrossEntropyWithLogitsGrad_Op : public pir::Op<SigmoidCrossEntropyWithLogitsGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_cross_entropy_with_logits_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, bool normalize, int ignore_index);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value label_, pir::Value pos_weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value pos_weight() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  SigmoidDoubleGradOp : public pir::Op<SigmoidDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SigmoidDoubleGrad_Op : public pir::Op<SigmoidDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SigmoidGradOp : public pir::Op<SigmoidGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SigmoidGrad_Op : public pir::Op<SigmoidGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SigmoidTripleGradOp : public pir::Op<SigmoidTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_grad_x_, pir::Value grad_out_grad_, pir::Value grad_grad_out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_out_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::Value out_grad() { return result(0); }
  pir::Value fwd_grad_out_grad() { return result(1); }
  pir::Value grad_grad_x_grad() { return result(2); }

};

class  SigmoidTripleGrad_Op : public pir::Op<SigmoidTripleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sigmoid_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value fwd_grad_out_, pir::Value grad_grad_x_, pir::Value grad_out_grad_, pir::Value grad_grad_out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value fwd_grad_out() { return operand_source(1); }
  pir::Value grad_grad_x() { return operand_source(2); }
  pir::Value grad_out_grad() { return operand_source(3); }
  pir::Value grad_grad_out_grad() { return operand_source(4); }
  pir::Value out_grad() { return result(0); }
  pir::Value fwd_grad_out_grad() { return result(1); }
  pir::Value grad_grad_x_grad() { return result(2); }

};

class  SignGradOp : public pir::Op<SignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  SiluGradOp : public pir::Op<SiluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SiluGrad_Op : public pir::Op<SiluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SinDoubleGradOp : public pir::Op<SinDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SinDoubleGrad_Op : public pir::Op<SinDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SinGradOp : public pir::Op<SinGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinGrad_Op : public pir::Op<SinGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinTripleGradOp : public pir::Op<SinTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  SinTripleGrad_Op : public pir::Op<SinTripleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_x_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  SinhGradOp : public pir::Op<SinhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinhGrad_Op : public pir::Op<SinhGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SliceDoubleGradOp : public pir::Op<SliceDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_double_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_input_grad_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_input_grad() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value grad_out_grad() { return result(0); }

};

class  SliceGradOp : public pir::Op<SliceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes, const std::vector<int64_t>& infer_flags, const std::vector<int64_t>& decrease_axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }

};

class  SlogdetGradOp : public pir::Op<SlogdetGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slogdet_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SoftplusDoubleGradOp : public pir::Op<SoftplusDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SoftplusDoubleGrad_Op : public pir::Op<SoftplusDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_double_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SoftplusGradOp : public pir::Op<SoftplusGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftplusGrad_Op : public pir::Op<SoftplusGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softplus_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float beta, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftshrinkGradOp : public pir::Op<SoftshrinkGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftshrinkGrad_Op : public pir::Op<SoftshrinkGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softshrink_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftsignGradOp : public pir::Op<SoftsignGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftsignGrad_Op : public pir::Op<SoftsignGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softsign_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SolveGradOp : public pir::Op<SolveGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.solve_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SpectralNormGradOp : public pir::Op<SpectralNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.spectral_norm_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::Value out_grad_, int dim, int power_iters, float eps);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value u_, pir::Value v_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value weight() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value weight_grad() { return result(0); }

};

class  SplitWithNumGradOp : public pir::Op<SplitWithNumGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.split_with_num_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int axis=-1);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SqrtDoubleGradOp : public pir::Op<SqrtDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SqrtDoubleGrad_Op : public pir::Op<SqrtDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_x_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_x() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SqrtGradOp : public pir::Op<SqrtGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SqrtGrad_Op : public pir::Op<SqrtGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SquareDoubleGradOp : public pir::Op<SquareDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SquareDoubleGrad_Op : public pir::Op<SquareDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SquareGradOp : public pir::Op<SquareGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SquareGrad_Op : public pir::Op<SquareGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SquaredL2NormGradOp : public pir::Op<SquaredL2NormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squared_l2_norm_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SqueezeDoubleGradOp : public pir::Op<SqueezeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  SqueezeGradOp : public pir::Op<SqueezeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SqueezeGrad_Op : public pir::Op<SqueezeGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  StackDoubleGradOp : public pir::Op<StackDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stack_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, int axis=0);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value grad_out_grad() { return result(0); }

};

class  StackGradOp : public pir::Op<StackGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stack_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  StanhGradOp : public pir::Op<StanhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stanh_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float scale_a, float scale_b);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  StridedSliceGradOp : public pir::Op<StridedSliceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.strided_slice_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& strides);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, pir::Value strides_, const std::vector<int>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value strides() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  SumDoubleGradOp : public pir::Op<SumDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  SumGradOp : public pir::Op<SumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis, bool keepdim, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool keepdim, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SvdGradOp : public pir::Op<SvdGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svd_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value u_, pir::Value vh_, pir::Value s_, pir::Value u_grad_, pir::Value vh_grad_, pir::Value s_grad_, bool full_matrices);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value u_, pir::Value vh_, pir::Value s_, pir::Value u_grad_, pir::Value vh_grad_, pir::Value s_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value u() { return operand_source(1); }
  pir::Value vh() { return operand_source(2); }
  pir::Value s() { return operand_source(3); }
  pir::Value u_grad() { return operand_source(4); }
  pir::Value vh_grad() { return operand_source(5); }
  pir::Value s_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }

};

class  SvdvalsGradOp : public pir::Op<SvdvalsGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.svdvals_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value s_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value s_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SwigluGradOp : public pir::Op<SwigluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swiglu_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SwishGradOp : public pir::Op<SwishGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SwishGrad_Op : public pir::Op<SwishGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.swish_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SyncBatchNormGradOp : public pir::Op<SyncBatchNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value saved_mean() { return operand_source(3); }
  pir::Value saved_variance() { return operand_source(4); }
  pir::Value reserve_space() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  TakeAlongAxisDoubleGradOp : public pir::Op<TakeAlongAxisDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.take_along_axis_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value indices() { return operand_source(0); }
  pir::Value grad_arr_grad() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  TakeAlongAxisGradOp : public pir::Op<TakeAlongAxisGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.take_along_axis_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value arr_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value arr() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value arr_grad() { return result(0); }

};

class  TanGradOp : public pir::Op<TanGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanGrad_Op : public pir::Op<TanGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhDoubleGradOp : public pir::Op<TanhDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  TanhDoubleGrad_Op : public pir::Op<TanhDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_double_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  TanhGradOp : public pir::Op<TanhGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhGrad_Op : public pir::Op<TanhGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhShrinkGradOp : public pir::Op<TanhShrinkGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhShrinkGrad_Op : public pir::Op<TanhShrinkGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_shrink_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhTripleGradOp : public pir::Op<TanhTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_triple_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_out_new_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_out_new_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  TanhTripleGrad_Op : public pir::Op<TanhTripleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_triple_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value grad_out_forward_, pir::Value grad_x_grad_forward_, pir::Value grad_out_new_grad_, pir::Value grad_out_grad_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value grad_out_forward() { return operand_source(1); }
  pir::Value grad_x_grad_forward() { return operand_source(2); }
  pir::Value grad_out_new_grad() { return operand_source(3); }
  pir::Value grad_out_grad_grad() { return operand_source(4); }
  pir::Value out_grad() { return result(0); }
  pir::Value grad_out_forward_grad() { return result(1); }
  pir::Value grad_x_grad_forward_grad() { return result(2); }

};

class  TemporalShiftGradOp : public pir::Op<TemporalShiftGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.temporal_shift_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int seg_num, float shift_ratio, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  ThresholdedReluGradOp : public pir::Op<ThresholdedReluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold, float value);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ThresholdedReluGrad_Op : public pir::Op<ThresholdedReluGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.thresholded_relu_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float threshold, float value);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TopkGradOp : public pir::Op<TopkGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.topk_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, int k, int axis, bool largest, bool sorted);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::Value k_, int axis, bool largest, bool sorted);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value k() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  TraceGradOp : public pir::Op<TraceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trace_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, int offset, int axis1, int axis2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TransLayoutGradOp : public pir::Op<TransLayoutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trans_layout_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TransposeDoubleGradOp : public pir::Op<TransposeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int>& perm);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value grad_out_grad() { return result(0); }

};

class  TransposeGradOp : public pir::Op<TransposeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  TriangularSolveGradOp : public pir::Op<TriangularSolveGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triangular_solve_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, bool upper, bool transpose, bool unitriangular);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  TrilGradOp : public pir::Op<TrilGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tril_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  TrilinearInterpGradOp : public pir::Op<TrilinearInterpGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trilinear_interp_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, const std::string& data_format, int out_d, int out_h, int out_w, const std::vector<float>& scale, const std::string& interp_method, bool align_corners, int align_mode);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_size_, pir::Value size_tensor_, pir::Value scale_tensor_, pir::Value output_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_size() { return operand_source(1); }
  pir::Value size_tensor() { return operand_source(2); }
  pir::Value scale_tensor() { return operand_source(3); }
  pir::Value output_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  TriuGradOp : public pir::Op<TriuGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.triu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int diagonal);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  TruncGradOp : public pir::Op<TruncGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.trunc_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value input_grad() { return result(0); }

};

class  UnbindGradOp : public pir::Op<UnbindGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unbind_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value input_grad() { return result(0); }

};

class  UnfoldGradOp : public pir::Op<UnfoldGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unfold_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& kernel_sizes, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& dilations);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  UniformInplaceGradOp : public pir::Op<UniformInplaceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  UniformInplaceGrad_Op : public pir::Op<UniformInplaceGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.uniform_inplace_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, float min=-1.0, float max=1.0, int seed=0, int diag_num=0, int diag_step=0, float diag_val=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  UnsqueezeDoubleGradOp : public pir::Op<UnsqueezeDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& axis);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  UnsqueezeGradOp : public pir::Op<UnsqueezeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  UnsqueezeGrad_Op : public pir::Op<UnsqueezeGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unsqueeze_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  UnstackGradOp : public pir::Op<UnstackGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unstack_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  ViewDtypeGradOp : public pir::Op<ViewDtypeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.view_dtype_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value input_grad() { return result(0); }

};

class  WarpctcGradOp : public pir::Op<WarpctcGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warpctc_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value logits_length_, pir::Value warpctcgrad_, pir::Value loss_grad_, int blank, bool norm_by_times);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value logits_length_, pir::Value warpctcgrad_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value logits_length() { return operand_source(1); }
  pir::Value warpctcgrad() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::Value logits_grad() { return result(0); }

};

class  WarprnntGradOp : public pir::Op<WarprnntGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.warprnnt_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_lengths_, pir::Value warprnntgrad_, pir::Value loss_grad_, int blank=0, float fastemit_lambda=0.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value input_lengths_, pir::Value warprnntgrad_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value input_lengths() { return operand_source(1); }
  pir::Value warprnntgrad() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }

};

class  WeightOnlyLinearGradOp : public pir::Op<WeightOnlyLinearGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.weight_only_linear_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::Value out_grad_, const std::string& weight_dtype, int arch, int group_size);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value bias_, pir::Value weight_scale_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight_scale() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  WhereGradOp : public pir::Op<WhereGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  YoloLossGradOp : public pir::Op<YoloLossGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_loss_grad"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::Value objectness_mask_, pir::Value gt_match_mask_, pir::Value loss_grad_, const std::vector<int>& anchors, const std::vector<int>& anchor_mask, int class_num, float ignore_thresh, int downsample_ratio, bool use_label_smooth, float scale_x_y);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value gt_box_, pir::Value gt_label_, pir::Value gt_score_, pir::Value objectness_mask_, pir::Value gt_match_mask_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value gt_box() { return operand_source(1); }
  pir::Value gt_label() { return operand_source(2); }
  pir::Value gt_score() { return operand_source(3); }
  pir::Value objectness_mask() { return operand_source(4); }
  pir::Value gt_match_mask() { return operand_source(5); }
  pir::Value loss_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value gt_box_grad() { return result(1); }
  pir::Value gt_label_grad() { return result(2); }
  pir::Value gt_score_grad() { return result(3); }

};

class  BmmDoubleGradOp : public pir::Op<BmmDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bmm_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  DisableCheckModelNanInfGradOp : public pir::Op<DisableCheckModelNanInfGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.disable_check_model_nan_inf_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int unsetflag=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  EnableCheckModelNanInfGradOp : public pir::Op<EnableCheckModelNanInfGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.enable_check_model_nan_inf_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int unsetflag=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FusedRmsNormExtGradOp : public pir::Op<FusedRmsNormExtGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rms_norm_ext_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value invvar_, pir::Value y_grad_, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value invvar_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value invvar() { return operand_source(2); }
  pir::Value y_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }

};

class  Im2sequenceGradOp : public pir::Op<Im2sequenceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.im2sequence_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, const std::vector<int>& kernels, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0, 0, 0}, const std::vector<int>& out_stride={1, 1});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  PyramidHashGradOp : public pir::Op<PyramidHashGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pyramid_hash_grad"; }
  static const char *attributes_name[12];
  static constexpr uint32_t attributes_num = 12;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value drop_pos_, pir::Value x_temp_out_, pir::Value out_grad_, int num_emb=0, int space_len=0, int pyramid_layer=2, int rand_len=0, float drop_out_percent=0, int is_training=0, bool use_filter=true, int white_list_len=0, int black_list_len=0, int seed=0, float lr=0.0, const std::string& distribute_update_vars="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value drop_pos_, pir::Value x_temp_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value drop_pos() { return operand_source(2); }
  pir::Value x_temp_out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  ShuffleBatchGradOp : public pir::Op<ShuffleBatchGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shuffle_batch_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shuffle_idx_, pir::Value out_grad_, int startup_seed=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value shuffle_idx_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value shuffle_idx() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SiluDoubleGradOp : public pir::Op<SiluDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.silu_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value grad_out_grad() { return result(1); }

};

class  SparseAttentionGradOp : public pir::Op<SparseAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_attention_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value offset_, pir::Value columns_, pir::Value sparse_dot_sdd_, pir::Value softmax_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value offset() { return operand_source(3); }
  pir::Value columns() { return operand_source(4); }
  pir::Value sparse_dot_sdd() { return operand_source(5); }
  pir::Value softmax() { return operand_source(6); }
  pir::Value out_grad() { return operand_source(7); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  StftGradOp : public pir::Op<StftGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.stft_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value window_, pir::Value out_grad_, int n_fft, int hop_length, bool normalized, bool onesided);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value window_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value window() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  Unpool3dGradOp : public pir::Op<Unpool3dGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool3d_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_size, const std::string& data_format);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  UnpoolGradOp : public pir::Op<UnpoolGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unpool_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::vector<int64_t>& output_size, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::Value output_size_, const std::vector<int>& ksize, const std::vector<int>& strides, const std::vector<int>& padding, const std::string& data_format);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value indices_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value output_size() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  WhereDoubleGradOp : public pir::Op<WhereDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.where_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value condition() { return operand_source(0); }
  pir::Value grad_x_grad() { return operand_source(1); }
  pir::Value grad_y_grad() { return operand_source(2); }
  pir::Value grad_out_grad() { return result(0); }

};


class  AddActXpuOp : public pir::Op<AddActXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_act_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value y_, pir::Value y_max_, int act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value y_, pir::Value y_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value y_max() { return operand_source(3); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  AddLayernormXpuOp : public pir::Op<AddLayernormXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_layernorm_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  AddcmulXpuOp : public pir::Op<AddcmulXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addcmul_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value w_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  BlhaGetMaxLenOp : public pir::Op<BlhaGetMaxLenOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.blha_get_max_len"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value batch_size_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value seq_lens_encoder() { return operand_source(0); }
  pir::Value seq_lens_decoder() { return operand_source(1); }
  pir::Value batch_size() { return operand_source(2); }
  pir::Value max_enc_len_this_time() { return result(0); }
  pir::Value max_dec_len_this_time() { return result(1); }

};

class  BlockMultiheadAttention_Op : public pir::Op<BlockMultiheadAttention_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.block_multihead_attention_"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, int max_seq_len, int block_size, bool use_neox_style, bool dynamic_cachekv_quant=false, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0, float out_scale=-1, const std::string& compute_dtype="default", float rope_theta=10000.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value key_cache() { return operand_source(1); }
  pir::Value value_cache() { return operand_source(2); }
  pir::Value seq_lens_encoder() { return operand_source(3); }
  pir::Value seq_lens_decoder() { return operand_source(4); }
  pir::Value seq_lens_this_time() { return operand_source(5); }
  pir::Value padding_offsets() { return operand_source(6); }
  pir::Value cum_offsets() { return operand_source(7); }
  pir::Value cu_seqlens_q() { return operand_source(8); }
  pir::Value cu_seqlens_k() { return operand_source(9); }
  pir::Value block_tables() { return operand_source(10); }
  pir::Value pre_key_cache() { return operand_source(11); }
  pir::Value pre_value_cache() { return operand_source(12); }
  pir::Value rope_emb() { return operand_source(13); }
  pir::Value mask() { return operand_source(14); }
  pir::Value tgt_mask() { return operand_source(15); }
  pir::Value cache_k_quant_scales() { return operand_source(16); }
  pir::Value cache_v_quant_scales() { return operand_source(17); }
  pir::Value cache_k_dequant_scales() { return operand_source(18); }
  pir::Value cache_v_dequant_scales() { return operand_source(19); }
  pir::Value qkv_out_scale() { return operand_source(20); }
  pir::Value qkv_bias() { return operand_source(21); }
  pir::Value out_shift() { return operand_source(22); }
  pir::Value out_smooth() { return operand_source(23); }
  pir::Value max_enc_len_this_time() { return operand_source(24); }
  pir::Value max_dec_len_this_time() { return operand_source(25); }
  pir::Value fmha_out() { return result(0); }
  pir::Value qkv_out() { return result(1); }
  pir::Value key_cache_out() { return result(2); }
  pir::Value value_cache_out() { return result(3); }

};

class  BlockMultiheadAttentionXpuOp : public pir::Op<BlockMultiheadAttentionXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.block_multihead_attention_xpu"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value cache_k_per_batch_maxs_, pir::Value cache_v_per_batch_maxs_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, int max_seq_len, int block_size, bool use_neox_style, bool dynamic_cachekv_quant=false, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0, float out_scale=-1, const std::string& compute_dtype="default", float rope_theta=10000.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value cache_k_per_batch_maxs_, pir::Value cache_v_per_batch_maxs_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value key_cache() { return operand_source(1); }
  pir::Value value_cache() { return operand_source(2); }
  pir::Value seq_lens_encoder() { return operand_source(3); }
  pir::Value seq_lens_decoder() { return operand_source(4); }
  pir::Value seq_lens_this_time() { return operand_source(5); }
  pir::Value padding_offsets() { return operand_source(6); }
  pir::Value cum_offsets() { return operand_source(7); }
  pir::Value cu_seqlens_q() { return operand_source(8); }
  pir::Value cu_seqlens_k() { return operand_source(9); }
  pir::Value block_tables() { return operand_source(10); }
  pir::Value cache_k_per_batch_maxs() { return operand_source(11); }
  pir::Value cache_v_per_batch_maxs() { return operand_source(12); }
  pir::Value pre_key_cache() { return operand_source(13); }
  pir::Value pre_value_cache() { return operand_source(14); }
  pir::Value rope_emb() { return operand_source(15); }
  pir::Value mask() { return operand_source(16); }
  pir::Value tgt_mask() { return operand_source(17); }
  pir::Value cache_k_quant_scales() { return operand_source(18); }
  pir::Value cache_v_quant_scales() { return operand_source(19); }
  pir::Value cache_k_dequant_scales() { return operand_source(20); }
  pir::Value cache_v_dequant_scales() { return operand_source(21); }
  pir::Value qkv_out_scale() { return operand_source(22); }
  pir::Value qkv_bias() { return operand_source(23); }
  pir::Value out_shift() { return operand_source(24); }
  pir::Value out_smooth() { return operand_source(25); }
  pir::Value max_enc_len_this_time() { return operand_source(26); }
  pir::Value max_dec_len_this_time() { return operand_source(27); }
  pir::Value fmha_out() { return result(0); }
  pir::Value qkv_out() { return result(1); }
  pir::Value key_cache_out() { return result(2); }
  pir::Value value_cache_out() { return result(3); }

};

class  BlockMultiheadAttentionXpu_Op : public pir::Op<BlockMultiheadAttentionXpu_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.block_multihead_attention_xpu_"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value cache_k_per_batch_maxs_, pir::Value cache_v_per_batch_maxs_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, int max_seq_len, int block_size, bool use_neox_style, bool dynamic_cachekv_quant=false, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0, float out_scale=-1, const std::string& compute_dtype="default", float rope_theta=10000.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value qkv_, pir::Value key_cache_, pir::Value value_cache_, pir::Value seq_lens_encoder_, pir::Value seq_lens_decoder_, pir::Value seq_lens_this_time_, pir::Value padding_offsets_, pir::Value cum_offsets_, pir::Value cu_seqlens_q_, pir::Value cu_seqlens_k_, pir::Value block_tables_, pir::Value cache_k_per_batch_maxs_, pir::Value cache_v_per_batch_maxs_, pir::Value pre_key_cache_, pir::Value pre_value_cache_, pir::Value rope_emb_, pir::Value mask_, pir::Value tgt_mask_, pir::Value cache_k_quant_scales_, pir::Value cache_v_quant_scales_, pir::Value cache_k_dequant_scales_, pir::Value cache_v_dequant_scales_, pir::Value qkv_out_scale_, pir::Value qkv_bias_, pir::Value out_shift_, pir::Value out_smooth_, pir::Value max_enc_len_this_time_, pir::Value max_dec_len_this_time_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value qkv() { return operand_source(0); }
  pir::Value key_cache() { return operand_source(1); }
  pir::Value value_cache() { return operand_source(2); }
  pir::Value seq_lens_encoder() { return operand_source(3); }
  pir::Value seq_lens_decoder() { return operand_source(4); }
  pir::Value seq_lens_this_time() { return operand_source(5); }
  pir::Value padding_offsets() { return operand_source(6); }
  pir::Value cum_offsets() { return operand_source(7); }
  pir::Value cu_seqlens_q() { return operand_source(8); }
  pir::Value cu_seqlens_k() { return operand_source(9); }
  pir::Value block_tables() { return operand_source(10); }
  pir::Value cache_k_per_batch_maxs() { return operand_source(11); }
  pir::Value cache_v_per_batch_maxs() { return operand_source(12); }
  pir::Value pre_key_cache() { return operand_source(13); }
  pir::Value pre_value_cache() { return operand_source(14); }
  pir::Value rope_emb() { return operand_source(15); }
  pir::Value mask() { return operand_source(16); }
  pir::Value tgt_mask() { return operand_source(17); }
  pir::Value cache_k_quant_scales() { return operand_source(18); }
  pir::Value cache_v_quant_scales() { return operand_source(19); }
  pir::Value cache_k_dequant_scales() { return operand_source(20); }
  pir::Value cache_v_dequant_scales() { return operand_source(21); }
  pir::Value qkv_out_scale() { return operand_source(22); }
  pir::Value qkv_bias() { return operand_source(23); }
  pir::Value out_shift() { return operand_source(24); }
  pir::Value out_smooth() { return operand_source(25); }
  pir::Value max_enc_len_this_time() { return operand_source(26); }
  pir::Value max_dec_len_this_time() { return operand_source(27); }
  pir::Value fmha_out() { return result(0); }
  pir::Value qkv_out() { return result(1); }
  pir::Value key_cache_out() { return result(2); }
  pir::Value value_cache_out() { return result(3); }

};

class  BnActXpuOp : public pir::Op<BnActXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.bn_act_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, float momentum, float epsilon, const std::string& data_format, int act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }

};

class  Conv1dXpuOp : public pir::Op<Conv1dXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv1d_xpu"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, const std::vector<int>& paddings, const std::string& padding_algorithm, int dilations, int strides, int groups, int act_type, float act_param);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value branch() { return operand_source(5); }
  pir::Value branch_max() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  Conv2dTransposeXpuOp : public pir::Op<Conv2dTransposeXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_transpose_xpu"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, const std::vector<int>& strides, const std::vector<int>& paddings, const std::vector<int>& output_padding, const std::vector<int64_t>& output_size, const std::string& padding_algorithm, int groups, const std::vector<int>& dilations, const std::string& data_format, bool has_bias, bool with_act, const std::string& act_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  Conv2dXpuOp : public pir::Op<Conv2dXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv2d_xpu"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::Value scale_max_, pir::Value out_max_in_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, int act_type, float act_param, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::Value branch_max_, pir::Value scale_max_, pir::Value out_max_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value filter() { return operand_source(2); }
  pir::Value filter_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value branch() { return operand_source(5); }
  pir::Value branch_max() { return operand_source(6); }
  pir::Value scale_max() { return operand_source(7); }
  pir::Value out_max_in() { return operand_source(8); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  CrossAttentionXpuOp : public pir::Op<CrossAttentionXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cross_attention_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_q_, pir::Value input_kv_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value mask_, int head_num, int head_dim, float alpha, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_q_, pir::Value input_kv_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input_q() { return operand_source(0); }
  pir::Value input_kv() { return operand_source(1); }
  pir::Value fc_weight() { return operand_source(2); }
  pir::Value fc_weight_max() { return operand_source(3); }
  pir::Value fc_bias() { return operand_source(4); }
  pir::Value mask() { return operand_source(5); }
  pir::Value qkv() { return result(0); }
  pir::Value qkv_max() { return result(1); }

};

class  DequantizeXpuOp : public pir::Op<DequantizeXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType out_dtype, float scale=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return result(0); }

};

class  DistributedFusedLambInitOp : public pir::Op<DistributedFusedLambInitOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.distributed_fused_lamb_init"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, float beta1, float beta2, const std::vector<int>& apply_weight_decay, int alignment, int rank, int nranks);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value fp32_fused_param() { return result(0); }
  pir::Value fp32_fused_grad() { return result(1); }
  pir::Value fp16_fused_param() { return result(2); }
  pir::Value fp16_fused_grad() { return result(3); }
  pir::Value moment1() { return result(4); }
  pir::Value moment2() { return result(5); }
  pir::Value beta1_pow() { return result(6); }
  pir::Value beta2_pow() { return result(7); }
  pir::Value fused_param_offsets() { return result(8); }
  pir::Value fp32_shard_fused_param_offsets() { return result(9); }
  pir::Value fp16_shard_fused_param_offsets() { return result(10); }
  pir::Value param_info() { return result(11); }
  pir::Value param_order() { return result(12); }
  pir::Value param_out() { return result(13); }
  pir::Value master_param_out() { return result(14); }
  pir::Value grad_out() { return result(15); }
  pir::Value global_scale() { return result(16); }
  pir::Value step() { return result(17); }

};

class  DistributedFusedLambInit_Op : public pir::Op<DistributedFusedLambInit_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.distributed_fused_lamb_init_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, float beta1, float beta2, const std::vector<int>& apply_weight_decay, int alignment, int rank, int nranks);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value fp32_fused_param() { return result(0); }
  pir::Value fp32_fused_grad() { return result(1); }
  pir::Value fp16_fused_param() { return result(2); }
  pir::Value fp16_fused_grad() { return result(3); }
  pir::Value moment1() { return result(4); }
  pir::Value moment2() { return result(5); }
  pir::Value beta1_pow() { return result(6); }
  pir::Value beta2_pow() { return result(7); }
  pir::Value fused_param_offsets() { return result(8); }
  pir::Value fp32_shard_fused_param_offsets() { return result(9); }
  pir::Value fp16_shard_fused_param_offsets() { return result(10); }
  pir::Value param_info() { return result(11); }
  pir::Value param_order() { return result(12); }
  pir::Value param_out() { return result(13); }
  pir::Value master_param_out() { return result(14); }
  pir::Value grad_out() { return result(15); }
  pir::Value global_scale() { return result(16); }
  pir::Value step() { return result(17); }

};

class  EmbeddingWithEltwiseAddXpuOp : public pir::Op<EmbeddingWithEltwiseAddXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_with_eltwise_add_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value tables_, pir::Value mask_, int64_t padding_idx);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value tables_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value ids() { return operand_source(0); }
  pir::Value tables() { return operand_source(1); }
  pir::Value mask() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value seq_lod() { return result(1); }
  pir::Value max_seq_len() { return result(2); }

};

class  FastLayernormXpuOp : public pir::Op<FastLayernormXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fast_layernorm_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  FastWhereXpuOp : public pir::Op<FastWhereXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fast_where_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value condition_, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value condition() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  FcOp : public pir::Op<FcOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fc"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, int in_num_col_dims=1, const std::string& activation_type="", bool padding_weights=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  FcXpuOp : public pir::Op<FcXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fc_xpu"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value w_, pir::Value w_max_, pir::Value bias_, pir::Value scale_max_, pir::Value out_max_in_, int in_num_col_dims, bool transpose_x, float alpha, float beta, int act_type, float act_alpha, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value w_, pir::Value w_max_, pir::Value bias_, pir::Value scale_max_, pir::Value out_max_in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value w() { return operand_source(2); }
  pir::Value w_max() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value scale_max() { return operand_source(5); }
  pir::Value out_max_in() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  Fp8Fp8HalfGemmFusedOp : public pir::Op<Fp8Fp8HalfGemmFusedOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fp8_fp8_half_gemm_fused"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value bias_, bool transpose_x=false, bool transpose_y=false, float scale=1.0f, const std::string& output_dtype="float16", const std::string& activation_type="identity");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  FusedBiasActOp : public pir::Op<FusedBiasActOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_act"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value dequant_scales_, pir::Value shift_, pir::Value smooth_, const std::string& act_method="gelu", const std::string& compute_dtype="default", float quant_scale=-1, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value dequant_scales_, pir::Value shift_, pir::Value smooth_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value dequant_scales() { return operand_source(2); }
  pir::Value shift() { return operand_source(3); }
  pir::Value smooth() { return operand_source(4); }
  pir::Value out() { return result(0); }

};

class  FusedBiasDropoutResidualLayerNormOp : public pir::Op<FusedBiasDropoutResidualLayerNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_dropout_residual_layer_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, float dropout_rate=0.5f, bool is_test=false, bool dropout_fix_seed=true, int dropout_seed=true, const std::string& dropout_implementation="downgrade_in_infer", float ln_epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value residual() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value ln_scale() { return operand_source(3); }
  pir::Value ln_bias() { return operand_source(4); }
  pir::Value y() { return result(0); }
  pir::Value bias_dropout_residual_out() { return result(1); }
  pir::Value dropout_mask_out() { return result(2); }
  pir::Value ln_mean() { return result(3); }
  pir::Value ln_variance() { return result(4); }

};

class  FusedBiasResidualLayernormOp : public pir::Op<FusedBiasResidualLayernormOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_residual_layernorm"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, float epsilon, float residual_alpha, int begin_norm_axis, float quant_scale, int quant_round_type, float quant_max_bound, float quant_min_bound);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value bias_, pir::Value residual_, pir::Value norm_weight_, pir::Value norm_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value bias() { return operand_source(1); }
  pir::Value residual() { return operand_source(2); }
  pir::Value norm_weight() { return operand_source(3); }
  pir::Value norm_bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value residual_out() { return result(1); }
  pir::Value mean() { return result(2); }
  pir::Value variance() { return result(3); }

};

class TEST_API FusedConv2dAddActOp : public pir::Op<FusedConv2dAddActOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_conv2d_add_act"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value bias_, pir::Value residual_data_, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& padding_algorithm="EXPLICIT", const std::vector<int>& dilations={1, 1}, int groups=1, const std::string& data_format="NCHW", const std::string& activation="relu", const std::vector<int>& split_channels={}, bool exhaustive_search=false, int workspace_size_MB=32, float fuse_alpha=0.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value filter_, pir::Value bias_, pir::Value residual_data_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value residual_data() { return operand_source(3); }
  pir::Value output() { return result(0); }
  pir::Value outputs() { return result(1); }

};

class  FusedDconvDreluDbnOp : public pir::Op<FusedDconvDreluDbnOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dconv_drelu_dbn"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_output_, pir::Value weight_, pir::Value grad_output_add_, pir::Value residual_input_, pir::Value bn1_eqscale_, pir::Value bn1_eqbias_, pir::Value conv_input_, pir::Value bn1_mean_, pir::Value bn1_inv_std_, pir::Value bn1_gamma_, pir::Value bn1_beta_, pir::Value bn1_input_, pir::Value bn2_mean_, pir::Value bn2_inv_std_, pir::Value bn2_gamma_, pir::Value bn2_beta_, pir::Value bn2_input_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, const std::string& data_format, bool fuse_shortcut, bool fuse_dual, bool fuse_add, bool exhaustive_search);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_output_, pir::Value weight_, pir::Value grad_output_add_, pir::Value residual_input_, pir::Value bn1_eqscale_, pir::Value bn1_eqbias_, pir::Value conv_input_, pir::Value bn1_mean_, pir::Value bn1_inv_std_, pir::Value bn1_gamma_, pir::Value bn1_beta_, pir::Value bn1_input_, pir::Value bn2_mean_, pir::Value bn2_inv_std_, pir::Value bn2_gamma_, pir::Value bn2_beta_, pir::Value bn2_input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_output() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value grad_output_add() { return operand_source(2); }
  pir::Value residual_input() { return operand_source(3); }
  pir::Value bn1_eqscale() { return operand_source(4); }
  pir::Value bn1_eqbias() { return operand_source(5); }
  pir::Value conv_input() { return operand_source(6); }
  pir::Value bn1_mean() { return operand_source(7); }
  pir::Value bn1_inv_std() { return operand_source(8); }
  pir::Value bn1_gamma() { return operand_source(9); }
  pir::Value bn1_beta() { return operand_source(10); }
  pir::Value bn1_input() { return operand_source(11); }
  pir::Value bn2_mean() { return operand_source(12); }
  pir::Value bn2_inv_std() { return operand_source(13); }
  pir::Value bn2_gamma() { return operand_source(14); }
  pir::Value bn2_beta() { return operand_source(15); }
  pir::Value bn2_input() { return operand_source(16); }
  pir::Value grad_weight() { return result(0); }
  pir::Value grad_bn1_input() { return result(1); }
  pir::Value grad_bn1_gamma() { return result(2); }
  pir::Value grad_bn1_beta() { return result(3); }
  pir::Value grad_bn2_input() { return result(4); }
  pir::Value grad_bn2_gamma() { return result(5); }
  pir::Value grad_bn2_beta() { return result(6); }

};

class  FusedDotProductAttentionOp : public pir::Op<FusedDotProductAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dot_product_attention"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value bias_, pir::Value cu_seqlen_q_, pir::Value cu_seqlen_kv_, float scaling_factor, float dropout_probability, bool is_training=false, const std::string& mask_type_str="none", const std::string& bias_type_str="none");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value bias_, pir::Value cu_seqlen_q_, pir::Value cu_seqlen_kv_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlen_q() { return operand_source(4); }
  pir::Value cu_seqlen_kv() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value softmax_out() { return result(1); }
  pir::Value rng_state() { return result(2); }

};

class  FusedDropoutAddOp : public pir::Op<FusedDropoutAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dropout_add"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value seed_tensor_, float p, bool is_test, const std::string& mode, int seed=0, bool fix_seed=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value seed_tensor_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value seed_tensor() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value seed_offset() { return result(1); }

};

class  FusedElementwiseAddOp : public pir::Op<FusedElementwiseAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elementwise_add"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=-1, const std::string& fuse_activation="", float fuse_alpha=0.0f, float fuse_beta=0.0f, float fused_output_scale=1.0f, const std::vector<int>& fused_unsqueeze2_axes={}, float scale_x=1.0f, float scale_y=1.0f, float scale_out=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedElementwiseDivOp : public pir::Op<FusedElementwiseDivOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elementwise_div"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=-1, const std::string& fuse_activation="", float fuse_alpha=0.0f, float fuse_beta=0.0f, float fused_output_scale=1.0f, const std::vector<int>& fused_unsqueeze2_axes={}, float scale_x=1.0f, float scale_y=1.0f, float scale_out=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedElementwiseMulOp : public pir::Op<FusedElementwiseMulOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elementwise_mul"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=-1, const std::string& fuse_activation="", float fuse_alpha=0.0f, float fuse_beta=0.0f, float fused_output_scale=1.0f, const std::vector<int>& fused_unsqueeze2_axes={}, float scale_x=1.0f, float scale_y=1.0f, float scale_out=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedElementwiseSubOp : public pir::Op<FusedElementwiseSubOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elementwise_sub"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int axis=-1, const std::string& fuse_activation="", float fuse_alpha=0.0f, float fuse_beta=0.0f, float fused_output_scale=1.0f, const std::vector<int>& fused_unsqueeze2_axes={}, float scale_x=1.0f, float scale_y=1.0f, float scale_out=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedElemwiseActivationOp : public pir::Op<FusedElemwiseActivationOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_activation"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<std::string>& functor_list, int axis=-1, float scale=0.0, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value intermediate_out() { return result(1); }

};

class  FusedElemwiseAddActivationOp : public pir::Op<FusedElemwiseAddActivationOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_add_activation"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<std::string>& functor_list, int axis=-1, float scale=0.0, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value intermediate_out() { return result(1); }

};

class  FusedEmbeddingEltwiseLayernormOp : public pir::Op<FusedEmbeddingEltwiseLayernormOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_embedding_eltwise_layernorm"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embs_, pir::Value bias_, pir::Value scale_, float epsilon=0.00001f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embs_, pir::Value bias_, pir::Value scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value ids() { return operand_source(0); }
  pir::Value embs() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  FusedFcElementwiseLayernormOp : public pir::Op<FusedFcElementwiseLayernormOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_fc_elementwise_layernorm"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value y_, pir::Value bias0_, pir::Value scale_, pir::Value bias1_, int x_num_col_dims=1, const std::string& activation_type="", float epsilon=0.00001f, int begin_norm_axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value y_, pir::Value bias0_, pir::Value scale_, pir::Value bias1_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value bias0() { return operand_source(3); }
  pir::Value scale() { return operand_source(4); }
  pir::Value bias1() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value mean() { return result(1); }
  pir::Value variance() { return result(2); }

};

class  FusedLinearParamGradAddOp : public pir::Op<FusedLinearParamGradAddOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_linear_param_grad_add"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dout_, pir::Value dweight_, pir::Value dbias_, bool multi_precision=true, bool has_bias=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dout_, pir::Value dweight_, pir::Value dbias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value dout() { return operand_source(1); }
  pir::Value dweight() { return operand_source(2); }
  pir::Value dbias() { return operand_source(3); }
  pir::Value dweight_out() { return result(0); }
  pir::Value dbias_out() { return result(1); }

};

class  FusedMultiTransformer_Op : public pir::Op<FusedMultiTransformer_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_"; }
  static const char *attributes_name[13];
  static constexpr uint32_t attributes_num = 13;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scales_, pir::Value ln_biases_, pir::Value qkv_weights_, pir::Value qkv_biases_, pir::Value cache_kvs_, pir::Value pre_caches_, pir::Value rotary_tensor_, pir::Value beam_offset_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value out_linear_weights_, pir::Value out_linear_biases_, pir::Value ffn_ln_scales_, pir::Value ffn_ln_biases_, pir::Value ffn1_weights_, pir::Value ffn1_biases_, pir::Value ffn2_weights_, pir::Value ffn2_biases_, bool pre_layer_norm=true, float epsilon=1e-5, float residual_alpha=1.0f, float dropout_rate=.5f, int rotary_emb_dims=0, bool is_test=false, const std::string& dropout_implementation="downgrade_in_infer", const std::string& act_method="gelu", bool trans_qkvw=true, int ring_id=-1, const std::string& norm_type="layernorm", bool use_neox_rotary_style=true, int gqa_group_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scales_, pir::Value ln_biases_, pir::Value qkv_weights_, pir::Value qkv_biases_, pir::Value cache_kvs_, pir::Value pre_caches_, pir::Value rotary_tensor_, pir::Value beam_offset_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value out_linear_weights_, pir::Value out_linear_biases_, pir::Value ffn_ln_scales_, pir::Value ffn_ln_biases_, pir::Value ffn1_weights_, pir::Value ffn1_biases_, pir::Value ffn2_weights_, pir::Value ffn2_biases_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ln_scales() { return operand_source(1); }
  pir::Value ln_biases() { return operand_source(2); }
  pir::Value qkv_weights() { return operand_source(3); }
  pir::Value qkv_biases() { return operand_source(4); }
  pir::Value cache_kvs() { return operand_source(5); }
  pir::Value pre_caches() { return operand_source(6); }
  pir::Value rotary_tensor() { return operand_source(7); }
  pir::Value beam_offset() { return operand_source(8); }
  pir::Value time_step() { return operand_source(9); }
  pir::Value seq_lengths() { return operand_source(10); }
  pir::Value src_mask() { return operand_source(11); }
  pir::Value out_linear_weights() { return operand_source(12); }
  pir::Value out_linear_biases() { return operand_source(13); }
  pir::Value ffn_ln_scales() { return operand_source(14); }
  pir::Value ffn_ln_biases() { return operand_source(15); }
  pir::Value ffn1_weights() { return operand_source(16); }
  pir::Value ffn1_biases() { return operand_source(17); }
  pir::Value ffn2_weights() { return operand_source(18); }
  pir::Value ffn2_biases() { return operand_source(19); }
  pir::Value cache_kv_outs() { return result(0); }
  pir::Value out() { return result(1); }

};

class  FusedMultiTransformerInt8XpuOp : public pir::Op<FusedMultiTransformerInt8XpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_int8_xpu"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_in_max_, pir::Value qkvw_, pir::Value qkv_bias_, pir::Value qkv_scales_, pir::Value out_linear_in_max_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value out_linear_scales_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_in_max_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn1_scales_, pir::Value ffn2_in_max_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value ffn2_scales_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate, bool is_test, const std::string& dropout_implementation, const std::string& act_method, bool trans_qkvw, int ring_id, int gather_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_in_max_, pir::Value qkvw_, pir::Value qkv_bias_, pir::Value qkv_scales_, pir::Value out_linear_in_max_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value out_linear_scales_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_in_max_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn1_scales_, pir::Value ffn2_in_max_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value ffn2_scales_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkv_in_max() { return operand_source(3); }
  pir::Value qkvw() { return operand_source(4); }
  pir::Value qkv_bias() { return operand_source(5); }
  pir::Value qkv_scales() { return operand_source(6); }
  pir::Value out_linear_in_max() { return operand_source(7); }
  pir::Value out_linear_w() { return operand_source(8); }
  pir::Value out_linear_bias() { return operand_source(9); }
  pir::Value out_linear_scales() { return operand_source(10); }
  pir::Value ffn_ln_scale() { return operand_source(11); }
  pir::Value ffn_ln_bias() { return operand_source(12); }
  pir::Value ffn1_in_max() { return operand_source(13); }
  pir::Value ffn1_weight() { return operand_source(14); }
  pir::Value ffn1_bias() { return operand_source(15); }
  pir::Value ffn1_scales() { return operand_source(16); }
  pir::Value ffn2_in_max() { return operand_source(17); }
  pir::Value ffn2_weight() { return operand_source(18); }
  pir::Value ffn2_bias() { return operand_source(19); }
  pir::Value ffn2_scales() { return operand_source(20); }
  pir::Value cache_kv() { return operand_source(21); }
  pir::Value pre_caches() { return operand_source(22); }
  pir::Value rotary_pos_emb() { return operand_source(23); }
  pir::Value time_step() { return operand_source(24); }
  pir::Value seq_lengths() { return operand_source(25); }
  pir::Value src_mask() { return operand_source(26); }
  pir::Value gather_index() { return operand_source(27); }
  pir::Value max_buffer() { return operand_source(28); }
  pir::Value out() { return result(0); }
  pir::Value cache_kv_out() { return result(1); }

};

class  FusedMultiTransformerXpuOp : public pir::Op<FusedMultiTransformerXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_xpu"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkvw_, pir::Value qkvw_max_, pir::Value qkv_bias_, pir::Value out_linear_w_, pir::Value out_linear_wmax_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_weight_max_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_weight_max_, pir::Value ffn2_bias_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, bool pre_layer_norm, int rotary_emb_dims, float epsilon, float dropout_rate, bool is_test, const std::string& dropout_implementation, const std::string& act_method, bool trans_qkvw, int ring_id, int gather_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkvw_, pir::Value qkvw_max_, pir::Value qkv_bias_, pir::Value out_linear_w_, pir::Value out_linear_wmax_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_weight_max_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_weight_max_, pir::Value ffn2_bias_, pir::Value cache_kv_, pir::Value pre_caches_, pir::Value rotary_pos_emb_, pir::Value time_step_, pir::Value seq_lengths_, pir::Value src_mask_, pir::Value gather_index_, pir::Value max_buffer_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkvw() { return operand_source(3); }
  pir::Value qkvw_max() { return operand_source(4); }
  pir::Value qkv_bias() { return operand_source(5); }
  pir::Value out_linear_w() { return operand_source(6); }
  pir::Value out_linear_wmax() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ffn_ln_scale() { return operand_source(9); }
  pir::Value ffn_ln_bias() { return operand_source(10); }
  pir::Value ffn1_weight() { return operand_source(11); }
  pir::Value ffn1_weight_max() { return operand_source(12); }
  pir::Value ffn1_bias() { return operand_source(13); }
  pir::Value ffn2_weight() { return operand_source(14); }
  pir::Value ffn2_weight_max() { return operand_source(15); }
  pir::Value ffn2_bias() { return operand_source(16); }
  pir::Value cache_kv() { return operand_source(17); }
  pir::Value pre_caches() { return operand_source(18); }
  pir::Value rotary_pos_emb() { return operand_source(19); }
  pir::Value time_step() { return operand_source(20); }
  pir::Value seq_lengths() { return operand_source(21); }
  pir::Value src_mask() { return operand_source(22); }
  pir::Value gather_index() { return operand_source(23); }
  pir::Value max_buffer() { return operand_source(24); }
  pir::Value out() { return result(0); }
  pir::Value cache_kv_out() { return result(1); }

};

class  FusedRotaryPositionEmbeddingOp : public pir::Op<FusedRotaryPositionEmbeddingOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rotary_position_embedding"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, bool use_neox_rotary_style=true, bool time_major=false, float rotary_emb_base=10000.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value sin() { return operand_source(3); }
  pir::Value cos() { return operand_source(4); }
  pir::Value position_ids() { return operand_source(5); }
  pir::Value out_q() { return result(0); }
  pir::Value out_k() { return result(1); }
  pir::Value out_v() { return result(2); }

};

class  FusedScaleBiasAddReluOp : public pir::Op<FusedScaleBiasAddReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_scale_bias_add_relu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x1_, pir::Value scale1_, pir::Value bias1_, pir::Value x2_, pir::Value scale2_, pir::Value bias2_, bool fuse_dual, bool exhaustive_search);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x1_, pir::Value scale1_, pir::Value bias1_, pir::Value x2_, pir::Value scale2_, pir::Value bias2_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x1() { return operand_source(0); }
  pir::Value scale1() { return operand_source(1); }
  pir::Value bias1() { return operand_source(2); }
  pir::Value x2() { return operand_source(3); }
  pir::Value scale2() { return operand_source(4); }
  pir::Value bias2() { return operand_source(5); }
  pir::Value out() { return result(0); }

};

class  FusedScaleBiasReluConvBnOp : public pir::Op<FusedScaleBiasReluConvBnOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_scale_bias_relu_conv_bn"; }
  static const char *attributes_name[11];
  static constexpr uint32_t attributes_num = 11;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value scale_, pir::Value bias_, pir::Value bn_scale_, pir::Value bn_bias_, pir::Value input_running_mean_, pir::Value input_running_var_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, const std::string& padding_algorithm, int groups, const std::string& data_format, float momentum, float epsilon, bool fuse_prologue, bool exhaustive_search, int64_t accumulation_count=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value scale_, pir::Value bias_, pir::Value bn_scale_, pir::Value bn_bias_, pir::Value input_running_mean_, pir::Value input_running_var_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value bn_scale() { return operand_source(4); }
  pir::Value bn_bias() { return operand_source(5); }
  pir::Value input_running_mean() { return operand_source(6); }
  pir::Value input_running_var() { return operand_source(7); }
  pir::Value out() { return result(0); }
  pir::Value out_running_mean() { return result(1); }
  pir::Value out_running_var() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_var() { return result(4); }
  pir::Value eq_scale() { return result(5); }
  pir::Value eq_bias() { return result(6); }

};

class  FusedSeqpoolCvmOp : public pir::Op<FusedSeqpoolCvmOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_seqpool_cvm"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, const std::string& pooltype="SUM", float pad_value=0.0, bool use_cvm=true, int cvm_offset=2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cvm() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedStackQuantOp : public pir::Op<FusedStackQuantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_stack_quant"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scale() { return result(1); }

};

class  FusedStackTransposeQuantOp : public pir::Op<FusedStackTransposeQuantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_stack_transpose_quant"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scale() { return result(1); }

};

class  FusedTokenPruneOp : public pir::Op<FusedTokenPruneOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_token_prune"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value attn_, pir::Value x_, pir::Value mask_, pir::Value new_mask_, bool keep_first_token=true, bool keep_order=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value attn_, pir::Value x_, pir::Value mask_, pir::Value new_mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value attn() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value mask() { return operand_source(2); }
  pir::Value new_mask() { return operand_source(3); }
  pir::Value slimmed_x() { return result(0); }
  pir::Value cls_inds() { return result(1); }

};

class  FusedTransposeWlchSplitQuantOp : public pir::Op<FusedTransposeWlchSplitQuantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_transpose_wlch_split_quant"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& tokens_per_expert, bool pow_2_scales=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scales() { return result(1); }

};

class  FusionGroupOp : public pir::Op<FusionGroupOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_group"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, const std::vector<int>& outs_dtype={}, const std::vector<int>& inputs_dtype={}, const std::string& func_name="", int type=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value outs() { return result(0); }

};

class  FusionGruOp : public pir::Op<FusionGruOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_gru"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value h0_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, const std::string& activation="tanh", const std::string& gate_activation="sigmoid", bool is_reverse=false, bool use_seq=true, bool origin_mode=false, bool force_fp32_output=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value h0_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value h0() { return operand_source(1); }
  pir::Value weight_x() { return operand_source(2); }
  pir::Value weight_h() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value reordered_h0() { return result(0); }
  pir::Value xx() { return result(1); }
  pir::Value batched_input() { return result(2); }
  pir::Value batched_out() { return result(3); }
  pir::Value hidden() { return result(4); }

};

class  FusionLstmOp : public pir::Op<FusionLstmOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_lstm"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, pir::Value h0_, pir::Value c0_, bool use_peepholes=true, bool is_reverse=false, bool use_seq=true, const std::string& gate_activation="sigmoid", const std::string& cell_activation="tanh", const std::string& candidate_activation="tanh", float scale_data=1.0, float shift_data=0.0, const std::vector<float>& scale_weights={1.0}, bool force_fp32_output=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_x_, pir::Value weight_h_, pir::Value bias_, pir::Value h0_, pir::Value c0_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight_x() { return operand_source(1); }
  pir::Value weight_h() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value h0() { return operand_source(4); }
  pir::Value c0() { return operand_source(5); }
  pir::Value hidden() { return result(0); }
  pir::Value cell() { return result(1); }
  pir::Value xx() { return result(2); }
  pir::Value batched_input() { return result(3); }
  pir::Value batched_hidden() { return result(4); }
  pir::Value batched_cell() { return result(5); }
  pir::Value reordered_h0() { return result(6); }
  pir::Value reordered_c0() { return result(7); }
  pir::Value checked_cell() { return result(8); }

};

class  FusionRepeatedFcReluOp : public pir::Op<FusionRepeatedFcReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_repeated_fc_relu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value w_, pir::Value bias_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value relu_out() { return result(0); }
  pir::Value out() { return result(1); }

};

class  FusionSeqconvEltaddReluOp : public pir::Op<FusionSeqconvEltaddReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_seqconv_eltadd_relu"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, int context_length, int context_start=0, int context_stride=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value col_mat() { return result(1); }

};

class  FusionSeqpoolConcatOp : public pir::Op<FusionSeqpoolConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_seqpool_concat"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& pooltype="SUM", int axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FusionSeqpoolCvmConcatOp : public pir::Op<FusionSeqpoolCvmConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_seqpool_cvm_concat"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, const std::string& pooltype="SUM", bool use_cvm=true, int axis=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cvm() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusionSquaredMatSubOp : public pir::Op<FusionSquaredMatSubOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_squared_mat_sub"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, float scalar=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value squared_x() { return result(0); }
  pir::Value squared_y() { return result(1); }
  pir::Value squared_xy() { return result(2); }
  pir::Value out() { return result(3); }

};

class  FusionTransposeFlattenConcatOp : public pir::Op<FusionTransposeFlattenConcatOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fusion_transpose_flatten_concat"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& trans_axis, int flatten_axis, int concat_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GemmEpilogueOp : public pir::Op<GemmEpilogueOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.gemm_epilogue"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, int in_num_col_dims=1, const std::string& activation_type="", bool padding_weights=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  GenerateSequenceXpuOp : public pir::Op<GenerateSequenceXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.generate_sequence_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GroupNormSiluXpuOp : public pir::Op<GroupNormSiluXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.group_norm_silu_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int groups=-1, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  LayerNormActXpuOp : public pir::Op<LayerNormActXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm_act_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon, int act_type, float act_param);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  LayerNormReluXpuOp : public pir::Op<LayerNormReluXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.layer_norm_relu_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, int begin_norm_axis, float epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  MaskAdaptiveXpuOp : public pir::Op<MaskAdaptiveXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mask_adaptive_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value mask() { return operand_source(0); }
  pir::Value length() { return result(0); }
  pir::Value seq_lod() { return result(1); }
  pir::Value pad_seq_len() { return result(2); }

};

class  MaxPool2dV2Op : public pir::Op<MaxPool2dV2Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_v2"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_size, const std::vector<int>& strides={1, 1}, const std::vector<int>& paddings={0, 0}, const std::string& data_format="NCHW", bool global_pooling=false, bool adaptive=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value saved_idx() { return result(1); }

};

class  MultiEncoderXpuOp : public pir::Op<MultiEncoderXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multi_encoder_xpu"; }
  static const char *attributes_name[13];
  static constexpr uint32_t attributes_num = 13;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_input_max_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value smooth_scale_weight_, pir::Value roformer_embedding_, pir::Value mask_, pir::Value seq_lod_, pir::Value max_seq_len_, int layer_num, bool norm_before, int hidden_dim, int head_num, int size_per_head, int ffn_hidden_dim_scale, int act_type, int relative_type, int slice_idx, bool is_per_channel, int max_pos_len, const std::vector<float>& softmax_max_value, const std::vector<std::string>& quant_types);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value fc_input_max_, pir::Value fc_weight_, pir::Value fc_weight_max_, pir::Value fc_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value smooth_scale_weight_, pir::Value roformer_embedding_, pir::Value mask_, pir::Value seq_lod_, pir::Value max_seq_len_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value fc_input_max() { return operand_source(1); }
  pir::Value fc_weight() { return operand_source(2); }
  pir::Value fc_weight_max() { return operand_source(3); }
  pir::Value fc_bias() { return operand_source(4); }
  pir::Value ln_scale() { return operand_source(5); }
  pir::Value ln_bias() { return operand_source(6); }
  pir::Value smooth_scale_weight() { return operand_source(7); }
  pir::Value roformer_embedding() { return operand_source(8); }
  pir::Value mask() { return operand_source(9); }
  pir::Value seq_lod() { return operand_source(10); }
  pir::Value max_seq_len() { return operand_source(11); }
  pir::Value out() { return result(0); }
  pir::Value x_fp16() { return result(1); }
  pir::Value out_fp16() { return result(2); }

};

class  MultiheadMatmulOp : public pir::Op<MultiheadMatmulOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multihead_matmul"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::Value bias_qk_, bool transpose_q=false, bool transpose_k=true, bool transpose_v=false, float alpha=1.0f, int head_number=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value w_, pir::Value bias_, pir::Value bias_qk_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value w() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value bias_qk() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  Pad2dXpuOp : public pir::Op<Pad2dXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pad2d_xpu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& paddings, const std::string& mode="constant", float pad_value=0.0, const std::string& data_format="NCHW");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  QkvAttentionXpuOp : public pir::Op<QkvAttentionXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qkv_attention_xpu"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_max_, pir::Value k_max_, pir::Value v_max_, pir::Value qk_max_, pir::Value qkv_max_, float alpha, int head_num, int head_dim, bool qkv_fc_fusion, phi::DataType out_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value q_max_, pir::Value k_max_, pir::Value v_max_, pir::Value qk_max_, pir::Value qkv_max_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value q_max() { return operand_source(3); }
  pir::Value k_max() { return operand_source(4); }
  pir::Value v_max() { return operand_source(5); }
  pir::Value qk_max() { return operand_source(6); }
  pir::Value qkv_max() { return operand_source(7); }
  pir::Value qkv() { return result(0); }

};

class  QkvUnpackMhaOp : public pir::Op<QkvUnpackMhaOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.qkv_unpack_mha"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value src_mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value src_mask() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  QuantizeXpuOp : public pir::Op<QuantizeXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.quantize_xpu"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType out_dtype, float scale=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return result(0); }

};

class  ResnetBasicBlockOp : public pir::Op<ResnetBasicBlockOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.resnet_basic_block"; }
  static const char *attributes_name[19];
  static constexpr uint32_t attributes_num = 19;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter1_, pir::Value scale1_, pir::Value bias1_, pir::Value mean1_, pir::Value var1_, pir::Value filter2_, pir::Value scale2_, pir::Value bias2_, pir::Value mean2_, pir::Value var2_, pir::Value filter3_, pir::Value scale3_, pir::Value bias3_, pir::Value mean3_, pir::Value var3_, int stride1=1, int stride2=1, int stride3=1, int padding1=0, int padding2=0, int padding3=0, int dilation1=1, int dilation2=1, int dilation3=1, int group=1, float momentum=0.9, float epsilon=1e-5, const std::string& data_format="NCHW", bool has_shortcut=false, bool use_global_stats=false, bool is_test=false, bool trainable_statistics=false, const std::string& act_type="relu", bool find_conv_input_max=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter1_, pir::Value scale1_, pir::Value bias1_, pir::Value mean1_, pir::Value var1_, pir::Value filter2_, pir::Value scale2_, pir::Value bias2_, pir::Value mean2_, pir::Value var2_, pir::Value filter3_, pir::Value scale3_, pir::Value bias3_, pir::Value mean3_, pir::Value var3_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter1() { return operand_source(1); }
  pir::Value scale1() { return operand_source(2); }
  pir::Value bias1() { return operand_source(3); }
  pir::Value mean1() { return operand_source(4); }
  pir::Value var1() { return operand_source(5); }
  pir::Value filter2() { return operand_source(6); }
  pir::Value scale2() { return operand_source(7); }
  pir::Value bias2() { return operand_source(8); }
  pir::Value mean2() { return operand_source(9); }
  pir::Value var2() { return operand_source(10); }
  pir::Value filter3() { return operand_source(11); }
  pir::Value scale3() { return operand_source(12); }
  pir::Value bias3() { return operand_source(13); }
  pir::Value mean3() { return operand_source(14); }
  pir::Value var3() { return operand_source(15); }
  pir::Value out() { return result(0); }
  pir::Value conv1() { return result(1); }
  pir::Value saved_mean1() { return result(2); }
  pir::Value saved_invstd1() { return result(3); }
  pir::Value mean1_out() { return result(4); }
  pir::Value var1_out() { return result(5); }
  pir::Value conv2() { return result(6); }
  pir::Value conv2_input() { return result(7); }
  pir::Value saved_mean2() { return result(8); }
  pir::Value saved_invstd2() { return result(9); }
  pir::Value mean2_out() { return result(10); }
  pir::Value var2_out() { return result(11); }
  pir::Value conv3() { return result(12); }
  pir::Value saved_mean3() { return result(13); }
  pir::Value saved_invstd3() { return result(14); }
  pir::Value mean3_out() { return result(15); }
  pir::Value var3_out() { return result(16); }
  pir::Value max_input1() { return result(17); }
  pir::Value max_filter1() { return result(18); }
  pir::Value max_input2() { return result(19); }
  pir::Value max_filter2() { return result(20); }
  pir::Value max_input3() { return result(21); }
  pir::Value max_filter3() { return result(22); }

};

class  ResnetUnitOp : public pir::Op<ResnetUnitOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.resnet_unit"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_x_, pir::Value scale_x_, pir::Value bias_x_, pir::Value mean_x_, pir::Value var_x_, pir::Value z_, pir::Value filter_z_, pir::Value scale_z_, pir::Value bias_z_, pir::Value mean_z_, pir::Value var_z_, int stride=1, int stride_z=1, int padding=0, int dilation=1, int group=1, float momentum=0.9, float epsilon=1e-5, const std::string& data_format="NHWC", bool fuse_add=false, bool has_shortcut=false, bool use_global_stats=false, bool is_test=false, bool use_addto=false, const std::string& act_type="relu");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_x_, pir::Value scale_x_, pir::Value bias_x_, pir::Value mean_x_, pir::Value var_x_, pir::Value z_, pir::Value filter_z_, pir::Value scale_z_, pir::Value bias_z_, pir::Value mean_z_, pir::Value var_z_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter_x() { return operand_source(1); }
  pir::Value scale_x() { return operand_source(2); }
  pir::Value bias_x() { return operand_source(3); }
  pir::Value mean_x() { return operand_source(4); }
  pir::Value var_x() { return operand_source(5); }
  pir::Value z() { return operand_source(6); }
  pir::Value filter_z() { return operand_source(7); }
  pir::Value scale_z() { return operand_source(8); }
  pir::Value bias_z() { return operand_source(9); }
  pir::Value mean_z() { return operand_source(10); }
  pir::Value var_z() { return operand_source(11); }
  pir::Value out() { return result(0); }
  pir::Value bit_mask() { return result(1); }
  pir::Value conv_x() { return result(2); }
  pir::Value saved_mean_x() { return result(3); }
  pir::Value saved_invstd_x() { return result(4); }
  pir::Value running_mean_x() { return result(5); }
  pir::Value running_var_x() { return result(6); }
  pir::Value conv_z() { return result(7); }
  pir::Value saved_mean_z() { return result(8); }
  pir::Value saved_invstd_z() { return result(9); }
  pir::Value running_mean_z() { return result(10); }
  pir::Value running_var_z() { return result(11); }

};

class  RoformerRelativeEmbeddingXpuOp : public pir::Op<RoformerRelativeEmbeddingXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.roformer_relative_embedding_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value sin_emb_, pir::Value cos_emb_, int max_pos_len);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value sin_emb_, pir::Value cos_emb_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value sin_emb() { return operand_source(1); }
  pir::Value cos_emb() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SelfDpAttentionOp : public pir::Op<SelfDpAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.self_dp_attention"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha=1.0f, int head_number=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SequenceUnpadXpuOp : public pir::Op<SequenceUnpadXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_unpad_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value length_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value length() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SinePosXpuOp : public pir::Op<SinePosXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sine_pos_xpu"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SkipLayernormOp : public pir::Op<SkipLayernormOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.skip_layernorm"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, float epsilon, int begin_norm_axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  SpatialTransformerResblockXpuOp : public pir::Op<SpatialTransformerResblockXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.spatial_transformer_resblock_xpu"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value conv_bias_, pir::Value conv_filter_, pir::Value conv_filter_max_, pir::Value gn_bias_, pir::Value gn_scale_, const std::vector<int>& dilations, const std::vector<int>& paddings, const std::vector<int>& strides, const std::vector<float>& gn_eps, const std::vector<int>& gn_groups, const std::vector<int>& groups, bool conv_fix, bool has_silu_fc_input, bool include_silu);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value conv_bias_, pir::Value conv_filter_, pir::Value conv_filter_max_, pir::Value gn_bias_, pir::Value gn_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value conv_bias() { return operand_source(2); }
  pir::Value conv_filter() { return operand_source(3); }
  pir::Value conv_filter_max() { return operand_source(4); }
  pir::Value gn_bias() { return operand_source(5); }
  pir::Value gn_scale() { return operand_source(6); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  SqueezeExcitationBlockOp : public pir::Op<SqueezeExcitationBlockOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.squeeze_excitation_block"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, const std::vector<int>& act_type, const std::vector<float>& act_param, const std::vector<int>& filter_dims);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value filter_max_, pir::Value bias_, pir::Value branch_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value filter_max() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value branch() { return operand_source(4); }
  pir::Value out() { return result(0); }

};

class  VariableLengthMemoryEfficientAttentionOp : public pir::Op<VariableLengthMemoryEfficientAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.variable_length_memory_efficient_attention"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value seq_lens_, pir::Value kv_seq_lens_, pir::Value mask_, float scale, bool causal, int pre_cache_length);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value seq_lens_, pir::Value kv_seq_lens_, pir::Value mask_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value seq_lens() { return operand_source(3); }
  pir::Value kv_seq_lens() { return operand_source(4); }
  pir::Value mask() { return operand_source(5); }
  pir::Value out() { return result(0); }

};

class  YoloBoxXpuOp : public pir::Op<YoloBoxXpuOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.yolo_box_xpu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value grid_, pir::Value stride_, pir::Value anchor_grid_, float offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_max_, pir::Value grid_, pir::Value stride_, pir::Value anchor_grid_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_max() { return operand_source(1); }
  pir::Value grid() { return operand_source(2); }
  pir::Value stride() { return operand_source(3); }
  pir::Value anchor_grid() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value out_max() { return result(1); }

};

class  AddGroupNormSiluOp : public pir::Op<AddGroupNormSiluOp,paddle::dialect::InferMetaInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_group_norm_silu"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value scale_, pir::Value bias_, float epsilon=1e-5, int groups=-1, const std::string& data_format="NCHW", const std::string& activation="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value residual() { return operand_source(1); }
  pir::Value scale() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value y() { return result(0); }
  pir::Value residual_out() { return result(1); }
  pir::Value mean() { return result(2); }
  pir::Value variance() { return result(3); }

};

class  FusedActDequantOp : public pir::Op<FusedActDequantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_act_dequant"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value x_scale_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value x_scale() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedEmbeddingFcLstmOp : public pir::Op<FusedEmbeddingFcLstmOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_embedding_fc_lstm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embeddings_, pir::Value weight_h_, pir::Value bias_, pir::Value h0_, pir::Value c0_, bool use_peepholes=true, bool is_reverse=false, bool use_seq=true, const std::string& gate_activation="sigmoid", const std::string& cell_activation="tanh", const std::string& candidate_activation="tanh");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value embeddings_, pir::Value weight_h_, pir::Value bias_, pir::Value h0_, pir::Value c0_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value ids() { return operand_source(0); }
  pir::Value embeddings() { return operand_source(1); }
  pir::Value weight_h() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value h0() { return operand_source(4); }
  pir::Value c0() { return operand_source(5); }
  pir::Value hidden() { return result(0); }
  pir::Value cell() { return result(1); }
  pir::Value xx() { return result(2); }
  pir::Value batched_input() { return result(3); }
  pir::Value batched_hidden() { return result(4); }
  pir::Value batched_cell() { return result(5); }
  pir::Value reordered_h0() { return result(6); }
  pir::Value reordered_c0() { return result(7); }

};

class  FusedSwigluWeightedBwdOp : public pir::Op<FusedSwigluWeightedBwdOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_swiglu_weighted_bwd"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value o1_, pir::Value do2_s_, pir::Value unzipped_probs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value o1() { return operand_source(0); }
  pir::Value do2_s() { return operand_source(1); }
  pir::Value unzipped_probs() { return operand_source(2); }
  pir::Value do1() { return result(0); }
  pir::Value probs_grad() { return result(1); }
  pir::Value o2_s() { return result(2); }

};

class  FusedTransposeSplitQuantOp : public pir::Op<FusedTransposeSplitQuantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_transpose_split_quant"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& tokens_per_expert, bool pow_2_scales=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value scales() { return result(1); }

};

class  FusedWeightedSwigluActQuantOp : public pir::Op<FusedWeightedSwigluActQuantOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_weighted_swiglu_act_quant"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value prob_, bool using_pow2_scaling);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value prob_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value prob() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value scale() { return result(1); }

};


class  FusedBiasDropoutResidualLayerNormGradOp : public pir::Op<FusedBiasDropoutResidualLayerNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_bias_dropout_residual_layer_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_mean_, pir::Value ln_variance_, pir::Value bias_dropout_residual_out_, pir::Value dropout_mask_out_, pir::Value y_grad_, float dropout_rate=0.5f, bool is_test=false, bool dropout_fix_seed=true, int dropout_seed=true, const std::string& dropout_implementation="downgrade_in_infer", float ln_epsilon=1e-5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value residual_, pir::Value bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_mean_, pir::Value ln_variance_, pir::Value bias_dropout_residual_out_, pir::Value dropout_mask_out_, pir::Value y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value residual() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value ln_scale() { return operand_source(3); }
  pir::Value ln_bias() { return operand_source(4); }
  pir::Value ln_mean() { return operand_source(5); }
  pir::Value ln_variance() { return operand_source(6); }
  pir::Value bias_dropout_residual_out() { return operand_source(7); }
  pir::Value dropout_mask_out() { return operand_source(8); }
  pir::Value y_grad() { return operand_source(9); }
  pir::Value x_grad() { return result(0); }
  pir::Value residual_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }
  pir::Value ln_scale_grad() { return result(3); }
  pir::Value ln_bias_grad() { return result(4); }

};

class  FusedDotProductAttentionGradOp : public pir::Op<FusedDotProductAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dot_product_attention_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value bias_, pir::Value cu_seqlen_q_, pir::Value cu_seqlen_kv_, pir::Value out_, pir::Value softmax_out_, pir::Value rng_state_, pir::Value out_grad_, float scaling_factor, float dropout_probability, const std::string& mask_type_str="none", const std::string& bias_type_str="none");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value q_, pir::Value k_, pir::Value v_, pir::Value bias_, pir::Value cu_seqlen_q_, pir::Value cu_seqlen_kv_, pir::Value out_, pir::Value softmax_out_, pir::Value rng_state_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value q() { return operand_source(0); }
  pir::Value k() { return operand_source(1); }
  pir::Value v() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value cu_seqlen_q() { return operand_source(4); }
  pir::Value cu_seqlen_kv() { return operand_source(5); }
  pir::Value out() { return operand_source(6); }
  pir::Value softmax_out() { return operand_source(7); }
  pir::Value rng_state() { return operand_source(8); }
  pir::Value out_grad() { return operand_source(9); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }
  pir::Value bias_grad() { return result(3); }

};

class  FusedDropoutAddGradOp : public pir::Op<FusedDropoutAddGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_dropout_add_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value seed_offset_, pir::Value out_grad_, float p, bool is_test, const std::string& mode, bool fix_seed);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value seed_offset_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value seed_offset() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  FusedElemwiseActivationGradOp : public pir::Op<FusedElemwiseActivationGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_activation_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, const std::vector<std::string>& functor_list, int axis=-1, float scale=0.0, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value intermediate_out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  FusedElemwiseAddActivationGradOp : public pir::Op<FusedElemwiseAddActivationGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_elemwise_add_activation_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, const std::vector<std::string>& functor_list, int axis=-1, float scale=0.0, bool save_intermediate_out=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value intermediate_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value intermediate_out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  FusedRotaryPositionEmbeddingGradOp : public pir::Op<FusedRotaryPositionEmbeddingGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_rotary_position_embedding_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::Value out_q_grad_, pir::Value out_k_grad_, pir::Value out_v_grad_, bool use_neox_rotary_style, bool time_major, float rotary_emb_base);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value sin_, pir::Value cos_, pir::Value position_ids_, pir::Value out_q_grad_, pir::Value out_k_grad_, pir::Value out_v_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value sin() { return operand_source(0); }
  pir::Value cos() { return operand_source(1); }
  pir::Value position_ids() { return operand_source(2); }
  pir::Value out_q_grad() { return operand_source(3); }
  pir::Value out_k_grad() { return operand_source(4); }
  pir::Value out_v_grad() { return operand_source(5); }
  pir::Value q_grad() { return result(0); }
  pir::Value k_grad() { return result(1); }
  pir::Value v_grad() { return result(2); }

};

class  FusedSeqpoolCvmGradOp : public pir::Op<FusedSeqpoolCvmGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_seqpool_cvm_grad"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::Value out_grad_, const std::string& pooltype="SUM", float pad_value=0.0, bool use_cvm=true, int cvm_offset=2);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value cvm_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value cvm() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value cvm_grad() { return result(1); }

};

class  MaxPool2dV2GradOp : public pir::Op<MaxPool2dV2GradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.max_pool2d_v2_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value saved_idx_, pir::Value out_grad_, const std::vector<int>& kernel_size, const std::vector<int>& strides, const std::vector<int>& paddings, const std::string& data_format, bool global_pooling, bool adaptive);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value saved_idx_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value saved_idx() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  ResnetBasicBlockGradOp : public pir::Op<ResnetBasicBlockGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.resnet_basic_block_grad"; }
  static const char *attributes_name[19];
  static constexpr uint32_t attributes_num = 19;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter1_, pir::Value conv1_, pir::Value scale1_, pir::Value bias1_, pir::Value saved_mean1_, pir::Value saved_invstd1_, pir::Value filter2_, pir::Value conv2_, pir::Value conv2_input_, pir::Value scale2_, pir::Value bias2_, pir::Value saved_mean2_, pir::Value saved_invstd2_, pir::Value filter3_, pir::Value conv3_, pir::Value scale3_, pir::Value bias3_, pir::Value saved_mean3_, pir::Value saved_invstd3_, pir::Value max_input1_, pir::Value max_filter1_, pir::Value max_input2_, pir::Value max_filter2_, pir::Value max_input3_, pir::Value max_filter3_, pir::Value out_, pir::Value out_grad_, int stride1=1, int stride2=1, int stride3=1, int padding1=0, int padding2=0, int padding3=0, int dilation1=1, int dilation2=1, int dilation3=1, int group=1, float momentum=0.9, float epsilon=1e-5, const std::string& data_format="NCHW", bool has_shortcut=false, bool use_global_stats=false, bool is_test=false, bool trainable_statistics=false, const std::string& act_type="relu", bool find_conv_input_max=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter1_, pir::Value conv1_, pir::Value scale1_, pir::Value bias1_, pir::Value saved_mean1_, pir::Value saved_invstd1_, pir::Value filter2_, pir::Value conv2_, pir::Value conv2_input_, pir::Value scale2_, pir::Value bias2_, pir::Value saved_mean2_, pir::Value saved_invstd2_, pir::Value filter3_, pir::Value conv3_, pir::Value scale3_, pir::Value bias3_, pir::Value saved_mean3_, pir::Value saved_invstd3_, pir::Value max_input1_, pir::Value max_filter1_, pir::Value max_input2_, pir::Value max_filter2_, pir::Value max_input3_, pir::Value max_filter3_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter1() { return operand_source(1); }
  pir::Value conv1() { return operand_source(2); }
  pir::Value scale1() { return operand_source(3); }
  pir::Value bias1() { return operand_source(4); }
  pir::Value saved_mean1() { return operand_source(5); }
  pir::Value saved_invstd1() { return operand_source(6); }
  pir::Value filter2() { return operand_source(7); }
  pir::Value conv2() { return operand_source(8); }
  pir::Value conv2_input() { return operand_source(9); }
  pir::Value scale2() { return operand_source(10); }
  pir::Value bias2() { return operand_source(11); }
  pir::Value saved_mean2() { return operand_source(12); }
  pir::Value saved_invstd2() { return operand_source(13); }
  pir::Value filter3() { return operand_source(14); }
  pir::Value conv3() { return operand_source(15); }
  pir::Value scale3() { return operand_source(16); }
  pir::Value bias3() { return operand_source(17); }
  pir::Value saved_mean3() { return operand_source(18); }
  pir::Value saved_invstd3() { return operand_source(19); }
  pir::Value max_input1() { return operand_source(20); }
  pir::Value max_filter1() { return operand_source(21); }
  pir::Value max_input2() { return operand_source(22); }
  pir::Value max_filter2() { return operand_source(23); }
  pir::Value max_input3() { return operand_source(24); }
  pir::Value max_filter3() { return operand_source(25); }
  pir::Value out() { return operand_source(26); }
  pir::Value out_grad() { return operand_source(27); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter1_grad() { return result(1); }
  pir::Value scale1_grad() { return result(2); }
  pir::Value bias1_grad() { return result(3); }
  pir::Value filter2_grad() { return result(4); }
  pir::Value scale2_grad() { return result(5); }
  pir::Value bias2_grad() { return result(6); }
  pir::Value filter3_grad() { return result(7); }
  pir::Value scale3_grad() { return result(8); }
  pir::Value bias3_grad() { return result(9); }

};

class  ResnetUnitGradOp : public pir::Op<ResnetUnitGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.resnet_unit_grad"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_x_, pir::Value conv_x_, pir::Value scale_x_, pir::Value bias_x_, pir::Value saved_mean_x_, pir::Value saved_invstd_x_, pir::Value z_, pir::Value filter_z_, pir::Value conv_z_, pir::Value scale_z_, pir::Value bias_z_, pir::Value saved_mean_z_, pir::Value saved_invstd_z_, pir::Value out_, pir::Value bit_mask_, pir::Value out_grad_, int stride=1, int stride_z=1, int padding=0, int dilation=1, int group=1, float momentum=0.9, float epsilon=1e-5, const std::string& data_format="NHWC", bool fuse_add=false, bool has_shortcut=false, bool use_global_stats=false, bool is_test=false, bool use_addto=false, const std::string& act_type="relu");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_x_, pir::Value conv_x_, pir::Value scale_x_, pir::Value bias_x_, pir::Value saved_mean_x_, pir::Value saved_invstd_x_, pir::Value z_, pir::Value filter_z_, pir::Value conv_z_, pir::Value scale_z_, pir::Value bias_z_, pir::Value saved_mean_z_, pir::Value saved_invstd_z_, pir::Value out_, pir::Value bit_mask_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter_x() { return operand_source(1); }
  pir::Value conv_x() { return operand_source(2); }
  pir::Value scale_x() { return operand_source(3); }
  pir::Value bias_x() { return operand_source(4); }
  pir::Value saved_mean_x() { return operand_source(5); }
  pir::Value saved_invstd_x() { return operand_source(6); }
  pir::Value z() { return operand_source(7); }
  pir::Value filter_z() { return operand_source(8); }
  pir::Value conv_z() { return operand_source(9); }
  pir::Value scale_z() { return operand_source(10); }
  pir::Value bias_z() { return operand_source(11); }
  pir::Value saved_mean_z() { return operand_source(12); }
  pir::Value saved_invstd_z() { return operand_source(13); }
  pir::Value out() { return operand_source(14); }
  pir::Value bit_mask() { return operand_source(15); }
  pir::Value out_grad() { return operand_source(16); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_x_grad() { return result(1); }
  pir::Value scale_x_grad() { return result(2); }
  pir::Value bias_x_grad() { return result(3); }
  pir::Value z_grad() { return result(4); }
  pir::Value filter_z_grad() { return result(5); }
  pir::Value scale_z_grad() { return result(6); }
  pir::Value bias_z_grad() { return result(7); }

};


class TEST_API AddOp : public pir::Op<AddOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class TEST_API Add_Op : public pir::Op<Add_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class TEST_API AddNOp : public pir::Op<AddNOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_n"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value inputs_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value inputs() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AnchorGeneratorOp : public pir::Op<AnchorGeneratorOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.anchor_generator"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, const std::vector<float>& anchor_sizes, const std::vector<float>& aspect_ratios, const std::vector<float>& variances, const std::vector<float>& stride={16.0, 16.0}, float offset=0.5);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value anchors() { return result(0); }
  pir::Value variances_out() { return result(1); }

};

class  AssignOp : public pir::Op<AssignOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Assign_Op : public pir::Op<Assign_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AssignValueOp : public pir::Op<AssignValueOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_value"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& shape, phi::DataType dtype, std::vector<phi::Scalar> values, const phi::Place& place={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class TEST_API BatchNormOp : public pir::Op<BatchNormOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_format, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class TEST_API BatchNorm_Op : public pir::Op<BatchNorm_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_format, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  BeamSearchDecodeOp : public pir::Op<BeamSearchDecodeOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.beam_search_decode"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value scores_, int beam_size, int end_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value ids_, pir::Value scores_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value ids() { return operand_source(0); }
  pir::Value scores() { return operand_source(1); }
  pir::Value sentence_ids() { return result(0); }
  pir::Value sentence_scores() { return result(1); }

};

class  CEmbeddingOp : public pir::Op<CEmbeddingOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, int64_t start_index=0, int64_t vocab_size=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value weight() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CoalesceTensor_Op : public pir::Op<CoalesceTensor_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coalesce_tensor_"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, phi::DataType dtype, bool copy_data=false, bool set_constant=false, bool persist_output=false, float constant=0.0, bool use_align=true, int align_size=-1, int size_of_dtype=-1, const std::vector<int64_t>& concated_shapes={}, const std::vector<int64_t>& concated_ranks={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value output() { return result(0); }
  pir::Value fused_output() { return result(1); }

};

class  CommInitAllOp : public pir::Op<CommInitAllOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.comm_init_all"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& devices={}, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );

};

class  DequantizeLinearOp : public pir::Op<DequantizeLinearOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_linear"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, int quant_axis=0, int bit_length=8, int qmin=-128, int qmax=127, int round_type=0, bool is_test=true, bool only_observer=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value zero_point() { return operand_source(2); }
  pir::Value in_accum() { return operand_source(3); }
  pir::Value in_state() { return operand_source(4); }
  pir::Value y() { return result(0); }
  pir::Value out_state() { return result(1); }
  pir::Value out_accum() { return result(2); }
  pir::Value out_scale() { return result(3); }

};

class  DequantizeLinear_Op : public pir::Op<DequantizeLinear_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dequantize_linear_"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, int quant_axis=0, int bit_length=8, int qmin=-128, int qmax=127, int round_type=0, bool is_test=true, bool only_observer=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value zero_point() { return operand_source(2); }
  pir::Value in_accum() { return operand_source(3); }
  pir::Value in_state() { return operand_source(4); }
  pir::Value y() { return result(0); }
  pir::Value out_state() { return result(1); }
  pir::Value out_accum() { return result(2); }
  pir::Value out_scale() { return result(3); }

};

class  DistributeFpnProposalsOp : public pir::Op<DistributeFpnProposalsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.distribute_fpn_proposals"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value fpn_rois_, pir::Value rois_num_, int min_level, int max_level, int refer_level, int refer_scale, bool pixel_offset);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value fpn_rois_, pir::Value rois_num_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value fpn_rois() { return operand_source(0); }
  pir::Value rois_num() { return operand_source(1); }
  pir::Value multi_fpn_rois() { return result(0); }
  pir::Value multi_level_rois_num() { return result(1); }
  pir::Value restore_index() { return result(2); }

};

class  DivideOp : public pir::Op<DivideOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Divide_Op : public pir::Op<Divide_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  EinsumOp : public pir::Op<EinsumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.einsum"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::string& equation);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value inner_cache() { return result(1); }
  pir::Value xshape() { return result(2); }

};

class  ElementwisePowOp : public pir::Op<ElementwisePowOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elementwise_pow"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  EmbeddingOp : public pir::Op<EmbeddingOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, int64_t padding_idx=-1, bool sparse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SparseWeightEmbeddingOp : public pir::Op<SparseWeightEmbeddingOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, int64_t padding_idx=-1, bool sparse=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  EqualOp : public pir::Op<EqualOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Equal_Op : public pir::Op<Equal_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FeedOp : public pir::Op<FeedOp,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::ImmutableLayoutTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.feed"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out() { return result(0); }

};

class  FloorDivideOp : public pir::Op<FloorDivideOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_divide"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FloorDivide_Op : public pir::Op<FloorDivide_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.floor_divide_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  FusedAdam_Op : public pir::Op<FusedAdam_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_adam_"; }
  static const char *attributes_name[9];
  static constexpr uint32_t attributes_num = 9;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value params_, pir::Value grads_, pir::Value learning_rate_, pir::Value moments1_, pir::Value moments2_, pir::Value moments2_max_, pir::Value beta1_pows_, pir::Value beta2_pows_, pir::Value master_params_, pir::Value skip_update_, float beta1, float beta2, float epsilon, int chunk_size, float weight_decay, bool use_adamw, bool multi_precision, bool use_global_beta_pow, bool amsgrad=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value params_, pir::Value grads_, pir::Value learning_rate_, pir::Value moments1_, pir::Value moments2_, pir::Value moments2_max_, pir::Value beta1_pows_, pir::Value beta2_pows_, pir::Value master_params_, pir::Value skip_update_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value params() { return operand_source(0); }
  pir::Value grads() { return operand_source(1); }
  pir::Value learning_rate() { return operand_source(2); }
  pir::Value moments1() { return operand_source(3); }
  pir::Value moments2() { return operand_source(4); }
  pir::Value moments2_max() { return operand_source(5); }
  pir::Value beta1_pows() { return operand_source(6); }
  pir::Value beta2_pows() { return operand_source(7); }
  pir::Value master_params() { return operand_source(8); }
  pir::Value skip_update() { return operand_source(9); }
  pir::Value params_out() { return result(0); }
  pir::Value moments1_out() { return result(1); }
  pir::Value moments2_out() { return result(2); }
  pir::Value moments2_max_out() { return result(3); }
  pir::Value beta1_pows_out() { return result(4); }
  pir::Value beta2_pows_out() { return result(5); }
  pir::Value master_params_out() { return result(6); }

};

class  FusedGateAttentionOp : public pir::Op<FusedGateAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_gate_attention"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value query_weight_, pir::Value key_weight_, pir::Value value_weight_, pir::Value qkv_weight_, pir::Value nonbatched_bias_, pir::Value src_mask_, pir::Value gate_weight_, pir::Value gate_bias_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, bool has_gating=true, bool merge_qkv=true, bool use_flash_attn=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value query_weight_, pir::Value key_weight_, pir::Value value_weight_, pir::Value qkv_weight_, pir::Value nonbatched_bias_, pir::Value src_mask_, pir::Value gate_weight_, pir::Value gate_bias_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value query_weight() { return operand_source(2); }
  pir::Value key_weight() { return operand_source(3); }
  pir::Value value_weight() { return operand_source(4); }
  pir::Value qkv_weight() { return operand_source(5); }
  pir::Value nonbatched_bias() { return operand_source(6); }
  pir::Value src_mask() { return operand_source(7); }
  pir::Value gate_weight() { return operand_source(8); }
  pir::Value gate_bias() { return operand_source(9); }
  pir::Value out_linear_weight() { return operand_source(10); }
  pir::Value out_linear_bias() { return operand_source(11); }
  pir::Value query_transpose_out() { return result(0); }
  pir::Value key_transpose_out() { return result(1); }
  pir::Value value_transpose_out() { return result(2); }
  pir::Value qkv_transpose_out() { return result(3); }
  pir::Value softmax_out() { return result(4); }
  pir::Value softmax_lse() { return result(5); }
  pir::Value fmha_out() { return result(6); }
  pir::Value gate_out() { return result(7); }
  pir::Value out() { return result(8); }

};

class  FusedMultiTransformerInt8Op : public pir::Op<FusedMultiTransformerInt8Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_multi_transformer_int8"; }
  static const char *attributes_name[18];
  static constexpr uint32_t attributes_num = 18;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_w_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value time_step_, pir::Value src_mask_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value qkv_out_scale_, pir::Value out_linear_out_scale_, pir::Value ffn1_out_scale_, pir::Value ffn2_out_scale_, bool pre_layer_norm=true, float epsilon=1e-5, float dropout_rate=.5f, bool is_test=false, const std::string& dropout_implementation="downgrade_in_infer", const std::string& act_method="gelu", bool trans_qkvw=true, int ring_id=-1, int num_head=0, int dim_head=0, int dim_ffn=0, const std::vector<float>& qkv_in_scale={}, const std::vector<float>& out_linear_in_scale={}, const std::vector<float>& ffn1_in_scale={}, const std::vector<float>& ffn2_in_scale={}, int quant_round_type=1, float quant_max_bound=127.0, float quant_min_bound=-127.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_w_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value time_step_, pir::Value src_mask_, pir::Value out_linear_w_, pir::Value out_linear_bias_, pir::Value ffn_ln_scale_, pir::Value ffn_ln_bias_, pir::Value ffn1_weight_, pir::Value ffn1_bias_, pir::Value ffn2_weight_, pir::Value ffn2_bias_, pir::Value qkv_out_scale_, pir::Value out_linear_out_scale_, pir::Value ffn1_out_scale_, pir::Value ffn2_out_scale_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkv_w() { return operand_source(3); }
  pir::Value qkv_bias() { return operand_source(4); }
  pir::Value cache_kv() { return operand_source(5); }
  pir::Value time_step() { return operand_source(6); }
  pir::Value src_mask() { return operand_source(7); }
  pir::Value out_linear_w() { return operand_source(8); }
  pir::Value out_linear_bias() { return operand_source(9); }
  pir::Value ffn_ln_scale() { return operand_source(10); }
  pir::Value ffn_ln_bias() { return operand_source(11); }
  pir::Value ffn1_weight() { return operand_source(12); }
  pir::Value ffn1_bias() { return operand_source(13); }
  pir::Value ffn2_weight() { return operand_source(14); }
  pir::Value ffn2_bias() { return operand_source(15); }
  pir::Value qkv_out_scale() { return operand_source(16); }
  pir::Value out_linear_out_scale() { return operand_source(17); }
  pir::Value ffn1_out_scale() { return operand_source(18); }
  pir::Value ffn2_out_scale() { return operand_source(19); }
  pir::Value cache_kv_out() { return result(0); }
  pir::Value out() { return result(1); }

};

class  GetTensorFromSelectedRowsOp : public pir::Op<GetTensorFromSelectedRowsOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.get_tensor_from_selected_rows"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  GreaterEqualOp : public pir::Op<GreaterEqualOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GreaterEqual_Op : public pir::Op<GreaterEqual_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GreaterThanOp : public pir::Op<GreaterThanOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_than"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  GreaterThan_Op : public pir::Op<GreaterThan_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.greater_than_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  HardswishOp : public pir::Op<HardswishOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  HashOp : public pir::Op<HashOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hash"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int num_hash=1, int64_t mod_by=100000, bool runtime_shape=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LarsMomentum_Op : public pir::Op<LarsMomentum_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lars_momentum_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, float mu, float lars_coeff=0.001f, const std::vector<float>& lars_weight_decay={0.0005f}, float epsilon=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value learning_rate() { return operand_source(3); }
  pir::Value master_param() { return operand_source(4); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  LegacyMatmulOp : public pir::Op<LegacyMatmulOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.legacy_matmul"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool transpose_x=false, bool transpose_y=false, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LegacyReshapeOp : public pir::Op<LegacyReshapeOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.legacy_reshape"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LegacyReshape_Op : public pir::Op<LegacyReshape_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.legacy_reshape_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LessEqualOp : public pir::Op<LessEqualOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LessEqual_Op : public pir::Op<LessEqual_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class TEST_API LessThanOp : public pir::Op<LessThanOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_than"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LessThan_Op : public pir::Op<LessThan_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.less_than_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LoadCombineOp : public pir::Op<LoadCombineOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.load_combine"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value Out() { return result(0); }

};

class  LodArrayLengthOp : public pir::Op<LodArrayLengthOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_array_length"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LodResetOp : public pir::Op<LodResetOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_reset"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<int>& target_lod={}, bool append=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LodReset_Op : public pir::Op<LodReset_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_reset_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, const std::vector<int>& target_lod={}, bool append=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LookupTableOp : public pir::Op<LookupTableOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LookupTableSrOp : public pir::Op<LookupTableSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_sr"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  LrnOp : public pir::Op<LrnOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lrn"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int n=5, float k=2.0, float alpha=0.0001, float beta=0.75, const std::string& data_format="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value mid_out() { return result(1); }

};

class TEST_API MatmulOp : public pir::Op<MatmulOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MatmulWithFlattenOp : public pir::Op<MatmulWithFlattenOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_with_flatten"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int x_num_col_dims=1, int y_num_col_dims=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaximumOp : public pir::Op<MaximumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maximum"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MemcpyOp : public pir::Op<MemcpyOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.memcpy"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MinOp : public pir::Op<MinOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.min"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MinimumOp : public pir::Op<MinimumOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.minimum"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MultiplyOp : public pir::Op<MultiplyOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MultiplySrOp : public pir::Op<MultiplySrOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_sr"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Multiply_Op : public pir::Op<Multiply_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MultiplySr_Op : public pir::Op<MultiplySr_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_sr_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  NopOp : public pir::Op<NopOp,paddle::dialect::InferMetaInterface,paddle::dialect::ParseKernelKeyInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nop"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);


  static std::tuple<phi::DataType, phi::Backend> ParseKernelKey(pir::Operation *op);




  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Nop_Op : public pir::Op<Nop_Op,paddle::dialect::InferMetaInterface,paddle::dialect::ParseKernelKeyInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait,paddle::dialect::ForwardOnlyTrait,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nop_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);


  static std::tuple<phi::DataType, phi::Backend> ParseKernelKey(pir::Operation *op);




  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  NotEqualOp : public pir::Op<NotEqualOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.not_equal"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  NotEqual_Op : public pir::Op<NotEqual_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.not_equal_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  PartialRecvOp : public pir::Op<PartialRecvOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_recv"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int ring_id=0, int peer=0, phi::DataType dtype=phi::DataType::FLOAT32, const std::vector<int>& out_shape={}, int num=1, int id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  PartialSendOp : public pir::Op<PartialSendOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.partial_send"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int peer=0, int num=1, int id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }

};

class  PrintOp : public pir::Op<PrintOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.print"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value in_, int first_n, const std::string& message, int summarize, bool print_tensor_name=true, bool print_tensor_type=true, bool print_tensor_shape=true, bool print_tensor_layout=true, bool print_tensor_lod=true, const std::string& print_phase="BOTH", bool is_forward=true);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value in_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value in() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  QuantizeLinearOp : public pir::Op<QuantizeLinearOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.quantize_linear"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, int quant_axis=0, int bit_length=8, int qmin=-128, int qmax=127, int round_type=0, bool is_test=true, bool only_observer=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value zero_point() { return operand_source(2); }
  pir::Value in_accum() { return operand_source(3); }
  pir::Value in_state() { return operand_source(4); }
  pir::Value y() { return result(0); }
  pir::Value out_state() { return result(1); }
  pir::Value out_accum() { return result(2); }
  pir::Value out_scale() { return result(3); }

};

class  QuantizeLinear_Op : public pir::Op<QuantizeLinear_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.quantize_linear_"; }
  static const char *attributes_name[7];
  static constexpr uint32_t attributes_num = 7;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, int quant_axis=0, int bit_length=8, int qmin=-128, int qmax=127, int round_type=0, bool is_test=true, bool only_observer=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value zero_point_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value zero_point() { return operand_source(2); }
  pir::Value in_accum() { return operand_source(3); }
  pir::Value in_state() { return operand_source(4); }
  pir::Value y() { return result(0); }
  pir::Value out_state() { return result(1); }
  pir::Value out_accum() { return result(2); }
  pir::Value out_scale() { return result(3); }

};

class  RecvV2Op : public pir::Op<RecvV2Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.recv_v2"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, const std::vector<int>& out_shape={}, phi::DataType dtype=phi::DataType::FLOAT32, int peer=0, int ring_id=0, bool use_calc_stream=false, bool dynamic_shape=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  RemainderOp : public pir::Op<RemainderOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.remainder"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Remainder_Op : public pir::Op<Remainder_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::LayoutTransformationInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.remainder_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  RowConvOp : public pir::Op<RowConvOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.row_conv"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SaveCombineOp : public pir::Op<SaveCombineOp,paddle::dialect::ParseKernelKeyInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.save_combine"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);


  static std::tuple<phi::DataType, phi::Backend> ParseKernelKey(pir::Operation *op);




  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SeedOp : public pir::Op<SeedOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.seed"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, int seed, bool deterministic, const std::string& rng_name, bool force_cpu);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return result(0); }

};

class  SendV2Op : public pir::Op<SendV2Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::SideEffectTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.send_v2"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0, int peer=0, bool use_calc_stream=false, bool dynamic_shape=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }

};

class  SequenceExpandOp : public pir::Op<SequenceExpandOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_expand"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, int ref_level=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SequenceSoftmaxOp : public pir::Op<SequenceSoftmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_softmax"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SetValueOp : public pir::Op<SetValueOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value steps() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  SetValue_Op : public pir::Op<SetValue_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends, const std::vector<int64_t>& steps, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, pir::Value steps_, const std::vector<int64_t>& axes, const std::vector<int64_t>& decrease_axes, const std::vector<int64_t>& none_axes, const std::vector<int64_t>& shape, std::vector<phi::Scalar> values);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value steps() { return operand_source(3); }
  pir::Value out() { return result(0); }

};

class  ShadowFeedOp : public pir::Op<ShadowFeedOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shadow_feed"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShadowFeedTensorsOp : public pir::Op<ShadowFeedTensorsOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.shadow_feed_tensors"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_place_type);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ShareData_Op : public pir::Op<ShareData_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.share_data_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftReluOp : public pir::Op<SoftReluOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.soft_relu"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float threshold=40.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class TEST_API SoftmaxOp : public pir::Op<SoftmaxOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> Decomp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Softmax_Op : public pir::Op<Softmax_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SparseMomentumOp : public pir::Op<SparseMomentumOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_momentum"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, float mu, int axis=0, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, pir::Value axis_, float mu, bool use_nesterov=false, const std::string& regularization_method="", float regularization_coeff=0.0f, bool multi_precision=false, float rescale_grad=1.0f);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value param_, pir::Value grad_, pir::Value velocity_, pir::Value index_, pir::Value learning_rate_, pir::Value master_param_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value param() { return operand_source(0); }
  pir::Value grad() { return operand_source(1); }
  pir::Value velocity() { return operand_source(2); }
  pir::Value index() { return operand_source(3); }
  pir::Value learning_rate() { return operand_source(4); }
  pir::Value master_param() { return operand_source(5); }
  pir::Value axis() { return operand_source(6); }
  pir::Value param_out() { return result(0); }
  pir::Value velocity_out() { return result(1); }
  pir::Value master_param_out() { return result(2); }

};

class  StraightThroughEstimatorGradOp : public pir::Op<StraightThroughEstimatorGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.straight_through_estimator_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  SubtractOp : public pir::Op<SubtractOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  Subtract_Op : public pir::Op<Subtract_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SyncCommStreamOp : public pir::Op<SyncCommStreamOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_comm_stream"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SyncCommStream_Op : public pir::Op<SyncCommStream_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_comm_stream_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int ring_id=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TileOp : public pir::Op<TileOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& repeat_times={});
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value repeat_times_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value repeat_times() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  UniqueOp : public pir::Op<UniqueOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.unique"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, bool return_index=false, bool return_inverse=false, bool return_counts=false, const std::vector<int>& axis={}, phi::DataType dtype=phi::DataType::INT64, bool is_sorted=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value indices() { return result(1); }
  pir::Value inverse() { return result(2); }
  pir::Value counts() { return result(3); }

};

class  WriteToArrayOp : public pir::Op<WriteToArrayOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.write_to_array"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value i() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  CSoftmaxWithMultiLabelCrossEntropyOp : public pir::Op<CSoftmaxWithMultiLabelCrossEntropyOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_multi_label_cross_entropy"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value smooth_weight_, int64_t ignore_index=-100, bool sum_multi_label_loss=true, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value logits_, pir::Value label_, pir::Value smooth_weight_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value logits() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value smooth_weight() { return operand_source(2); }
  pir::Value softmax() { return result(0); }
  pir::Value loss() { return result(1); }

};

class  FasterTokenizerOp : public pir::Op<FasterTokenizerOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.faster_tokenizer"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value vocab_, pir::Value text_, pir::Value text_pair_, bool do_lower_case=false, bool is_split_into_words=false, int max_seq_len=0, bool pad_to_max_seq_len=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value vocab_, pir::Value text_, pir::Value text_pair_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value vocab() { return operand_source(0); }
  pir::Value text() { return operand_source(1); }
  pir::Value text_pair() { return operand_source(2); }
  pir::Value input_ids() { return result(0); }
  pir::Value segment_ids() { return result(1); }

};

class  FusedAttentionOp : public pir::Op<FusedAttentionOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention"; }
  static const char *attributes_name[16];
  static constexpr uint32_t attributes_num = 16;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value src_mask_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, int num_heads, bool transpose_qkv_wb, bool pre_layer_norm, float epsilon, float attn_dropout_rate, bool is_test, bool attn_dropout_fix_seed, int attn_dropout_seed, const std::string& attn_dropout_implementation, float dropout_rate, bool dropout_fix_seed, int dropout_seed, const std::string& dropout_implementation, float ln_epsilon, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value cache_kv_, pir::Value src_mask_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value ln_scale() { return operand_source(1); }
  pir::Value ln_bias() { return operand_source(2); }
  pir::Value qkv_weight() { return operand_source(3); }
  pir::Value qkv_bias() { return operand_source(4); }
  pir::Value cache_kv() { return operand_source(5); }
  pir::Value src_mask() { return operand_source(6); }
  pir::Value out_linear_weight() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ln_scale_2() { return operand_source(9); }
  pir::Value ln_bias_2() { return operand_source(10); }
  pir::Value ln_mean() { return result(0); }
  pir::Value ln_var() { return result(1); }
  pir::Value ln_out() { return result(2); }
  pir::Value qkv_out() { return result(3); }
  pir::Value qkv_bias_out() { return result(4); }
  pir::Value transpose_out_2() { return result(5); }
  pir::Value qk_out() { return result(6); }
  pir::Value qktv_out() { return result(7); }
  pir::Value softmax_out() { return result(8); }
  pir::Value attn_dropout_mask_out() { return result(9); }
  pir::Value attn_dropout_out() { return result(10); }
  pir::Value src_mask_out() { return result(11); }
  pir::Value fmha_out() { return result(12); }
  pir::Value out_linear_out() { return result(13); }
  pir::Value dropout_mask_out() { return result(14); }
  pir::Value ln_mean_2() { return result(15); }
  pir::Value ln_var_2() { return result(16); }
  pir::Value bias_dropout_residual_out() { return result(17); }
  pir::Value cache_kv_out() { return result(18); }
  pir::Value out() { return result(19); }

};

class  FusedFeedforwardOp : public pir::Op<FusedFeedforwardOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_feedforward"; }
  static const char *attributes_name[15];
  static constexpr uint32_t attributes_num = 15;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dropout1_seed_, pir::Value dropout2_seed_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value linear2_bias_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln2_scale_, pir::Value ln2_bias_, bool pre_layer_norm, float ln1_epsilon, float ln2_epsilon, const std::string& act_method, float dropout1_prob, float dropout2_prob, const std::string& dropout1_implementation, const std::string& dropout2_implementation, bool is_test, bool dropout1_fix_seed, bool dropout2_fix_seed, int dropout1_seed_val, int dropout2_seed_val, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value dropout1_seed_, pir::Value dropout2_seed_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value linear2_bias_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value dropout1_seed() { return operand_source(1); }
  pir::Value dropout2_seed() { return operand_source(2); }
  pir::Value linear1_weight() { return operand_source(3); }
  pir::Value linear1_bias() { return operand_source(4); }
  pir::Value linear2_weight() { return operand_source(5); }
  pir::Value linear2_bias() { return operand_source(6); }
  pir::Value ln1_scale() { return operand_source(7); }
  pir::Value ln1_bias() { return operand_source(8); }
  pir::Value ln2_scale() { return operand_source(9); }
  pir::Value ln2_bias() { return operand_source(10); }
  pir::Value out() { return result(0); }
  pir::Value dropout1_mask() { return result(1); }
  pir::Value dropout2_mask() { return result(2); }
  pir::Value ln1_mean() { return result(3); }
  pir::Value ln1_variance() { return result(4); }
  pir::Value ln2_mean() { return result(5); }
  pir::Value ln2_variance() { return result(6); }
  pir::Value linear1_out() { return result(7); }
  pir::Value ln1_out() { return result(8); }
  pir::Value dropout1_out() { return result(9); }
  pir::Value dropout2_out() { return result(10); }

};

class  MovingAverageAbsMaxScaleOp : public pir::Op<MovingAverageAbsMaxScaleOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moving_average_abs_max_scale"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9f, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_accum() { return operand_source(1); }
  pir::Value in_state() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  MovingAverageAbsMaxScale_Op : public pir::Op<MovingAverageAbsMaxScale_Op,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.moving_average_abs_max_scale_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_accum_, pir::Value in_state_, float moving_rate=0.9f, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value in_accum_, pir::Value in_state_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value in_accum() { return operand_source(1); }
  pir::Value in_state() { return operand_source(2); }
  pir::Value out() { return result(0); }
  pir::Value out_scale() { return result(1); }
  pir::Value out_state() { return result(2); }
  pir::Value out_accum() { return result(3); }

};

class  NceOp : public pir::Op<NceOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nce"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value bias_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, int num_total_classes, const std::vector<int>& custom_neg_classes={}, int num_neg_samples=10, int sampler=0, int seed=0, bool is_sparse=false, bool remote_prefetch=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value weight_, pir::Value bias_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value weight() { return operand_source(2); }
  pir::Value bias() { return operand_source(3); }
  pir::Value sample_weight() { return operand_source(4); }
  pir::Value custom_dist_probs() { return operand_source(5); }
  pir::Value custom_dist_alias() { return operand_source(6); }
  pir::Value custom_dist_alias_probs() { return operand_source(7); }
  pir::Value cost() { return result(0); }
  pir::Value sample_logits() { return result(1); }
  pir::Value sample_labels() { return result(2); }

};

class  OnednnToPaddleLayoutOp : public pir::Op<OnednnToPaddleLayoutOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.onednn_to_paddle_layout"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int dst_layout);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};


class  AddDoubleGradOp : public pir::Op<AddDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class  AddDoubleGrad_Op : public pir::Op<AddDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class TEST_API AddGradOp : public pir::Op<AddGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AddGrad_Op : public pir::Op<AddGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AddTripleGradOp : public pir::Op<AddTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_grad_x() { return operand_source(0); }
  pir::Value grad_grad_y() { return operand_source(1); }
  pir::Value grad_grad_out_grad() { return operand_source(2); }
  pir::Value grad_grad_x_grad() { return result(0); }
  pir::Value grad_grad_y_grad() { return result(1); }

};

class  AddTripleGrad_Op : public pir::Op<AddTripleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_triple_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value grad_grad_x() { return operand_source(0); }
  pir::Value grad_grad_y() { return operand_source(1); }
  pir::Value grad_grad_out_grad() { return operand_source(2); }
  pir::Value grad_grad_x_grad() { return result(0); }
  pir::Value grad_grad_y_grad() { return result(1); }

};

class  AssignGradOp : public pir::Op<AssignGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  AssignOutGradOp : public pir::Op<AssignOutGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_out__grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  AssignOutGrad_Op : public pir::Op<AssignOutGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.assign_out__grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  BatchNormDoubleGradOp : public pir::Op<BatchNormDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_double_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out_mean() { return operand_source(2); }
  pir::Value out_variance() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value grad_out() { return operand_source(6); }
  pir::Value grad_x_grad() { return operand_source(7); }
  pir::Value grad_scale_grad() { return operand_source(8); }
  pir::Value grad_bias_grad() { return operand_source(9); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  BatchNormDoubleGrad_Op : public pir::Op<BatchNormDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_double_grad_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value out_mean_, pir::Value out_variance_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_scale_grad_, pir::Value grad_bias_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value out_mean() { return operand_source(2); }
  pir::Value out_variance() { return operand_source(3); }
  pir::Value saved_mean() { return operand_source(4); }
  pir::Value saved_variance() { return operand_source(5); }
  pir::Value grad_out() { return operand_source(6); }
  pir::Value grad_x_grad() { return operand_source(7); }
  pir::Value grad_scale_grad() { return operand_source(8); }
  pir::Value grad_bias_grad() { return operand_source(9); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  BatchNormGradOp : public pir::Op<BatchNormGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_grad"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean_out() { return operand_source(3); }
  pir::Value variance_out() { return operand_source(4); }
  pir::Value saved_mean() { return operand_source(5); }
  pir::Value saved_variance() { return operand_source(6); }
  pir::Value reserve_space() { return operand_source(7); }
  pir::Value out_grad() { return operand_source(8); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  CEmbeddingGradOp : public pir::Op<CEmbeddingGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::Value out_grad_, int64_t start_index=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value weight_, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value weight() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  CSoftmaxWithMultiLabelCrossEntropyGradOp : public pir::Op<CSoftmaxWithMultiLabelCrossEntropyGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.c_softmax_with_multi_label_cross_entropy_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value smooth_weight_, pir::Value loss_grad_, int64_t ignore_index=-100, bool sum_multi_label_loss=true, int ring_id=0, int rank=0, int nranks=0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value softmax_, pir::Value label_, pir::Value smooth_weight_, pir::Value loss_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value softmax() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value smooth_weight() { return operand_source(2); }
  pir::Value loss_grad() { return operand_source(3); }
  pir::Value logits_grad() { return result(0); }

};

class  DivideDoubleGradOp : public pir::Op<DivideDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x() { return operand_source(3); }
  pir::Value grad_x_grad() { return operand_source(4); }
  pir::Value grad_y_grad() { return operand_source(5); }
  pir::Value y_grad() { return result(0); }
  pir::Value out_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  DivideDoubleGrad_Op : public pir::Op<DivideDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value out_, pir::Value grad_out_, pir::Value grad_x_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x() { return operand_source(3); }
  pir::Value grad_x_grad() { return operand_source(4); }
  pir::Value grad_y_grad() { return operand_source(5); }
  pir::Value y_grad() { return result(0); }
  pir::Value out_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  DivideGradOp : public pir::Op<DivideGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  EinsumGradOp : public pir::Op<EinsumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.einsum_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_shape_, pir::Value inner_cache_, pir::Value out_grad_, const std::string& equation);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_shape_, pir::Value inner_cache_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x_shape() { return operand_source(0); }
  pir::Value inner_cache() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  ElementwisePowGradOp : public pir::Op<ElementwisePowGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.elementwise_pow_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  EmbeddingGradOp : public pir::Op<EmbeddingGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  EmbeddingSparseGradOp : public pir::Op<EmbeddingSparseGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.embedding_sparse_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  SparseWeightEmbeddingGradOp : public pir::Op<SparseWeightEmbeddingGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  SparseWeightEmbeddingSparseGradOp : public pir::Op<SparseWeightEmbeddingSparseGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_weight_embedding_sparse_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, int64_t padding_idx=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value weight_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value weight() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value weight_grad() { return result(0); }

};

class  ExponentialGradOp : public pir::Op<ExponentialGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.exponential__grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  FusedAttentionGradOp : public pir::Op<FusedAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention_grad"; }
  static const char *attributes_name[16];
  static constexpr uint32_t attributes_num = 16;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value qkv_bias_out_, pir::Value src_mask_, pir::Value src_mask_out_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::Value ln_out_, pir::Value ln_mean_, pir::Value ln_var_, pir::Value ln_mean_2_, pir::Value ln_var_2_, pir::Value bias_dropout_residual_out_, pir::Value qkv_out_, pir::Value transpose_out_2_, pir::Value qk_out_, pir::Value qktv_out_, pir::Value softmax_out_, pir::Value attn_dropout_mask_out_, pir::Value attn_dropout_out_, pir::Value fmha_out_, pir::Value out_linear_out_, pir::Value dropout_mask_out_, int num_heads, bool transpose_qkv_wb, bool pre_layer_norm, float epsilon, float attn_dropout_rate, bool is_test, bool attn_dropout_fix_seed, int attn_dropout_seed, const std::string& attn_dropout_implementation, float dropout_rate, bool dropout_fix_seed, int dropout_seed, const std::string& dropout_implementation, float ln_epsilon, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value qkv_weight_, pir::Value qkv_bias_, pir::Value qkv_bias_out_, pir::Value src_mask_, pir::Value src_mask_out_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value ln_scale_, pir::Value ln_bias_, pir::Value ln_scale_2_, pir::Value ln_bias_2_, pir::Value ln_out_, pir::Value ln_mean_, pir::Value ln_var_, pir::Value ln_mean_2_, pir::Value ln_var_2_, pir::Value bias_dropout_residual_out_, pir::Value qkv_out_, pir::Value transpose_out_2_, pir::Value qk_out_, pir::Value qktv_out_, pir::Value softmax_out_, pir::Value attn_dropout_mask_out_, pir::Value attn_dropout_out_, pir::Value fmha_out_, pir::Value out_linear_out_, pir::Value dropout_mask_out_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value qkv_weight() { return operand_source(2); }
  pir::Value qkv_bias() { return operand_source(3); }
  pir::Value qkv_bias_out() { return operand_source(4); }
  pir::Value src_mask() { return operand_source(5); }
  pir::Value src_mask_out() { return operand_source(6); }
  pir::Value out_linear_weight() { return operand_source(7); }
  pir::Value out_linear_bias() { return operand_source(8); }
  pir::Value ln_scale() { return operand_source(9); }
  pir::Value ln_bias() { return operand_source(10); }
  pir::Value ln_scale_2() { return operand_source(11); }
  pir::Value ln_bias_2() { return operand_source(12); }
  pir::Value ln_out() { return operand_source(13); }
  pir::Value ln_mean() { return operand_source(14); }
  pir::Value ln_var() { return operand_source(15); }
  pir::Value ln_mean_2() { return operand_source(16); }
  pir::Value ln_var_2() { return operand_source(17); }
  pir::Value bias_dropout_residual_out() { return operand_source(18); }
  pir::Value qkv_out() { return operand_source(19); }
  pir::Value transpose_out_2() { return operand_source(20); }
  pir::Value qk_out() { return operand_source(21); }
  pir::Value qktv_out() { return operand_source(22); }
  pir::Value softmax_out() { return operand_source(23); }
  pir::Value attn_dropout_mask_out() { return operand_source(24); }
  pir::Value attn_dropout_out() { return operand_source(25); }
  pir::Value fmha_out() { return operand_source(26); }
  pir::Value out_linear_out() { return operand_source(27); }
  pir::Value dropout_mask_out() { return operand_source(28); }
  pir::Value qkv_bias_grad() { return result(0); }
  pir::Value qkv_bias_out_grad() { return result(1); }
  pir::Value src_mask_out_grad() { return result(2); }
  pir::Value out_linear_bias_grad() { return result(3); }
  pir::Value ln_scale_grad() { return result(4); }
  pir::Value ln_bias_grad() { return result(5); }
  pir::Value ln_scale_2_grad() { return result(6); }
  pir::Value ln_bias_2_grad() { return result(7); }
  pir::Value x_grad() { return result(8); }
  pir::Value qkv_weight_grad() { return result(9); }
  pir::Value out_linear_weight_grad() { return result(10); }
  pir::Value ln_out_grad() { return result(11); }
  pir::Value bias_dropout_residual_out_grad() { return result(12); }
  pir::Value qkv_out_grad() { return result(13); }
  pir::Value qktv_out_grad() { return result(14); }
  pir::Value transpose_out_2_grad() { return result(15); }
  pir::Value qk_out_grad() { return result(16); }
  pir::Value softmax_out_grad() { return result(17); }
  pir::Value attn_dropout_out_grad() { return result(18); }
  pir::Value fmha_out_grad() { return result(19); }
  pir::Value out_linear_out_grad() { return result(20); }

};

class  FusedFeedforwardGradOp : public pir::Op<FusedFeedforwardGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_feedforward_grad"; }
  static const char *attributes_name[15];
  static constexpr uint32_t attributes_num = 15;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value dropout1_mask_, pir::Value dropout2_mask_, pir::Value linear1_out_, pir::Value dropout1_out_, pir::Value dropout2_out_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln1_out_, pir::Value ln1_mean_, pir::Value ln1_variance_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::Value ln2_mean_, pir::Value ln2_variance_, pir::Value linear2_bias_, bool pre_layer_norm, float ln1_epsilon, float ln2_epsilon, const std::string& act_method, float dropout1_prob, float dropout2_prob, const std::string& dropout1_implementation, const std::string& dropout2_implementation, bool is_test, bool dropout1_fix_seed, bool dropout2_fix_seed, int dropout1_seed_val, int dropout2_seed_val, bool add_residual, int ring_id);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::Value x_, pir::Value linear1_weight_, pir::Value linear1_bias_, pir::Value linear2_weight_, pir::Value dropout1_mask_, pir::Value dropout2_mask_, pir::Value linear1_out_, pir::Value dropout1_out_, pir::Value dropout2_out_, pir::Value ln1_scale_, pir::Value ln1_bias_, pir::Value ln1_out_, pir::Value ln1_mean_, pir::Value ln1_variance_, pir::Value ln2_scale_, pir::Value ln2_bias_, pir::Value ln2_mean_, pir::Value ln2_variance_, pir::Value linear2_bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value linear1_weight() { return operand_source(2); }
  pir::Value linear1_bias() { return operand_source(3); }
  pir::Value linear2_weight() { return operand_source(4); }
  pir::Value dropout1_mask() { return operand_source(5); }
  pir::Value dropout2_mask() { return operand_source(6); }
  pir::Value linear1_out() { return operand_source(7); }
  pir::Value dropout1_out() { return operand_source(8); }
  pir::Value dropout2_out() { return operand_source(9); }
  pir::Value ln1_scale() { return operand_source(10); }
  pir::Value ln1_bias() { return operand_source(11); }
  pir::Value ln1_out() { return operand_source(12); }
  pir::Value ln1_mean() { return operand_source(13); }
  pir::Value ln1_variance() { return operand_source(14); }
  pir::Value ln2_scale() { return operand_source(15); }
  pir::Value ln2_bias() { return operand_source(16); }
  pir::Value ln2_mean() { return operand_source(17); }
  pir::Value ln2_variance() { return operand_source(18); }
  pir::Value linear2_bias() { return operand_source(19); }
  pir::Value x_grad() { return result(0); }
  pir::Value linear1_weight_grad() { return result(1); }
  pir::Value linear1_bias_grad() { return result(2); }
  pir::Value linear2_weight_grad() { return result(3); }
  pir::Value linear2_bias_grad() { return result(4); }
  pir::Value ln1_scale_grad() { return result(5); }
  pir::Value ln1_bias_grad() { return result(6); }
  pir::Value ln2_scale_grad() { return result(7); }
  pir::Value ln2_bias_grad() { return result(8); }

};

class  FusedGateAttentionGradOp : public pir::Op<FusedGateAttentionGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_gate_attention_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value query_weight_, pir::Value key_weight_, pir::Value value_weight_, pir::Value qkv_weight_, pir::Value nonbatched_bias_, pir::Value src_mask_, pir::Value gate_weight_, pir::Value gate_bias_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value query_transpose_out_, pir::Value key_transpose_out_, pir::Value value_transpose_out_, pir::Value qkv_transpose_out_, pir::Value softmax_out_, pir::Value softmax_lse_, pir::Value fmha_out_, pir::Value gate_out_, pir::Value out_grad_, bool has_gating=true, bool merge_qkv=true, bool use_flash_attn=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value query_weight_, pir::Value key_weight_, pir::Value value_weight_, pir::Value qkv_weight_, pir::Value nonbatched_bias_, pir::Value src_mask_, pir::Value gate_weight_, pir::Value gate_bias_, pir::Value out_linear_weight_, pir::Value out_linear_bias_, pir::Value query_transpose_out_, pir::Value key_transpose_out_, pir::Value value_transpose_out_, pir::Value qkv_transpose_out_, pir::Value softmax_out_, pir::Value softmax_lse_, pir::Value fmha_out_, pir::Value gate_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value query_weight() { return operand_source(2); }
  pir::Value key_weight() { return operand_source(3); }
  pir::Value value_weight() { return operand_source(4); }
  pir::Value qkv_weight() { return operand_source(5); }
  pir::Value nonbatched_bias() { return operand_source(6); }
  pir::Value src_mask() { return operand_source(7); }
  pir::Value gate_weight() { return operand_source(8); }
  pir::Value gate_bias() { return operand_source(9); }
  pir::Value out_linear_weight() { return operand_source(10); }
  pir::Value out_linear_bias() { return operand_source(11); }
  pir::Value query_transpose_out() { return operand_source(12); }
  pir::Value key_transpose_out() { return operand_source(13); }
  pir::Value value_transpose_out() { return operand_source(14); }
  pir::Value qkv_transpose_out() { return operand_source(15); }
  pir::Value softmax_out() { return operand_source(16); }
  pir::Value softmax_lse() { return operand_source(17); }
  pir::Value fmha_out() { return operand_source(18); }
  pir::Value gate_out() { return operand_source(19); }
  pir::Value out_grad() { return operand_source(20); }
  pir::Value query_grad() { return result(0); }
  pir::Value key_grad() { return result(1); }
  pir::Value query_weight_grad() { return result(2); }
  pir::Value key_weight_grad() { return result(3); }
  pir::Value value_weight_grad() { return result(4); }
  pir::Value qkv_weight_grad() { return result(5); }
  pir::Value nonbatched_bias_grad() { return result(6); }
  pir::Value gate_weight_grad() { return result(7); }
  pir::Value gate_bias_grad() { return result(8); }
  pir::Value out_linear_weight_grad() { return result(9); }
  pir::Value out_linear_bias_grad() { return result(10); }

};

class  HardswishGradOp : public pir::Op<HardswishGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  HardswishGrad_Op : public pir::Op<HardswishGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.hardswish_grad_"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LegacyMatmulGradOp : public pir::Op<LegacyMatmulGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.legacy_matmul_grad"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, bool transpose_x=false, bool transpose_y=false, float alpha=1.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  LegacyReshapeGradOp : public pir::Op<LegacyReshapeGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.legacy_reshape_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LodResetGradOp : public pir::Op<LodResetGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_reset_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& target_lod={}, bool append=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LodResetGrad_Op : public pir::Op<LodResetGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lod_reset_grad_"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int>& target_lod={}, bool append=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LookupTableGradOp : public pir::Op<LookupTableGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_grad"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value w_grad() { return result(0); }

};

class  LookupTableSparseGradOp : public pir::Op<LookupTableSparseGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_sparse_grad"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value w_grad() { return result(0); }

};

class  LookupTableGradSrOp : public pir::Op<LookupTableGradSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_grad_sr"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value w_grad() { return result(0); }

};

class  LookupTableSparseGradSrOp : public pir::Op<LookupTableSparseGradSrOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lookup_table_sparse_grad_sr"; }
  static const char *attributes_name[14];
  static constexpr uint32_t attributes_num = 14;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, bool is_sparse=false, bool is_distributed=false, int64_t padding_idx=-1, bool remote_prefetch=false, const std::string& entry_config="", bool is_test=false, const std::string& entry="none", const std::string& table_class="none", const std::vector<std::string>& table_names={}, int trainer_id=0, int slot=0, bool grad_inplace=false, const std::vector<std::string>& epmap={}, const std::vector<int64_t>& height_sections={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value w_, pir::Value ids_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value w() { return operand_source(0); }
  pir::Value ids() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value w_grad() { return result(0); }

};

class  LrnGradOp : public pir::Op<LrnGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.lrn_grad"; }
  static const char *attributes_name[5];
  static constexpr uint32_t attributes_num = 5;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value mid_out_, pir::Value out_grad_, int n=5, float k=2.0, float alpha=0.0001, float beta=0.75, const std::string& data_format="AnyLayout");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value mid_out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value mid_out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  MatmulDoubleGradOp : public pir::Op<MatmulDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_double_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class TEST_API MatmulGradOp : public pir::Op<MatmulGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);

  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MatmulTripleGradOp : public pir::Op<MatmulTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_triple_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, bool transpose_x=false, bool transpose_y=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_grad_x_, pir::Value grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_grad_x() { return operand_source(3); }
  pir::Value grad_grad_y() { return operand_source(4); }
  pir::Value grad_x_grad() { return operand_source(5); }
  pir::Value grad_y_grad() { return operand_source(6); }
  pir::Value grad_grad_out_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }
  pir::Value grad_grad_x_grad() { return result(3); }
  pir::Value grad_grad_y_grad() { return result(4); }

};

class  MatmulWithFlattenGradOp : public pir::Op<MatmulWithFlattenGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_with_flatten_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int x_num_col_dims=1, int y_num_col_dims=1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MaximumGradOp : public pir::Op<MaximumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maximum_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MinGradOp : public pir::Op<MinGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.min_grad"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false, bool reduce_all=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value axis() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  MinimumGradOp : public pir::Op<MinimumGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.minimum_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MultiplyDoubleGradOp : public pir::Op<MultiplyDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  MultiplyDoubleGrad_Op : public pir::Op<MultiplyDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value grad_out() { return operand_source(2); }
  pir::Value grad_x_grad() { return operand_source(3); }
  pir::Value grad_y_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value grad_out_grad() { return result(2); }

};

class  MultiplyGradOp : public pir::Op<MultiplyGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MultiplyTripleGradOp : public pir::Op<MultiplyTripleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_triple_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value fwd_grad_out_, pir::Value fwd_grad_grad_x_, pir::Value fwd_grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value fwd_grad_out_, pir::Value fwd_grad_grad_x_, pir::Value fwd_grad_grad_y_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::Value grad_grad_out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value fwd_grad_out() { return operand_source(2); }
  pir::Value fwd_grad_grad_x() { return operand_source(3); }
  pir::Value fwd_grad_grad_y() { return operand_source(4); }
  pir::Value grad_x_grad() { return operand_source(5); }
  pir::Value grad_y_grad() { return operand_source(6); }
  pir::Value grad_grad_out_grad() { return operand_source(7); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }
  pir::Value fwd_grad_out_grad() { return result(2); }
  pir::Value fwd_grad_grad_x_grad() { return result(3); }
  pir::Value fwd_grad_grad_y_grad() { return result(4); }

};

class  NceGradOp : public pir::Op<NceGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nce_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, int num_total_classes, const std::vector<int>& custom_neg_classes={}, int num_neg_samples=10, int sampler=0, int seed=0, bool is_sparse=false, bool remote_prefetch=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight() { return operand_source(3); }
  pir::Value sample_logits() { return operand_source(4); }
  pir::Value sample_labels() { return operand_source(5); }
  pir::Value sample_weight() { return operand_source(6); }
  pir::Value custom_dist_probs() { return operand_source(7); }
  pir::Value custom_dist_alias() { return operand_source(8); }
  pir::Value custom_dist_alias_probs() { return operand_source(9); }
  pir::Value cost_grad() { return operand_source(10); }
  pir::Value input_grad() { return result(0); }
  pir::Value bias_grad() { return result(1); }
  pir::Value weight_grad() { return result(2); }

};

class  NceSrGradOp : public pir::Op<NceSrGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.nce_sr_grad"; }
  static const char *attributes_name[8];
  static constexpr uint32_t attributes_num = 8;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, int num_total_classes, const std::vector<int>& custom_neg_classes={}, int num_neg_samples=10, int sampler=0, int seed=0, bool is_sparse=false, bool remote_prefetch=false, bool is_test=false);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value label_, pir::Value bias_, pir::Value weight_, pir::Value sample_logits_, pir::Value sample_labels_, pir::Value sample_weight_, pir::Value custom_dist_probs_, pir::Value custom_dist_alias_, pir::Value custom_dist_alias_probs_, pir::Value cost_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value label() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value weight() { return operand_source(3); }
  pir::Value sample_logits() { return operand_source(4); }
  pir::Value sample_labels() { return operand_source(5); }
  pir::Value sample_weight() { return operand_source(6); }
  pir::Value custom_dist_probs() { return operand_source(7); }
  pir::Value custom_dist_alias() { return operand_source(8); }
  pir::Value custom_dist_alias_probs() { return operand_source(9); }
  pir::Value cost_grad() { return operand_source(10); }
  pir::Value input_grad() { return result(0); }
  pir::Value bias_grad() { return result(1); }
  pir::Value weight_grad() { return result(2); }

};

class  PrintGradOp : public pir::Op<PrintGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.print_grad"; }
  static const char *attributes_name[10];
  static constexpr uint32_t attributes_num = 10;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, int first_n, const std::string& message, int summarize, bool print_tensor_name=true, bool print_tensor_type=true, bool print_tensor_shape=true, bool print_tensor_layout=true, bool print_tensor_lod=true, const std::string& print_phase="BOTH", bool is_forward=true);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value in_grad() { return result(0); }

};

class  RemainderGradOp : public pir::Op<RemainderGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.remainder_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  RowConvGradOp : public pir::Op<RowConvGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.row_conv_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value filter_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value filter() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value filter_grad() { return result(1); }

};

class  SequenceExpandGradOp : public pir::Op<SequenceExpandGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_expand_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int ref_level=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SequenceSoftmaxGradOp : public pir::Op<SequenceSoftmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sequence_softmax_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SetValueGradOp : public pir::Op<SetValueGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.set_value_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  SoftReluGradOp : public pir::Op<SoftReluGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.soft_relu_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, float threshold=40.0f);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SoftmaxGradOp : public pir::Op<SoftmaxGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SubtractDoubleGradOp : public pir::Op<SubtractDoubleGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_double_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class  SubtractDoubleGrad_Op : public pir::Op<SubtractDoubleGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_double_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value y_, pir::Value grad_out_, pir::Value grad_x_grad_, pir::Value grad_y_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value y() { return operand_source(0); }
  pir::Value grad_out() { return operand_source(1); }
  pir::Value grad_x_grad() { return operand_source(2); }
  pir::Value grad_y_grad() { return operand_source(3); }
  pir::Value grad_out_grad() { return result(0); }

};

class  SubtractGradOp : public pir::Op<SubtractGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::DecompVjpInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_grad"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static std::vector<std::vector<pir::Value>> DecompVjp(pir::Operation* op);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SubtractGrad_Op : public pir::Op<SubtractGrad_Op,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::CacheGradOpSymbolicShapeInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_grad_"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  TileDoubleGradOp : public pir::Op<TileDoubleGradOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile_double_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value grad_x_grad_, const std::vector<int64_t>& repeat_times);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value grad_x_grad() { return operand_source(0); }
  pir::Value repeat_times() { return operand_source(1); }
  pir::Value grad_out_grad() { return result(0); }

};

class  TileGradOp : public pir::Op<TileGradOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tile_grad"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& repeat_times);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value repeat_times_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value repeat_times() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};


class  ArangeOp : public pir::Op<ArangeOp,paddle::dialect::InferMetaInterface,paddle::dialect::InferSymbolicShapeInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.arange"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, double start, double end, double step, phi::DataType dtype=phi::DataType::FLOAT64, const phi::Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value start_, pir::Value end_, pir::Value step_, phi::DataType dtype=phi::DataType::FLOAT64, const phi::Place& place=phi::CPUPlace());
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  bool InferSymbolicShape(pir::InferSymbolicShapeContext *infer_context);



  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value start() { return operand_source(0); }
  pir::Value end() { return operand_source(1); }
  pir::Value step() { return operand_source(2); }
  pir::Value out() { return result(0); }

};


class  AbsCooSpOp : public pir::Op<AbsCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AbsCsrSpOp : public pir::Op<AbsCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AcosCooSpOp : public pir::Op<AcosCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AcosCsrSpOp : public pir::Op<AcosCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AcoshCooSpOp : public pir::Op<AcoshCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AcoshCsrSpOp : public pir::Op<AcoshCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AddCooCooSpOp : public pir::Op<AddCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_coo_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  AddCsrCsrSpOp : public pir::Op<AddCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_csr_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  AddCooDenseSpOp : public pir::Op<AddCooDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_coo_dense_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  AsinCooSpOp : public pir::Op<AsinCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsinCsrSpOp : public pir::Op<AsinCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsinhCooSpOp : public pir::Op<AsinhCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AsinhCsrSpOp : public pir::Op<AsinhCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AtanCooSpOp : public pir::Op<AtanCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AtanCsrSpOp : public pir::Op<AtanCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AtanhCooSpOp : public pir::Op<AtanhCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AtanhCsrSpOp : public pir::Op<AtanhCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  BatchNorm_SpOp : public pir::Op<BatchNorm_SpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_sp_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_format, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  CastCooSpOp : public pir::Op<CastCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_coo_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType index_dtype=phi::DataType::UNDEFINED, phi::DataType value_dtype=phi::DataType::UNDEFINED);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CastCsrSpOp : public pir::Op<CastCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_csr_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, phi::DataType index_dtype=phi::DataType::UNDEFINED, phi::DataType value_dtype=phi::DataType::UNDEFINED);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Conv3dSpOp : public pir::Op<Conv3dSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_sp"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, int groups, bool subm, const std::string& key="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value kernel() { return operand_source(1); }
  pir::Value out() { return result(0); }
  pir::Value rulebook() { return result(1); }
  pir::Value counter() { return result(2); }

};

class  Conv3dImplicitGemmSpOp : public pir::Op<Conv3dImplicitGemmSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_implicit_gemm_sp"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, int groups, bool subm, const std::string& key="");
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value kernel() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DivideCooCooSpOp : public pir::Op<DivideCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_coo_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DivideCsrCsrSpOp : public pir::Op<DivideCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_csr_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  DivideScalarCooSpOp : public pir::Op<DivideScalarCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_scalar_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scalar);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DivideScalarCsrSpOp : public pir::Op<DivideScalarCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_scalar_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scalar);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Expm1CooSpOp : public pir::Op<Expm1CooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Expm1CsrSpOp : public pir::Op<Expm1CsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsnanCooSpOp : public pir::Op<IsnanCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  IsnanCsrSpOp : public pir::Op<IsnanCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.isnan_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LeakyReluCooSpOp : public pir::Op<LeakyReluCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  LeakyReluCsrSpOp : public pir::Op<LeakyReluCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log1pCooSpOp : public pir::Op<Log1pCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Log1pCsrSpOp : public pir::Op<Log1pCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MultiplyCooCooSpOp : public pir::Op<MultiplyCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_coo_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MultiplyCsrCsrSpOp : public pir::Op<MultiplyCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_csr_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  PowCooSpOp : public pir::Op<PowCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float factor);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  PowCsrSpOp : public pir::Op<PowCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float factor);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReluCooSpOp : public pir::Op<ReluCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReluCsrSpOp : public pir::Op<ReluCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Relu6CooSpOp : public pir::Op<Relu6CooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  Relu6CsrSpOp : public pir::Op<Relu6CsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ReshapeCooSpOp : public pir::Op<ReshapeCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ReshapeCsrSpOp : public pir::Op<ReshapeCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& shape);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value shape_);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value shape() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  ScaleCooSpOp : public pir::Op<ScaleCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_coo_sp"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale, float bias, bool bias_after_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ScaleCsrSpOp : public pir::Op<ScaleCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_csr_sp"; }
  static const char *attributes_name[3];
  static constexpr uint32_t attributes_num = 3;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float scale, float bias, bool bias_after_scale);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinCooSpOp : public pir::Op<SinCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinCsrSpOp : public pir::Op<SinCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinhCooSpOp : public pir::Op<SinhCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SinhCsrSpOp : public pir::Op<SinhCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftmaxCooSpOp : public pir::Op<SoftmaxCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SoftmaxCsrSpOp : public pir::Op<SoftmaxCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::CustomVjpTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int axis=-1);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SparseCooTensorSpOp : public pir::Op<SparseCooTensorSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_coo_tensor_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value indices_, const std::vector<int64_t>& shape={});
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value values_, pir::Value indices_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value values() { return operand_source(0); }
  pir::Value indices() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SqrtCooSpOp : public pir::Op<SqrtCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SqrtCsrSpOp : public pir::Op<SqrtCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquareCooSpOp : public pir::Op<SquareCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SquareCsrSpOp : public pir::Op<SquareCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  SubtractCooCooSpOp : public pir::Op<SubtractCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_coo_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SubtractCsrCsrSpOp : public pir::Op<SubtractCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,pir::BinaryElementWiseTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_csr_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SumCooSpOp : public pir::Op<SumCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_coo_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SumCsrSpOp : public pir::Op<SumCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_csr_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axis={}, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value axis_, phi::DataType dtype=phi::DataType::UNDEFINED, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value axis() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SyncBatchNorm_SpOp : public pir::Op<SyncBatchNorm_SpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::InplaceTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_sp_"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, bool is_test, float momentum, float epsilon, const std::string& data_format, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mean_, pir::Value variance_, pir::Value scale_, pir::Value bias_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mean() { return operand_source(1); }
  pir::Value variance() { return operand_source(2); }
  pir::Value scale() { return operand_source(3); }
  pir::Value bias() { return operand_source(4); }
  pir::Value out() { return result(0); }
  pir::Value mean_out() { return result(1); }
  pir::Value variance_out() { return result(2); }
  pir::Value saved_mean() { return result(3); }
  pir::Value saved_variance() { return result(4); }
  pir::Value reserve_space() { return result(5); }

};

class  TanCooSpOp : public pir::Op<TanCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TanCsrSpOp : public pir::Op<TanCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TanhCooSpOp : public pir::Op<TanhCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TanhCsrSpOp : public pir::Op<TanhCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CooToDenseSpOp : public pir::Op<CooToDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coo_to_dense_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CsrToDenseSpOp : public pir::Op<CsrToDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.csr_to_dense_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DenseToCooSpOp : public pir::Op<DenseToCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dense_to_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t sparse_dim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CsrToCooSpOp : public pir::Op<CsrToCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.csr_to_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, int64_t sparse_dim);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  DenseToCsrSpOp : public pir::Op<DenseToCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.dense_to_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  CooToCsrSpOp : public pir::Op<CooToCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coo_to_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TransposeCooSpOp : public pir::Op<TransposeCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  TransposeCsrSpOp : public pir::Op<TransposeCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ValuesCooSpOp : public pir::Op<ValuesCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.values_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  ValuesCsrSpOp : public pir::Op<ValuesCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.values_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  AddmmCsrDenseSpOp : public pir::Op<AddmmCsrDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_csr_dense_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AddmmCsrCsrSpOp : public pir::Op<AddmmCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_csr_csr_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AddmmCooDenseSpOp : public pir::Op<AddmmCooDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_coo_dense_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  AddmmCooCooSpOp : public pir::Op<AddmmCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_coo_coo_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, float beta=1.0, float alpha=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  CoalesceSpOp : public pir::Op<CoalesceSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.coalesce_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FullLikeCooSpOp : public pir::Op<FullLikeCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_like_coo_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value, phi::DataType dtype=phi::DataType::UNDEFINED);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FullLikeCsrSpOp : public pir::Op<FullLikeCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface,paddle::dialect::ForwardOnlyTrait> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.full_like_csr_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, float value, phi::DataType dtype=phi::DataType::UNDEFINED);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  FusedAttentionSpOp : public pir::Op<FusedAttentionSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value sparse_mask_, pir::Value key_padding_mask_, pir::Value attn_mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value sparse_mask() { return operand_source(3); }
  pir::Value key_padding_mask() { return operand_source(4); }
  pir::Value attn_mask() { return operand_source(5); }
  pir::Value out() { return result(0); }
  pir::Value softmax() { return result(1); }

};

class  IndicesSpOp : public pir::Op<IndicesSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.indices_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }

};

class  MaskAsCooSpOp : public pir::Op<MaskAsCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mask_as_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaskAsCsrSpOp : public pir::Op<MaskAsCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mask_as_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaskedMatmulSpOp : public pir::Op<MaskedMatmulSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_matmul_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value mask_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value mask() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  MatmulCsrDenseSpOp : public pir::Op<MatmulCsrDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_csr_dense_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MatmulCsrCsrSpOp : public pir::Op<MatmulCsrCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_csr_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MatmulCooDenseSpOp : public pir::Op<MatmulCooDenseSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_coo_dense_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MatmulCooCooSpOp : public pir::Op<MatmulCooCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_coo_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MaxpoolSpOp : public pir::Op<MaxpoolSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxpool_sp"; }
  static const char *attributes_name[4];
  static constexpr uint32_t attributes_num = 4;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int>& kernel_sizes, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out() { return result(0); }
  pir::Value rulebook() { return result(1); }
  pir::Value counter() { return result(2); }

};

class  MvCooSpOp : public pir::Op<MvCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_coo_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  MvCsrSpOp : public pir::Op<MvCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_csr_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out() { return result(0); }

};

class  SliceCooSpOp : public pir::Op<SliceCooSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_coo_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value out() { return result(0); }

};

class  SliceCsrSpOp : public pir::Op<SliceCsrSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::VjpInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_csr_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);



  void CacheGradOpSymbolicShape(pir::InferSymbolicShapeContext* infer_context);

  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value starts() { return operand_source(1); }
  pir::Value ends() { return operand_source(2); }
  pir::Value out() { return result(0); }

};


class  AbsCooGradSpOp : public pir::Op<AbsCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AbsCsrGradSpOp : public pir::Op<AbsCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.abs_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcosCooGradSpOp : public pir::Op<AcosCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcosCsrGradSpOp : public pir::Op<AcosCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acos_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcoshCooGradSpOp : public pir::Op<AcoshCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AcoshCsrGradSpOp : public pir::Op<AcoshCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.acosh_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AddCooCooGradSpOp : public pir::Op<AddCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_coo_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AddCsrCsrGradSpOp : public pir::Op<AddCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_csr_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AddCooDenseGradSpOp : public pir::Op<AddCooDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.add_coo_dense_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  AddmmCsrDenseGradSpOp : public pir::Op<AddmmCsrDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_csr_dense_grad_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha=1.0, float beta=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  AddmmCsrCsrGradSpOp : public pir::Op<AddmmCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_csr_csr_grad_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha=1.0, float beta=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  AddmmCooDenseGradSpOp : public pir::Op<AddmmCooDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_coo_dense_grad_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha=1.0, float beta=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  AddmmCooCooGradSpOp : public pir::Op<AddmmCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.addmm_coo_coo_grad_sp"; }
  static const char *attributes_name[2];
  static constexpr uint32_t attributes_num = 2;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, float alpha=1.0, float beta=1.0);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value input_, pir::Value x_, pir::Value y_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value input() { return operand_source(0); }
  pir::Value x() { return operand_source(1); }
  pir::Value y() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value input_grad() { return result(0); }
  pir::Value x_grad() { return result(1); }
  pir::Value y_grad() { return result(2); }

};

class  AsinCooGradSpOp : public pir::Op<AsinCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinCsrGradSpOp : public pir::Op<AsinCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asin_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinhCooGradSpOp : public pir::Op<AsinhCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AsinhCsrGradSpOp : public pir::Op<AsinhCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.asinh_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanCooGradSpOp : public pir::Op<AtanCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanCsrGradSpOp : public pir::Op<AtanCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atan_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanhCooGradSpOp : public pir::Op<AtanhCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  AtanhCsrGradSpOp : public pir::Op<AtanhCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.atanh_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  BatchNormGradSpOp : public pir::Op<BatchNormGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.batch_norm_grad_sp"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value mean_out_, pir::Value variance_out_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value mean_out() { return operand_source(3); }
  pir::Value variance_out() { return operand_source(4); }
  pir::Value saved_mean() { return operand_source(5); }
  pir::Value saved_variance() { return operand_source(6); }
  pir::Value reserve_space() { return operand_source(7); }
  pir::Value out_grad() { return operand_source(8); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  CastCooGradSpOp : public pir::Op<CastCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, phi::DataType value_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  CastCsrGradSpOp : public pir::Op<CastCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.cast_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, phi::DataType value_dtype);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Conv3dGradSpOp : public pir::Op<Conv3dGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.conv3d_grad_sp"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, pir::Value out_, pir::Value rulebook_, pir::Value counter_, pir::Value out_grad_, const std::vector<int>& paddings, const std::vector<int>& dilations, const std::vector<int>& strides, int groups, bool subm, const std::string& key);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value kernel_, pir::Value out_, pir::Value rulebook_, pir::Value counter_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value kernel() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value rulebook() { return operand_source(3); }
  pir::Value counter() { return operand_source(4); }
  pir::Value out_grad() { return operand_source(5); }
  pir::Value x_grad() { return result(0); }
  pir::Value kernel_grad() { return result(1); }

};

class  DivideCooCooGradSpOp : public pir::Op<DivideCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_coo_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  DivideCsrCsrGradSpOp : public pir::Op<DivideCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_csr_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out() { return operand_source(2); }
  pir::Value out_grad() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  DivideScalarGradSpOp : public pir::Op<DivideScalarGradSpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.divide_scalar_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  Expm1CooGradSpOp : public pir::Op<Expm1CooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Expm1CsrGradSpOp : public pir::Op<Expm1CsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.expm1_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LeakyReluCooGradSpOp : public pir::Op<LeakyReluCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  LeakyReluCsrGradSpOp : public pir::Op<LeakyReluCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.leaky_relu_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float alpha);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log1pCooGradSpOp : public pir::Op<Log1pCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Log1pCsrGradSpOp : public pir::Op<Log1pCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.log1p_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  MaskAsCooGradSpOp : public pir::Op<MaskAsCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mask_as_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MaskAsCsrGradSpOp : public pir::Op<MaskAsCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mask_as_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value mask_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value mask() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  MaskedMatmulGradSpOp : public pir::Op<MaskedMatmulGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.masked_matmul_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MatmulCsrDenseGradSpOp : public pir::Op<MatmulCsrDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_csr_dense_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MatmulCsrCsrGradSpOp : public pir::Op<MatmulCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_csr_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MatmulCooDenseGradSpOp : public pir::Op<MatmulCooDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_coo_dense_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MatmulCooCooGradSpOp : public pir::Op<MatmulCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.matmul_coo_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MaxpoolGradSpOp : public pir::Op<MaxpoolGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.maxpool_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rulebook_, pir::Value counter_, pir::Value out_, pir::Value out_grad_, const std::vector<int>& kernel_sizes);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value rulebook_, pir::Value counter_, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value rulebook() { return operand_source(1); }
  pir::Value counter() { return operand_source(2); }
  pir::Value out() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value x_grad() { return result(0); }

};

class  MultiplyCooCooGradSpOp : public pir::Op<MultiplyCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_coo_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MultiplyCsrCsrGradSpOp : public pir::Op<MultiplyCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.multiply_csr_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  MvCooGradSpOp : public pir::Op<MvCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value vec_grad() { return result(1); }

};

class  MvCsrGradSpOp : public pir::Op<MvCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.mv_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value vec_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value vec() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value vec_grad() { return result(1); }

};

class  PowCooGradSpOp : public pir::Op<PowCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float factor);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  PowCsrGradSpOp : public pir::Op<PowCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.pow_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, float factor);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Relu6CooGradSpOp : public pir::Op<Relu6CooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  Relu6CsrGradSpOp : public pir::Op<Relu6CsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu6_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReluCooGradSpOp : public pir::Op<ReluCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReluCsrGradSpOp : public pir::Op<ReluCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.relu_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReshapeCooGradSpOp : public pir::Op<ReshapeCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ReshapeCsrGradSpOp : public pir::Op<ReshapeCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.reshape_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ScaleGradSpOp : public pir::Op<ScaleGradSpOp,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.scale_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build();
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);

  pir::Value out_grad() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinCooGradSpOp : public pir::Op<SinCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinCsrGradSpOp : public pir::Op<SinCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sin_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinhCooGradSpOp : public pir::Op<SinhCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SinhCsrGradSpOp : public pir::Op<SinhCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sinh_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftmaxCooGradSpOp : public pir::Op<SoftmaxCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SoftmaxCsrGradSpOp : public pir::Op<SoftmaxCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.softmax_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, int axis);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SparseCooTensorGradSpOp : public pir::Op<SparseCooTensorGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sparse_coo_tensor_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value indices_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value indices() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value values_grad() { return result(0); }

};

class  SqrtCooGradSpOp : public pir::Op<SqrtCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SqrtCsrGradSpOp : public pir::Op<SqrtCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sqrt_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SquareCooGradSpOp : public pir::Op<SquareCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SquareCsrGradSpOp : public pir::Op<SquareCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.square_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  SubtractCooCooGradSpOp : public pir::Op<SubtractCooCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_coo_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SubtractCsrCsrGradSpOp : public pir::Op<SubtractCsrCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.subtract_csr_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value y_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value y() { return operand_source(1); }
  pir::Value out_grad() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }
  pir::Value y_grad() { return result(1); }

};

class  SumCooGradSpOp : public pir::Op<SumCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SumCsrGradSpOp : public pir::Op<SumCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sum_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axis={}, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value axis_, bool keepdim=false);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value axis() { return operand_source(2); }
  pir::Value x_grad() { return result(0); }

};

class  SyncBatchNormGradSpOp : public pir::Op<SyncBatchNormGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.sync_batch_norm_grad_sp"; }
  static const char *attributes_name[6];
  static constexpr uint32_t attributes_num = 6;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, float momentum, float epsilon, const std::string& data_format, bool is_test, bool use_global_stats, bool trainable_statistics);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value scale_, pir::Value bias_, pir::Value saved_mean_, pir::Value saved_variance_, pir::Value reserve_space_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value scale() { return operand_source(1); }
  pir::Value bias() { return operand_source(2); }
  pir::Value saved_mean() { return operand_source(3); }
  pir::Value saved_variance() { return operand_source(4); }
  pir::Value reserve_space() { return operand_source(5); }
  pir::Value out_grad() { return operand_source(6); }
  pir::Value x_grad() { return result(0); }
  pir::Value scale_grad() { return result(1); }
  pir::Value bias_grad() { return result(2); }

};

class  TanCooGradSpOp : public pir::Op<TanCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanCsrGradSpOp : public pir::Op<TanCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tan_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhCooGradSpOp : public pir::Op<TanhCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  TanhCsrGradSpOp : public pir::Op<TanhCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.tanh_csr_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ToDenseGradSpOp : public pir::Op<ToDenseGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.to_dense_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  ToSparseCooGradSpOp : public pir::Op<ToSparseCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.to_sparse_coo_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  TransposeCooGradSpOp : public pir::Op<TransposeCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  TransposeCsrGradSpOp : public pir::Op<TransposeCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.transpose_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, const std::vector<int>& perm);
  
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value out_grad() { return operand_source(0); }
  pir::Value x_grad() { return result(0); }

};

class  ValuesGradSpOp : public pir::Op<ValuesGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.values_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value x_grad() { return result(0); }

};

class  FusedAttentionGradSpOp : public pir::Op<FusedAttentionGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.fused_attention_grad_sp"; }
  static constexpr const char **attributes_name = nullptr;
  static constexpr uint32_t attributes_num = 0;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value query_, pir::Value key_, pir::Value value_, pir::Value softmax_, pir::Value out_grad_);
  
  
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value query() { return operand_source(0); }
  pir::Value key() { return operand_source(1); }
  pir::Value value() { return operand_source(2); }
  pir::Value softmax() { return operand_source(3); }
  pir::Value out_grad() { return operand_source(4); }
  pir::Value query_grad() { return result(0); }
  pir::Value key_grad() { return result(1); }
  pir::Value value_grad() { return result(2); }

};

class  SliceCooGradSpOp : public pir::Op<SliceCooGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_coo_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

class  SliceCsrGradSpOp : public pir::Op<SliceCsrGradSpOp,paddle::dialect::InferMetaInterface,paddle::dialect::OpYamlInfoInterface,paddle::dialect::GetKernelTypeForVarInterface> {
 public:
  using Op::Op;
  static const char *name() { return "pd_op.slice_csr_grad_sp"; }
  static const char *attributes_name[1];
  static constexpr uint32_t attributes_num = 1;
  static OpInfoTuple GetOpInfo();
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, const std::vector<int64_t>& axes, const std::vector<int64_t>& starts, const std::vector<int64_t>& ends);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::Value starts_, pir::Value ends_, const std::vector<int64_t>& axes);
  static void Build(pir::Builder &builder, pir::OperationArgument &argument, pir::Value x_, pir::Value out_grad_, pir::AttributeMap attributes);
  
  void VerifySig();

  static phi::DataType GetKernelTypeForVar(
      const std::string& var_name,
        const phi::DataType& tensor_dtype,
        const phi::DataType& expected_kernel_dtype);





  static std::vector<std::vector<pir::Value>> Vjp(pir::Operation* op, const std::vector<std::vector<pir::Value>>& inputs_, const std::vector<std::vector<pir::Value>>& outputs, const std::vector<std::vector<pir::Value>>& out_grads, const std::vector<std::vector<bool>>& stop_gradients);
  static void InferMeta(phi::InferMetaContext *infer_meta );
  static std::vector<pir::Type> InferMeta( const std::vector<pir::Value>& input_values, pir::AttributeMap* p_attributes );
  pir::Value x() { return operand_source(0); }
  pir::Value out_grad() { return operand_source(1); }
  pir::Value starts() { return operand_source(2); }
  pir::Value ends() { return operand_source(3); }
  pir::Value x_grad() { return result(0); }

};

} // namespace dialect
} // namespace paddle


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Abs_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AccuracyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AccuracyCheckOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Acos_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Acosh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adadelta_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adagrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AdagradDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AdamDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adamax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Adamw_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddPositionEncodingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Addmm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineChannelOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineChannel_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineGridOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllGatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllReduceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllReduce_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllToAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AllcloseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AngleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AnyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ApFacadeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ApTrivialFusionBeginOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ApTrivialFusionEndOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ApVariadicOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ApplyPerChannelScaleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgsortOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsComplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsRealOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsStridedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Asgd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Asin_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Asinh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignPosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignValue_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AttentionLstmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AucOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AverageAccumulates_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BaddbmmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Baddbmm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BarrierOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchFcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLoss_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BeamSearchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BernoulliOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BicubicInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BincountOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BinomialOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BipartiteMatchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseAndOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseAnd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseLeftShiftOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseLeftShift_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseNotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseNot_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseOrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseOr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseRightShiftOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseRightShift_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseXorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BitwiseXor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BmmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BoxClipOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BoxCoderOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BroadcastOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Broadcast_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BroadcastTensorsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BuildSrcRankAndLocalExpertIdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceSumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CAllreduceSum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CIdentityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CIdentity_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CScatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithCrossEntropyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSplitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CalAuxLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CalcReducedAttnScoresOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cast_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Ceil_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ChannelShuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CheckFiniteAndUnscale_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CheckNumericsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskySolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClassCenterSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Clip_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipByNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipByNormSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoalesceTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CollectFpnProposalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ComplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConjOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeBiasOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CopyToOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CopysignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Copysign_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CorrelationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cos_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cosh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrfDecodingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CropOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CtcAlignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CudnnLstmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CummaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumprodOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cumprod_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumsumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Cumsum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CvmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DataOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DecayedAdagradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DecodeJpegOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DeformableConvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DependOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dTransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeLogOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DetOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DgcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DgcClipByNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DgcClipByNormSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DgcMomentumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagEmbedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagonalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DigammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Digamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DirichletOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DisableCheckModelNanInfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DpsgdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DropoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EditDistanceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EighOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalshOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Elu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingWithScaledGradientOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmptyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmptyLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EnableCheckModelNanInfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EqualAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Erf_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfinvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Erfinv_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Exp_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandAsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandModalityExpertIdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Exponential_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EyeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeChannelWiseDequantizeMaxAbsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeChannelWiseQuantizeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeChannelWiseQuantizeDequantizeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeDequantizeMaxAbsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeMovingAverageAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeMovingAverageAbsMax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeMovingAverageAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeMovingAverageAbsMax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeRangeAbsMaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeRangeAbsMax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2cOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2rOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftR2cOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Fill_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnQkvpackedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnUnpaddedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnV3Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnV3VarlenOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnVarlenQkvpackedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashmaskAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Flatten_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlipOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Floor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FminOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FoldOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FractionalMaxPool2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FractionalMaxPool3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrameOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrobeniusNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FtrlOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FtrlSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Full_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullBatchSizeLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullIntArrayOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullWithTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormAct_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivation_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskUpperTriangleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammainccOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Gammaincc_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammalnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Gammaln_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherNdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherTreeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplace_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GenerateProposalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GlobalGatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GlobalScatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GraphKhopSamplerOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GraphSampleNeighborsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GridSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GruOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GruUnitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GumbelSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Hardtanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HeavisideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HingeLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HistogramOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HsigmoidLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HuberLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0eOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1eOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLoss_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Im2sequenceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ImagOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAdd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexElementwiseGetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexElementwisePutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexElementwisePut_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPut_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSampleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectStridedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InverseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsEmptyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IscloseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsfiniteOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsfiniteSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsinfOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsinfSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KldivLossOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KronOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KthvalueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::L1NormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::L1Norm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LabelSmoothOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lamb_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LambSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyRelu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LerpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lerp_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LgammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lgamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LimitByCapacityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinspaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LlmInt8LinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1p_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogcumsumexpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalAndOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalAnd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalNotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalNot_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalOrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalOr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalXorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogicalXor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Logit_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogspaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsumexpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableDequantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LpPool2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LstmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LstsqOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Lu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuSolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuUnpackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedFillOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedFill_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedMultiheadAttention_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedSelectOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatchMatrixTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixNmsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixPowerOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixRankOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixRankAtolRtolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixRankTolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dWithIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool3dWithIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyD2hOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyH2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemoryEfficientAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergeSelectedRowsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergedAdam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MergedMomentum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeshgridOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ModeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeCombineOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeCombineNoWeightOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchPartialNosoftmaxtopkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchPermuteOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoePermuteOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeUnpermuteOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Momentum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MomentumDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MpAllreduceSumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MpAllreduceSum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiDotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MulticlassNms3Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultinomialOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Nadam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NanmedianOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NearestInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NextafterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NllLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NmsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NonzeroOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NpuIdentityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NumelOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OneHotOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnesLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OverlapAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialAllgatherOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialAllgather_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialSumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelShuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelUnshuffleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PoissonOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PolygammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Polygamma_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pow_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PreluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PriorBoxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ProdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PruneGateByCapacityOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PsroiPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxisOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxis_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PyramidHashOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Radam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandintOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandomRoutingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandomRouting_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RandpermOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RankAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReadFileOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RealOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Reciprocal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReduceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Reduce_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReduceAsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReduceScatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReindexGraphOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RenormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Renorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveWithTensorIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Reshape_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RestrictNonzeroOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReverseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RmsNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rmsprop_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RmspropDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RnnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rnn_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiAlignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RollOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Round_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rprop_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RreluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Rsqrt_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Scale_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Scatter_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterNdAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SearchsortedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SegmentPoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendURecvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUeRecvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceConvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceMaskOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequencePoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Set_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sgd_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SgdDenseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SgdSparseParamSparseGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShapeSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Shape64Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Shape64SrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShardIndexOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShareDataOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShareDataSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleBatchOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleChannelOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sigmoid_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogits_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sin_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sinh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SlogdetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SpectralNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitWithNumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Sqrt_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Square_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareSr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquaredL2NormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Squeeze_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StandardGammaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StftOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StridedSliceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdvalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwigluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncCalcStreamOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncCalcStream_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TakeAlongAxisOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tanh_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TdmChildOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TdmSamplerOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TemporalShiftOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedRelu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopPSamplingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopkOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TraceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransLayoutOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Transpose_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriangularSolveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Tril_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilIndicesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilinearInterpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Triu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuIndicesOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Trunc_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncatedGaussianRandomOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnbindOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnfoldOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplace_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformRandomBatchSizeLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformRandomBatchSizeLikeSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniqueConsecutiveOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnpoolOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unpool3dOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unsqueeze_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnstackOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UpdateLossScaling_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::VarianceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewDtypeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewSliceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViterbiDecodeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarpctcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarprnntOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightDequantizeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightOnlyLinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightQuantizeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightedSampleNeighborsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WhereOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Where_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxHeadOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxPostOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloLossOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ZerosOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ZerosLikeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ChunkEvalOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Fp8GemmBlockwise_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Fp8QuantBlockwiseOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRmsNormExtOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IntBincountOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NumberCountOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddPositionEncodingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineChannelGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineChannelGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AffineGridGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AngleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArgsortGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsComplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsRealGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsStridedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Atan2GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BaddbmmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchFcGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BceLossGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BicubicInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BilinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BmmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BroadcastTensorsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CConcatGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithCrossEntropyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithCrossEntropyGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CalAuxLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeilGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CeluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ChannelShuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CholeskySolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ClipGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ComplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConcatGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ConjGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dGradGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CopysignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CopysignGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CorrelationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CosTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoshGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CropGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossEntropyWithSoftmaxGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CudnnLstmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CummaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumprodGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CumsumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CvmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DeformableConvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DepthwiseConv2dTransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DiagonalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DigammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DotGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DropoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EighGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EigvalshGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingWithScaledGradientGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ErfinvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandAsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExpandGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeChannelWiseQuantizeDequantizeAbsMaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeAbsMaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FakeQuantizeDequantizeMovingAverageAbsMaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2cGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftC2rGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FftR2cGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillDiagonalTensorGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FillGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnQkvpackedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnUnpaddedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnV3GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashAttnVarlenQkvpackedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlashmaskAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlattenGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FlipGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FminGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FoldGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FractionalMaxPool2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FractionalMaxPool3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrameGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FrobeniusNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBatchNormActGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBnAddActivationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSoftmaxMaskUpperTriangleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammainccGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GammalnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherNdDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GatherNdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GaussianInplaceGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GlobalGatherGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GlobalScatterGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GridSampleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GruGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GruUnitGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GumbelSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardshrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardsigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardtanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HeavisideGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HingeLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HsigmoidLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HuberLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I0eGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::I1eGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IdentityLossGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ImagGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexAddGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexElementwiseGetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexElementwisePutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPutDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexPutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSampleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndexSelectStridedGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InstanceNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::InverseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KldivLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KronGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::KthvalueGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::L1NormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LabelSmoothGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LerpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LgammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log10Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log2Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogcumsumexpGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogitGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LogsumexpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LpPool2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LstmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuSolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LuUnpackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MarginCrossEntropyGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedFillDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedFillGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedFillGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedSelectGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatchMatrixTensorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatrixPowerGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dWithIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool3dWithIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanAllGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemoryEfficientAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MeshgridGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ModeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeCombineGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeCombineNoWeightGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchPartialNosoftmaxtopkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MoeGateDispatchPermuteGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MpAllreduceSumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiDotGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NanmedianGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NearestInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NllLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OverlapAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PadGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialConcatGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialSumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelShuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PixelUnshuffleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PoissonGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PolygammaGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool2dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pool3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PreluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ProdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PsroiPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxisDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PutAlongAxisGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QrGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RankAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RealGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReciprocalGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReduceAsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6Grad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RenormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveWithTensorIndexDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RepeatInterleaveWithTensorIndexGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReverseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RmsNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RnnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiAlignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoiPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RollGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoundGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RreluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RsqrtGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScatterNdAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SegmentPoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendURecvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUeRecvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendUvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceConvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequencePoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueWithTensorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleChannelGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidCrossEntropyWithLogitsGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SigmoidTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SlogdetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftplusGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftshrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftsignGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SpectralNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SplitWithNumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquaredL2NormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StackDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StridedSliceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SvdvalsGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwigluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SwishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TakeAlongAxisDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TakeAlongAxisGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhShrinkGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TemporalShiftGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ThresholdedReluGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TopkGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TraceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransLayoutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriangularSolveGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TrilinearInterpGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TriuGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TruncGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnbindGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnfoldGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniformInplaceGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnsqueezeGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnstackGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ViewDtypeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarpctcGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WarprnntGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WeightOnlyLinearGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WhereGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloLossGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BmmDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DisableCheckModelNanInfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EnableCheckModelNanInfGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRmsNormExtGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Im2sequenceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PyramidHashGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShuffleBatchGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SiluDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StftGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Unpool3dGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UnpoolGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WhereDoubleGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddLayernormXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddcmulXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BlhaGetMaxLenOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BlockMultiheadAttention_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BlockMultiheadAttentionXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BlockMultiheadAttentionXpu_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BnActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv1dXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dTransposeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv2dXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CrossAttentionXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistributedFusedLambInitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistributedFusedLambInit_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingWithEltwiseAddXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FastLayernormXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FastWhereXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FcOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FcXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Fp8Fp8HalfGemmFusedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasDropoutResidualLayerNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasResidualLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedConv2dAddActOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDconvDreluDbnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDotProductAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDropoutAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElementwiseAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElementwiseDivOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElementwiseMulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElementwiseSubOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseActivationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseAddActivationOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedEmbeddingEltwiseLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFcElementwiseLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedLinearParamGradAddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformer_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformerInt8XpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformerXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRotaryPositionEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedScaleBiasAddReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedScaleBiasReluConvBnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSeqpoolCvmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedStackQuantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedStackTransposeQuantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedTokenPruneOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedTransposeWlchSplitQuantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionGroupOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionGruOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionLstmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionRepeatedFcReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSeqconvEltaddReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSeqpoolConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSeqpoolCvmConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionSquaredMatSubOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusionTransposeFlattenConcatOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GemmEpilogueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GenerateSequenceXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GroupNormSiluXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormActXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LayerNormReluXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskAdaptiveXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiEncoderXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiheadMatmulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Pad2dXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QkvAttentionXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QkvUnpackMhaOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QuantizeXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ResnetBasicBlockOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ResnetUnitOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RoformerRelativeEmbeddingXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SelfDpAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceUnpadXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinePosXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SkipLayernormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SpatialTransformerResblockXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqueezeExcitationBlockOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::VariableLengthMemoryEfficientAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::YoloBoxXpuOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddGroupNormSiluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedActDequantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedEmbeddingFcLstmOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSwigluWeightedBwdOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedTransposeSplitQuantOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedWeightedSwigluActQuantOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedBiasDropoutResidualLayerNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDotProductAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedDropoutAddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseActivationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedElemwiseAddActivationGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedRotaryPositionEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedSeqpoolCvmGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxPool2dV2GradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ResnetBasicBlockGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ResnetUnitGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Add_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddNOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AnchorGeneratorOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Assign_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignValueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNorm_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BeamSearchDecodeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoalesceTensor_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CommInitAllOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeLinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DequantizeLinear_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DistributeFpnProposalsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Divide_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EinsumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ElementwisePowOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Equal_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorDivideOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FloorDivide_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAdam_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedGateAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedMultiTransformerInt8Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GetTensorFromSelectedRowsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterThanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::GreaterThan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HashOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LarsMomentum_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LegacyMatmulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LegacyReshapeOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LegacyReshape_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessThanOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LessThan_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LoadCombineOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodArrayLengthOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodResetOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodReset_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LrnOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulWithFlattenOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaximumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MemcpyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinimumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplySrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Multiply_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplySr_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NopOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Nop_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NotEqualOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NotEqual_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialRecvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PartialSendOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PrintOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QuantizeLinearOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::QuantizeLinear_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RecvV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RemainderOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Remainder_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RowConvOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SaveCombineOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SendV2Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceExpandOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceSoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValue_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShadowFeedOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShadowFeedTensorsOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ShareData_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftReluOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Softmax_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseMomentumOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::StraightThroughEstimatorGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Subtract_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncCommStreamOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncCommStream_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::UniqueOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::WriteToArrayOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithMultiLabelCrossEntropyOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FasterTokenizerOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFeedforwardOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MovingAverageAbsMaxScaleOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MovingAverageAbsMaxScale_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NceOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::OnednnToPaddleLayoutOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddTripleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOutGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AssignOutGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CSoftmaxWithMultiLabelCrossEntropyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EinsumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ElementwisePowGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::EmbeddingSparseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseWeightEmbeddingSparseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ExponentialGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedFeedforwardGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedGateAttentionGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::HardswishGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LegacyMatmulGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LegacyReshapeGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodResetGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LodResetGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableSparseGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableGradSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LookupTableSparseGradSrOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LrnGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulWithFlattenGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaximumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MinimumGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyTripleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NceGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::NceSrGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PrintGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RemainderGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::RowConvGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceExpandGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SequenceSoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SetValueGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftReluGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractDoubleGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractGrad_Op)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileDoubleGradOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TileGradOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ArangeOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCooDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNorm_SpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dImplicitGemmSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideScalarCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideScalarCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1CooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1CsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IsnanCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6CooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6CsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseCooTensorSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNorm_SpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CooToDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CsrToDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DenseToCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CsrToCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DenseToCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CooToCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ValuesCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ValuesCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCsrDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCooDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CoalesceSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullLikeCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FullLikeCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::IndicesSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskAsCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskAsCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedMatmulSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCsrDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCsrCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCooDenseSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCooCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxpoolSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvCsrSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceCooSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceCsrSpOp)


IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AbsCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcosCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AcoshCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddCooDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCsrDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCooDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AddmmCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AsinhCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::AtanhCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::BatchNormGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::CastCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Conv3dGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::DivideScalarGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1CooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Expm1CsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::LeakyReluCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Log1pCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskAsCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskAsCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaskedMatmulGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCsrDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCooDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MatmulCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MaxpoolGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MultiplyCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::MvCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::PowCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6CooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::Relu6CsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReluCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ReshapeCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ScaleGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SinhCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SoftmaxCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SparseCooTensorGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SqrtCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SquareCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractCooCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SubtractCsrCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SumCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SyncBatchNormGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TanhCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ToDenseGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ToSparseCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::TransposeCsrGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::ValuesGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::FusedAttentionGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceCooGradSpOp)

IR_DECLARE_EXPLICIT_TYPE_ID(paddle::dialect::SliceCsrGradSpOp)

